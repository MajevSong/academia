# Literature Review: A Systematic Review of EEG Feature Extraction Methods for Brain-Computer Interfaces

**Generated Date:** 15.12.2025

> [!NOTE]
> This report is a compilation of the identified sources.

## 1. Emotion recognition with EEG-based brain-computer interfaces: a systematic literature review

**Authors:** Kübra Erat, Elif Bilge Şahin, Furkan Doğan, Nur Merdanoğlu, Ahmet Akcakaya, P. O. Durdu (2024)
**DOI/URL:** 10.1007/s11042-024-18259-z

Electroencephalography (EEG)-based Brain-Computer Interface (BCI) systems for emotion recognition have the potential to assist the enrichment of human–computer interaction with implicit information since they can enable understanding of the cognitive and emotional activities of humans. Therefore, these systems have become an important research topic today. This study aims to present trends and gaps on this topic by performing a systematic literature review based on the 216 published scientific literature gathered from various databases including ACM, IEEE Xplore, PubMed, Science Direct, and Web of Science from 2016 to 2020. This review gives an overview of all the components of EEG based BCI system from the signal stimulus module which includes the employed device, signal stimuli, and data processing modality, to the signal processing module which includes signal acquisition, pre-processing, feature extraction, feature selection, classification algorithms, and performance evaluation. Thus, this study provides an overview of all components of an EEG-based BCI system for emotion recognition and examines the available evidence in a clear, concise, and systematic way. In addition, the findings are aimed to inform researchers about the issues on what are research trends and the gaps in this field and guide them in their research directions.

## 2. Exploring the Evolution of Feature Extraction Methods in Brain–Computer Interfaces (BCIs): A Systematic Review of Research Progress and Future Trends

**Authors:** S. Thakur, Samriti Thakur, Aryan Rana, Pankaj Kumar, Kranti Kumar, Chien‐Ming Chen (2025)
**DOI/URL:** 10.1002/widm.70040

Brain–computer interfaces (BCIs) have emerged as transformative tools, enabling direct communication between the brain and external devices, particularly for individuals with neuromuscular disabilities. This paper provides a comprehensive analysis of feature extraction (FE) methods across all major signal processing domains and various types of BCIs, addressing a significant gap in existing reviews and surveys that often focus exclusively on EEG‐based systems. Also, a detailed comparative analysis of FE techniques, highlighting their formulas, advantages, limitations, and practical applications, is provided. The study not only reviews state‐of‐the‐art methods but also evaluates recent research, identifying trends and gaps in the field. Key insights reveal a growing foundation for invasive BCI research, which, while currently limited, shows promise for future advancements. Based on this analysis, we identify and discuss open challenges such as inter‐subject variability, real‐time processing demands, integration of multiple modalities, and user training and adaptation. Additionally, we examine pressing concerns related to security, privacy, and the transferability of models. By addressing these challenges, this paper aims to guide the development of robust, efficient, and inclusive BCI systems, paving the way for cutting‐edge innovations and real‐world applications.

## 3. Exploring the Potential of Brain-Computer Interfaces and EEG Signal Analysis Algorithms: A Review and Analysis of Computational Techniques

**Authors:** P. Nikolov, Olexiy Bychkov, Katia Rasheva-Yordanova, G. Dimitrov, Pavel S. Petrov, V. Martsenyuk (2025)
**DOI/URL:** 10.1109/ACIT65614.2025.11185624

In this paper, we review existing methods and algorithms for the analysis of electroencephalogram (EEG) signals in the context of brain-computer interfaces (BCIs). Through a systematic review of the current scientific literature, the main challenges and approaches in the field are identified. Special attention is paid to state-of-the-art data preprocessing, feature extraction and signal classification techniques. The paper discusses the limitations of existing methods, potential directions for future research and the use of brain waves for user authentication. By focusing on frequency spectra and other brainwave features combined with machine learning, it achieves extremely high accuracy in user recognition. Electroencephalography (EEG) offers new possibilities for controlling electronic devices via neural signals and also provides a basis for biometric user authentication. A survey of various data collection methods, feature extraction and classification algorithms including adaptive classifiers, deep learning and transfer learning is presented.

## 4. Feature Extraction and Classification of Motor Imagery EEG Signals in Motor Imagery for Sustainable Brain–Computer Interfaces

**Authors:** Yuyi Lu, Wenbo Wang, Baosheng Lian, Chencheng He (2024)
**DOI/URL:** 10.3390/su16156627

Motor imagery brain–computer interface (MI-BCI) systems hold the potential to restore motor function and offer the opportunity for sustainable autonomous living for individuals with a range of motor and sensory impairments. The feature extraction and classification of motor imagery EEG signals related to motor imagery brain–computer interface systems has become a research hotspot. To address the challenges of difficulty in feature extraction and low recognition rates of motor imagery EEG signals caused by individual variations in EEG signals, a classification algorithm for EEG signals based on multi-feature fusion and the SVM-AdaBoost algorithm was proposed to improve the recognition accuracy of motor imagery EEG signals. Initially, the electroencephalography (EEG) signals are preprocessed using Finite Impulse Response (FIR) filters, and a multi-wavelet framework is constructed based on the Morlet wavelet and the Haar wavelet. Subsequently, the preprocessed signals undergo multi-wavelet decomposition to extract energy features, Common Spatial Patterns (CSP) features, Autoregressive (AR) features, and Power Spectral Density (PSD) features. The extracted features are then fused, and the fused feature vector is normalized. Following that, classification is implemented within the SVM-AdaBoost algorithm. To enhance the adaptability of SVM-AdaBoost, the Grid Search method is employed to optimize the penalty parameter and kernel function parameter of the SVM. Concurrently, the Whale Optimization Algorithm is utilized to optimize the learning rate and number of weak learners within the AdaBoost ensemble, thereby refining the overall performance. In addition, the classification performance of the algorithm is validated using a brain-computer interface (BCI) dataset. In this study, it was found that the classification accuracy reached 95.37%. Via the analysis of motor imagery electroencephalography (EEG) signals, the activation patterns in different regions of the brain can be detected and identified, enabling the inference of user intentions and facilitating communication and control between the human brain and external devices.

## 5. Developing Innovative Feature Extraction Techniques from the Emotion Recognition Field on Motor Imagery Using Brain–Computer Interface EEG Signals

**Authors:** Amr F. Mohamed, V. Jusas (2024)
**DOI/URL:** 10.3390/app142311323

Research on brain–computer interfaces (BCIs) advances the way scientists understand how the human brain functions. The BCI system, which is based on the use of electroencephalography (EEG) signals to detect motor imagery (MI) tasks, enables opportunities for various applications in stroke rehabilitation, neuroprosthetic devices, and communication tools. BCIs can also be used in emotion recognition (ER) research to depict the sophistication of human emotions by improving mental health monitoring, human–computer interactions, and neuromarketing. To address the low accuracy of MI-BCI, which is a key issue faced by researchers, this study employs a new approach that has been proven to have the potential to enhance motor imagery classification accuracy. The basic idea behind the approach is to apply feature extraction methods from the field of emotion recognition to the field of motor imagery. Six feature sets and four classifiers were explored using four MI classes (left and right hands, both feet, and tongue) from the BCI Competition IV 2a dataset. Statistical, wavelet analysis, Hjorth parameters, higher-order spectra, fractal dimensions (Katz, Higuchi, and Petrosian), and a five-dimensional combination of all five feature sets were implemented. GSVM, CART, LinearSVM, and SVM with polynomial kernel classifiers were considered. Our findings show that 3D fractal dimensions predominantly outperform all other feature sets, specifically during LinearSVM classification, accomplishing nearly 79.1% mean accuracy, superior to the state-of-the-art results obtained from the referenced MI paper, where CSP reached 73.7% and Riemannian methods reached 75.5%. It even performs as well as the latest TWSB method, which also reached approximately 79.1%. These outcomes emphasize that the new hybrid approach in the motor imagery/emotion recognition field improves classification accuracy when applied to motor imagery EEG signals, thus enhancing MI-BCI performance.

## 6. Multiscale Spatial-Temporal Feature Fusion Neural Network for Motor Imagery Brain-Computer Interfaces

**Authors:** Jing Jin, Weijie Chen, Ren Xu, Wei Liang, Xiao Wu, Xinjie He, Xingyu Wang, Andrzej Cichocki (2024)
**DOI/URL:** 10.1109/JBHI.2024.3472097

Motor imagery, one of the main brain-computer interface (BCI) paradigms, has been extensively utilized in numerous BCI applications, such as the interaction between disabled people and external devices. Precise decoding, one of the most significant aspects of realizing efficient and stable interaction, has received a great deal of intensive research. However, the current decoding methods based on deep learning are still dominated by single-scale serial convolution, which leads to insufficient extraction of abundant information from motor imagery signals. To overcome such challenges, we propose a new end-to-end convolutional neural network based on multiscale spatial-temporal feature fusion (MSTFNet) for EEG classification of motor imagery. The architecture of MSTFNet consists of four distinct modules: feature enhancement module, multiscale temporal feature extraction module, spatial feature extraction module and feature fusion module, with the latter being further divided into the depthwise separable convolution block and efficient channel attention block. Moreover, we implement a straightforward yet potent data augmentation strategy to bolster the performance of MSTFNet significantly. To validate the performance of MSTFNet, we conduct cross-session experiments and leave-one-subject-out experiments. The cross-session experiment is conducted across two public datasets and one laboratory dataset. On the public datasets of BCI Competition IV 2a and BCI Competition IV 2b, MSTFNet achieves classification accuracies of 83.62% and 89.26%, respectively. On the laboratory dataset, MSTFNet achieves 86.68% classification accuracy. Besides, the leave-one-subject-out experiment is performed on the BCI Competition IV 2a dataset, and MSTFNet achieves 66.31% classification accuracy. These experimental results outperform several state-of-the-art methodologies, indicate the proposed MSTFNet's robust capability in decoding EEG signals associated with motor imagery.

## 7. EEG-based Brain-Computer Interfaces for people with Disorders of Consciousness: Features and applications. A systematic review

**Authors:** V. Galiotta, I. Quattrociocchi, M. D'ippolito, F. Schettini, P. Aricó, S. Sdoia, R. Formisano, F. Cincotti, D. Mattia, A. Riccio (2022)
**DOI/URL:** 10.3389/fnhum.2022.1040816

Background Disorders of Consciousness (DoC) are clinical conditions following a severe acquired brain injury (ABI) characterized by absent or reduced awareness, known as coma, Vegetative State (VS)/Unresponsive Wakefulness Syndrome (VS/UWS), and Minimally Conscious State (MCS). Misdiagnosis rate between VS/UWS and MCS is attested around 40% due to the clinical and behavioral fluctuations of the patients during bedside consciousness assessments. Given the large body of evidence that some patients with DoC possess “covert” awareness, revealed by neuroimaging and neurophysiological techniques, they are candidates for intervention with brain-computer interfaces (BCIs). Objectives The aims of the present work are (i) to describe the characteristics of BCI systems based on electroencephalography (EEG) performed on DoC patients, in terms of control signals adopted to control the system, characteristics of the paradigm implemented, classification algorithms and applications (ii) to evaluate the performance of DoC patients with BCI. Methods The search was conducted on Pubmed, Web of Science, Scopus and Google Scholar. The PRISMA guidelines were followed in order to collect papers published in english, testing a BCI and including at least one DoC patient. Results Among the 527 papers identified with the first run of the search, 27 papers were included in the systematic review. Characteristics of the sample of participants, behavioral assessment, control signals employed to control the BCI, the classification algorithms, the characteristics of the paradigm, the applications and performance of BCI were the data extracted from the study. Control signals employed to operate the BCI were: P300 (N = 19), P300 and Steady-State Visual Evoked Potentials (SSVEP; hybrid system, N = 4), sensorimotor rhythms (SMRs; N = 5) and brain rhythms elicited by an emotional task (N = 1), while assessment, communication, prognosis, and rehabilitation were the possible applications of BCI in DoC patients. Conclusion Despite the BCI is a promising tool in the management of DoC patients, supporting diagnosis and prognosis evaluation, results are still preliminary, and no definitive conclusions may be drawn; even though neurophysiological methods, such as BCI, are more sensitive to covert cognition, it is suggested to adopt a multimodal approach and a repeated assessment strategy.

## 8. EEG-based vibrotactile evoked brain-computer interfaces system: A systematic review

**Authors:** Xiuyu Huang, Shuang Liang, Zengguang Li, C. Lai, K. Choi (2022)
**DOI/URL:** 10.1371/journal.pone.0269001

Recently, a novel electroencephalogram-based brain-computer interface (EVE-BCI) using the vibrotactile stimulus shows great potential for an alternative to other typical motor imagery and visual-based ones. (i) Objective: in this review, crucial aspects of EVE-BCI are extracted from the literature to summarize its key factors, investigate the synthetic evidence of feasibility, and generate recommendations for further studies. (ii) Method: five major databases were searched for relevant publications. Multiple key concepts of EVE-BCI, including data collection, stimulation paradigm, vibrotactile control, EEG signal processing, and reported performance, were derived from each eligible article. We then analyzed these concepts to reach our objective. (iii) Results: (a) seventy-nine studies are eligible for inclusion; (b) EEG data are mostly collected among healthy people with an embodiment of EEG cap in EVE-BCI development; (c) P300 and Steady-State Somatosensory Evoked Potential are the two most popular paradigms; (d) only locations of vibration are heavily explored by previous researchers, while other vibrating factors draw little interest. (e) temporal features of EEG signal are usually extracted and used as the input to linear predictive models for EVE-BCI setup; (f) subject-dependent and offline evaluations remain popular assessments of EVE-BCI performance; (g) accuracies of EVE-BCI are significantly higher than chance levels among different populations. (iv) Significance: we summarize trends and gaps in the current EVE-BCI by identifying influential factors. A comprehensive overview of EVE-BCI can be quickly gained by reading this review. We also provide recommendations for the EVE-BCI design and formulate a checklist for a clear presentation of the research work. They are useful references for researchers to develop a more sophisticated and practical EVE-BCI in future studies.

## 9. Privacy-Preserving Brain–Computer Interfaces: A Systematic Review

**Authors:** Kun Xia, Włodziaław Duch, Yu Sun, Kedi Xu, Weili Fang, Hanbin Luo, Yi Zhang, Dong Sang, Xiaodong Xu, Fei‐Yue Wang, Dongrui Wu (2023)
**DOI/URL:** 10.1109/TCSS.2022.3184818

A brain–computer interface (BCI) establishes a direct communication pathway between the human brain and a computer. It has been widely used in medical diagnosis, rehabilitation, education, entertainment, and so on. Most research so far focuses on making BCIs more accurate and reliable, but much less attention has been paid to their privacy. Developing a commercial BCI system usually requires close collaborations among multiple organizations, e.g., hospitals, universities, and/or companies. Input data in BCIs, e.g., electroencephalogram (EEG), contain rich privacy information, and the developed machine learning model is usually proprietary. Data and model transmission among different parties may incur significant privacy threats, and hence, privacy protection in BCIs must be considered. Unfortunately, there does not exist any contemporary and comprehensive review on privacy-preserving BCIs. This article fills this gap, by describing potential privacy threats and protection strategies in BCIs. It also points out several challenges and future research directions in developing privacy-preserving BCIs.

## 10. Stimuli and Feature Extraction Algorithms for Brain-Computer Interfaces: A Systematic Comparison

**Authors:** M. Bittencourt-Villalpando, N. Maurits (2018)
**DOI/URL:** 10.1109/TNSRE.2018.2855801

A brain–computer interface (BCI) is a system that allows communication between the central nervous system and an external device. The BCIs developed by various research groups differ in their main features and the comparison across studies is therefore challenging. Here, in the same group of 19 healthy participants, we investigate three different tasks (SSVEP, P300, and hybrid) that allowed four choices to the user without previous neurofeedback training. We used the same 64-channel EEG equipment to acquire data, while participants performed each of the tasks. We systematically compared the participants’ offline performance on the following parameters: 1) accuracy; 2) BCI Utility (in bits/min); and 3) inefficiency/illiteracy. In addition, we evaluated the accuracy as a function of the number of electrodes. In this paper, the SSVEP task outperformed the other tasks in bit rate, reaching an average and maximum BCI Utility of 63.4 and 91.3 bits/min, respectively. All participants achieved an accuracy level above70% on both SSVEP and P300 tasks. Furthermore, the average accuracy of all tasks was highest if a reduced subset with 4–12 electrodes was used. These results are relevant for the development of online BCIs intended for the real-life applications.

## 11. Fatigue factors and fatigue indices in SSVEP-based brain-computer interfaces: a systematic review and meta-analysis

**Authors:** Maedeh Azadi Moghadam, Ali Maleki (2023)
**DOI/URL:** 10.3389/fnhum.2023.1248474

Background Fatigue is a serious challenge when applying a steady-state visual evoked potential (SSVEP)-based brain-computer interfaces (BCIs) in the real world. Many researchers have used quantitative indices to study the effect of visual stimuli on fatigue. According to a wide range of studies in fatigue analysis, there are contradictions and inconsistencies in the behavior of fatigue indicators. New method In this study, for the first time, a systematic review and meta-analysis were performed on fatigue indices and fatigue caused by stimulation paradigm. We queried three scientific search engines for studies published between 2000 and 2022. The inclusion criteria were papers investigating mental and visual fatigue from performing a visual task using electroencephalogram (EEG) signals. Results Attractiveness and variation are the most effective ways to reduce BCI fatigue. Therefore, zoom motion, Newton’s ring motion, and cue patterns reduce fatigue. While the color of the cue could effectively reduce fatigue, its shape and background had no effect on fatigue. Additionally, the questionnaire and quantitative indicators such as frequency indices, signal-to-noise ratio (SNR), SSVEP amplitude, and multiscale entropy were utilized to assess fatigue. Meta-analysis indicated that when a person is fatigued, the spectrum amplitude of alpha, theta, and α+θ/β increase significantly, while SNR and SSVEP amplitude decrease significantly. Conclusion The outcomes of this study can be used to design more optimal stimulation protocols that cause less fatigue. Moreover, the level of fatigue can be quantitatively assessed with indicators without the participant’s self-reports.

## 12. Cross-domain Feature Distillation Framework for Enhancing Classification in Ear-EEG Brain-Computer Interfaces

**Authors:** Ying Sun, Xiaolin Liu, Rui Na, Shuai Wang, Dezhi Zheng, Shangchun Fan (2023)
**DOI/URL:** 10.1145/3594739.3612911

Ear-electroencephalography (EEG) holds significant promise as a practical tool in brain-computer interfaces (BCIs) due to its enhanced unobtrusiveness, comfort, and mobility in comparison to traditional steady-state visual evoked potential (SSVEP)-based BCI systems. However, achieving accurate SSVEP classification in ear-EEG faces a major challenge due to the significant attenuation and distorted amplitude of the signal. To address this challenge, this paper focuses on enhancing ear-EEG feature representations by training the model to learn feature representations similar to those of scalp-EEG. We propose a cross-domain feature distillation (CD-FD) framework, which facilitates the extraction of shared features between the two domains. This framework facilitates the identification of crucial features concealed within ear-EEG signals, leading to more effective SSVEP classification. We evaluate the proposed CD-FD framework through single-session decoding and session-to-session transfer decoding, comparing it with EEGNet and canonical correlation analysis (CCA). The results demonstrate that the proposed framework achieves the best classification results in all experiments.

## 13. EEG-Based Brain-Computer Interactions in Immersive Virtual and Augmented Reality: A Systematic Review

**Authors:** Chukwuemeka Nwagu, Ala'a N. Alslaity, Rita Orji (2023)
**DOI/URL:** 10.1145/3593226

Brain-computer interactions allow humans to passively or actively control computer systems using their brain activity. For more than a decade now, these interactions have been implemented and evaluated in immersive virtual environments where they prompt novel means of human interaction with systems. In this paper, we present a systematic review of 76 studies published over the last 10 years that develop and evaluate immersive virtual reality or augmented reality systems with electroencephalography-based interactions. The aim of the review is to summarize and highlight trends in technology design, research methods, current practices, techniques used in systems of this kind, challenges and opportunities that present direction for future research in this area. Our analysis uncovers useful insights, limitations, and highlights of the trends, innovations, and usability and technical challenges at the intersection of brain-computer interfaces and immersive technologies, as well as recommendations for future research.

## 14. Optimal Deep Learning-Based Recognition Model for EEG Enabled Brain-Computer Interfaces Using Motor-Imagery

**Authors:** S. Rajalakshmi, Ibrahim AlMohimeed, Mohamed Yacin Sikkandar, S. Sabarunisha Begum (2023)
**DOI/URL:** 10.2478/msr-2023-0031

Abstract Brain-Computer Interfaces (BCIs) facilitate the translation of brain activity into actionable commands and act as a crucial link between the human brain and the external environment. Electroencephalography (EEG)-based BCIs, which focus on motor imagery, have emerged as an important area of study in this domain. They are used in neurorehabilitation, neuroprosthetics, and gaming, among other applications. Optimal Deep Learning-Based Recognition for EEG Signal Motor Imagery (ODLR-EEGSM) is a novel approach presented in this article that aims to improve the recognition of motor imagery from EEG signals. The proposed method includes several crucial stages to improve the precision and effectiveness of EEG-based motor imagery recognition. The pre-processing phase starts with the Variation Mode Decomposition (VMD) technique, which is used to improve EEG signals. The EEG signals are decomposed into different oscillatory modes by VMD, laying the groundwork for subsequent feature extraction. Feature extraction is a crucial component of the ODLR-EEGSM method. In this study, we use Stacked Sparse Auto Encoder (SSAE) models to identify significant patterns in the pre-processed EEG data. Our approach is based on the classification model using Deep Wavelet Neural Network (DWNN) optimized with Chaotic Dragonfly Algorithm (CDFA). CDFA optimizes the weight and bias values of the DWNN, significantly improving the classification accuracy of motor imagery. To evaluate the efficacy of the ODLR-EEGSM method, we use benchmark datasets to perform rigorous performance validation. The results show that our approach outperforms current methods in the classification of EEG motor imagery, confirming its promising performance. This study has the potential to make brain-computer interface applications in various fields more accurate and efficient, and pave the way for brain-controlled interactions with external systems and devices.

## 15. EEG Decoding Based on Normalized Mutual Information for Motor Imagery Brain–Computer Interfaces

**Authors:** Chao Tang, Dongyao Jiang, Lujuan Dang, Badong Chen (2024)
**DOI/URL:** 10.1109/TCDS.2024.3401717

In current research, noninvasive brain–computer interfaces (BCIs) typically rely on electroencephalogram (EEG) signals to measure brain activity. Motor imagery EEG decoding is an important research field of BCIs. Although multichannel EEG signals provide higher resolution, they contain noise and redundant data unrelated to the task, which affect the performance of BCI systems. We investigate the interactions between EEG signals from dependence analysis to improve the classification accuracy. In this article, a novel channel selection method based on normalized mutual information (NMI) is first proposed to select the informative channels. Then, a histogram of oriented gradient is applied to feature extraction in the rearranged NMI matrices. Finally, a support vector machine with a radial basis function kernel is used for the classification of different motor imagery tasks. Four publicly available BCI datasets are employed to evaluate the effectiveness of the proposed method. The experimental results show that the proposed decoding scheme significantly improves classification accuracy and outperforms other competing methods.

## 16. EEG-DBNet: A Dual-Branch Network for Temporal-Spectral Decoding in Motor-Imagery Brain-Computer Interfaces

**Authors:** Xicheng Lou, Xinwei Li, Hongying Meng, Jun Hu, Meili Xu, Yue Zhao, Jiazhang Yang, Zhangyong Li (2024)
**DOI/URL:** 10.48550/arXiv.2405.16090

Motor imagery electroencephalogram (EEG)-based brain-computer interfaces (BCIs) offer significant advantages for individuals with restricted limb mobility. However, challenges such as low signal-to-noise ratio and limited spatial resolution impede accurate feature extraction from EEG signals, thereby affecting the classification accuracy of different actions. To address these challenges, this study proposes an end-to-end dual-branch network (EEG-DBNet) that decodes the temporal and spectral sequences of EEG signals in parallel through two distinct network branches. Each branch comprises a local convolutional block and a global convolutional block. The local convolutional block transforms the source signal from the temporal-spatial domain to the temporal-spectral domain. By varying the number of filters and convolution kernel sizes, the local convolutional blocks in different branches adjust the length of their respective dimension sequences. Different types of pooling layers are then employed to emphasize the features of various dimension sequences, setting the stage for subsequent global feature extraction. The global convolution block splits and reconstructs the feature of the signal sequence processed by the local convolution block in the same branch and further extracts features through the dilated causal convolutional neural networks. Finally, the outputs from the two branches are concatenated, and signal classification is completed via a fully connected layer. Our proposed method achieves classification accuracies of 85.84% and 91.60% on the BCI Competition 4-2a and BCI Competition 4-2b datasets, respectively, surpassing existing state-of-the-art models. The source code is available at https://github.com/xicheng105/EEG-DBNet.

## 17. Advancing EEG Brain-Computer Interfaces with Efficient Machine Learning Classifications

**Authors:** R. Raman, Vikram Kumar, C. P. Sanjay, Apurv Verma, Shailesh Rastogi, Dharmendra Pandey (2024)
**DOI/URL:** 10.1109/ACOIT62457.2024.10939133

In recent years, brain-computer interfaces (BCIs) have advanced significantly through the integration of electroencephalogram (EEG) data, though the complexity of EEG signals remains challenging for traditional classification methods. This paper introduces a novel machine learning framework to enhance classification efficiency in EEG-based BCIs. We employ advanced algorithms, including convolutional neural networks (CNNs) and recurrent neural networks (RNNs), to capture temporal and spatial dependencies in EEG data. Our approach leverages a combination of feature extraction techniques and dimensionality reduction to optimize classification, improving accuracy and speed. We performed a comparative analysis using a standardized EEG dataset, revealing our model’s significant improvement in classification accuracy and computational efficiency over traditional classifiers. These results highlight our method’s potential in realtime BCI applications. This study contributes to the theoretical understanding of EEG signal processing and paves the way for more responsive and user-friendly BCI systems.

## 18. Feature Extraction and Classification Methods for Hybrid fNIRS-EEG Brain-Computer Interfaces

**Authors:** Rifai Chai, K. Hong, M. J. Khan, M. J. Hong (2018)
**DOI/URL:** 10.3389/fnhum.2018.00246

In this study, a brain-computer interface (BCI) framework for hybrid functional near-infrared spectroscopy (fNIRS) and electroencephalography (EEG) for locked-in syndrome (LIS) patients is investigated. Brain tasks, channel selection methods, and feature extraction and classification algorithms available in the literature are reviewed. First, we categorize various types of patients with cognitive and motor impairments to assess the suitability of BCI for each of them. The prefrontal cortex is identified as a suitable brain region for imaging. Second, the brain activity that contributes to the generation of hemodynamic signals is reviewed. Mental arithmetic and word formation tasks are found to be suitable for use with LIS patients. Third, since a specific targeted brain region is needed for BCI, methods for determining the region of interest are reviewed. The combination of a bundled-optode configuration and threshold-integrated vector phase analysis turns out to be a promising solution. Fourth, the usable fNIRS features and EEG features are reviewed. For hybrid BCI, a combination of the signal peak and mean fNIRS signals and the highest band powers of EEG signals is promising. For classification, linear discriminant analysis has been most widely used. However, further research on vector phase analysis as a classifier for multiple commands is desirable. Overall, proper brain region identification and proper selection of features will improve classification accuracy. In conclusion, five future research issues are identified, and a new BCI scheme, including brain therapy for LIS patients and using the framework of hybrid fNIRS-EEG BCI, is provided.

## 19. Enhancing Cross-Subject Motor Imagery Classification in EEG-Based Brain–Computer Interfaces by Using Multi-Branch CNN

**Authors:** Radia Rayan Chowdhury, Yar Muhammad, Usman Adeel (2023)
**DOI/URL:** 10.3390/s23187908

A brain–computer interface (BCI) is a computer-based system that allows for communication between the brain and the outer world, enabling users to interact with computers using neural activity. This brain signal is obtained from electroencephalogram (EEG) signals. A significant obstacle to the development of BCIs based on EEG is the classification of subject-independent motor imagery data since EEG data are very individualized. Deep learning techniques such as the convolutional neural network (CNN) have illustrated their influence on feature extraction to increase classification accuracy. In this paper, we present a multi-branch (five branches) 2D convolutional neural network that employs several hyperparameters for every branch. The proposed model achieved promising results for cross-subject classification and outperformed EEGNet, ShallowConvNet, DeepConvNet, MMCNN, and EEGNet_Fusion on three public datasets. Our proposed model, EEGNet Fusion V2, achieves 89.6% and 87.8% accuracy for the actual and imagined motor activity of the eegmmidb dataset and scores of 74.3% and 84.1% for the BCI IV-2a and IV-2b datasets, respectively. However, the proposed model has a bit higher computational cost, i.e., it takes around 3.5 times more computational time per sample than EEGNet_Fusion.

## 20. A Graph-Based Feature Extraction Algorithm Towards a Robust Data Fusion Framework for Brain-Computer Interfaces

**Authors:** Shaotong Zhu, S. Hosni, Xiaofei Huang, S. B. Borgheai, J. McLinden, Y. Shahriari, S. Ostadabbas (2021)
**DOI/URL:** 10.1109/EMBC46164.2021.9630804

Objective: The topological information hidden in the EEG spectral dynamics is often ignored in the majority of the existing brain-computer interface (BCI) systems. Moreover, a systematic multimodal fusion of EEG with other informative brain signals such as functional near-infrared spectroscopy (fNIRS) towards enhancing the performance of the BCI systems is not fully investigated. In this study, we present a robust EEG-fNIRS data fusion framework utilizing a series of graph-based EEG features to investigate their performance on a motor imaginary (MI) classification task. Method: We first extract the amplitude and phase sequences of users’ multi-channel EEG signals based on the complex Morlet wavelet time-frequency maps, and then convert them into an undirected graph to extract EEG topological features. The graph-based features from EEG are then selected by a thresholding method and fused with the temporal features from fNIRS signals after each being selected by the least absolute shrinkage and selection operator (LASSO) algorithm. The fused features were then classified as MI task vs. baseline by a linear support vector machine (SVM) classifier. Results: The time-frequency graphs of EEG signals improved the MI classification accuracy by ∼5% compared to the graphs built on the band-pass filtered temporal EEG signals. Our proposed graph-based method also showed comparable performance to the classical EEG features based on power spectral density (PSD), however with a much smaller standard deviation, showing its robustness for potential use in a practical BCI system. Our fusion analysis revealed a considerable improvement of ∼17% as opposed to the highest average accuracy of EEG only and ∼3% compared with the highest fNIRS only accuracy demonstrating an enhanced performance when modality fusion is used relative to single modal outcomes. Significance: Our findings indicate the potential use of the proposed data fusion framework utilizing the graph-based features in the hybrid BCI systems by making the motor imaginary inference more accurate and more robust.

## 21. A Comparative Analysis of Mathematical EEG Feature Extraction Methods Across Temporal, Spectral, and Nonlinear Domains

**Authors:** Mehmet Zubeyir Unlu (2025)
**DOI/URL:** 10.59671/xtsjd

Electroencephalography (EEG) feature extraction plays a fundamental role in translating raw neural signals into meaningful representations for applications such as neurological diagnostics, brain-computer interfaces (BCIs), and cognitive state monitoring. This study presents a comprehensive comparative analysis of mathematical approaches employed in EEG feature extraction, categorized into time, frequency, time-frequency and nonlinear domains. In addition to reviewing existing methods, an experimental study was conducted using real EEG data from the Bonn University dataset. Features including statistical descriptors, Hjorth parameters, band powers, spectral entropy, approximate entropy, fractal dimension, Hurst exponent, and Lempel-Ziv complexity were systematically extracted and compared between healthy and seizure recordings. Furthermore, timefrequency representations were generated using Short-Time Fourier Transform (STFT) and Continuous Wavelet Transform (CWT) to capture transient and non-stationary dynamics. The results demonstrate that a multi-domain feature extraction strategy significantly enhances the ability to characterize and discriminate pathological EEG signals. Key challenges such as data variability, limited dataset availability, and the need for standardized analysis pipelines are also discussed, along with future directions including the development of benchmark datasets, explainable AI-driven feature selection, and real-time EEG processing optimization. By integrating theoretical insights with experimental validation, this study aims to support the development of more reliable, interpretable, and scalable EEG-based systems for scientific and clinical use.

## 22. EEG Feature Extraction Using Evolutionary Algorithms for Brain-Computer Interface Development

**Authors:** César Alfredo Rocha-Herrera, Alan Díaz-Manríquez, J. H. Barrón-Zambrano, J. C. Elizondo-Leal, V. P. Saldivar-Alonso, J. Martínez-Angulo, M. Nuño-Maganda, Said Polanco-Martagón (2022)
**DOI/URL:** 10.1155/2022/7571208

Brain–computer interfaces are systems capable of mapping brain activity to specific commands, which enables to remotely automate different types of processes in hardware devices or software applications. However, the development of brain–computer interfaces has been limited by several factors that affect their performance, such as the characterization of events in brain signals and the excessive processing load generated by the high volume of data. In this paper, we propose a method based on computational intelligence techniques to handle these problems, turning them into a single optimization problem. An artificial neural network is used as a classifier for event detection, along with an evolutionary algorithm to find the optimal subset of electrodes and data points that better represents the target event. The obtained results indicate our approach is a competitive and viable alternative for feature extraction in electroencephalograms, leading to high accuracy values and allowing the reduction of a significant amount of data.

## 23. Brain computer interfaces for cognitive enhancement in older people - challenges and applications: a systematic review

**Authors:** Ping-Chen Tsai, Asangaedem Akpan, K. Tang, Heba Lakany (2025)
**DOI/URL:** 10.1186/s12877-025-05676-4

Brain-computer interface (BCI) offers promising solutions to cognitive enhancement in older people. Despite the clear progress received, there is limited evidence of BCI implementation for rehabilitation. This systematic review addresses BCI applications and challenges in the standard practice of EEG-based neurofeedback (NF) training in healthy older people or older people with mild cognitive impairment (MCI). Articles were searched via MEDLINE, PubMed, SCOPUS, SpringerLink, and Web of Science. 16 studies between 1st January 2010 to 1st November 2024 are included after screening using PRISMA. The risk of bias, system design, and neurofeedback protocols are reviewed. The successful BCI applications in NF trials in older people were biased by the randomisation process and outcome measurement. Although the studies demonstrate promising results in effectiveness of research-grade BCI for cognitive enhancement in older people, it is premature to make definitive claims about widespread BCI usability and applicability. This review highlights the common issues in the field of EEG-based BCI for older people. Future BCI research could focus on trial design and BCI performance gaps between the old and the young to develop a robust BCI system that compensates for age-related declines in cognitive and motor functions.

## 24. Neurotechnology in Gaming: A Systematic Review of Visual Evoked Potential-Based Brain-Computer Interfaces

**Authors:** Aigerim Keutayeva, China Jesse Nwachukwu, Muslim Alaran, Zhenis Otarbay, B. Abibullaev (2025)
**DOI/URL:** 10.1109/ACCESS.2025.3564328

Brain-computer interfaces (BCIs) have received considerable attention in gaming, enabling innovative interactions with digital environments. Visual Evoked Potentials (VEPs)—robust, noninvasive neural responses to visual stimuli—offer high information transfer rates, making them particularly promising. This systematic review, guided by the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) framework, examines VEP-based BCIs in gaming. We searched the Web of Science and Google Scholar, identifying 16 347 studies from the past decade, with 46 selected for in-depth analysis after rigorous screening. The review explores VEP response modeling, electroencephalography (EEG) signal acquisition and processing, stimulation paradigms, and their gaming applications. These systems enhance accessibility for players with physical or cognitive impairments, support adaptive difficulty scaling, personalize gameplay, aid neurorehabilitation, and enable multiplayer interactions. However, challenges remain, including technical limitations, complex data interpretation, user adaptability, and ergonomic issues. Advances in signal processing, personalized calibration, and hybrid multimodal approaches could improve usability. Future research should focus on integrating VEP-based BCIs with emerging technologies, optimizing user comfort, and developing adaptive interaction models to enhance immersion and accessibility. By addressing these challenges and utilizing neuroscience and computational advancements, VEP-based BCIs promise to transform gaming into a more inclusive and immersive experience for diverse users.

## 25. A Systematic Review on Motor-Imagery Brain-Connectivity-Based Computer Interfaces

**Authors:** Lorenza Brusini, Francesca Stival, F. Setti, E. Menegatti, G. Menegaz, S. Storti (2021)
**DOI/URL:** 10.1109/thms.2021.3115094

This review article discusses the definition and implementation of brain–computer interface (BCI) system relying on brain connectivity (BC) and machine learning/deep learning (DL) for motor imagery (MI)-based applications. During the past few years, many approaches have been explored in terms of types of neurological sources of information, feature extraction, and intention prediction for BCI applications. Two novel aspects are becoming increasingly interesting for the BCI community: BC modeling and DL. The former aims at describing the interactions among different brain regions as connectivity patterns that reflect the dynamics of information flow either at rest or when performing a task. The latter is becoming pervasive for its capability of modeling and predicting complex data, where a huge amount of information is involved. In this scenario, we conducted a systematic literature review on BCI studies that led to the selection of 34 articles meeting all the required criteria. This provides evidence of the rapid growth of the topic over the past few years, though being still in its infancy. The last part of this article is dedicated to this new frontier of BCI that we call MI BC-based computer interfaces highlighting the potential of BC features. This, jointly with DL as enabling technology, has the potential of improving the performance of electroencephalography-based systems.

## 26. A Comparative Review of Detection Methods in SSVEP-Based Brain-Computer Interfaces

**Authors:** Amin Besharat, N. Samadzadehaghdam, Reyhaneh Afghan (2024)
**DOI/URL:** 10.1109/ACCESS.2024.3509275

Steady-state visually evoked potential (SSVEP) refers to the brain’s response to visual stimuli at different frequencies and is widely used in brain-computer interfaces (BCIs). Despite their potential, SSVEP-based BCIs face significant challenges in real-world applications, particularly in controlling assistive devices, prosthetics, and communication systems for individuals with disabilities. The challenges include suboptimal frequency detection accuracy and long calibration periods, which limit the effectiveness of SSVEPs and contribute to increased visual fatigue during extended sessions. This review addresses these challenges by offering an overview of feature extraction methods for SSVEP recognition. It includes mathematical explanations of the processes, highlights their strengths and limitations, compares them, and discusses future directions. Feature extraction techniques can be categorized into three groups: calibration-free, calibration-based, and deep learning. While calibration-free methods require minimal data, they typically achieve lower accuracy than calibration-based methods, which rely on training datasets to provide better accuracy and information transfer rates; however, the lengthy training sessions often make these algorithms unsuitable for everyday use. On the other hand, deep learning approaches have improved accuracy and adaptability by automatically extracting complex features from data and accommodating varying conditions, even with shorter time windows. However, they require large amounts of data for training to improve accuracy. To address this issue, both calibration-based and deep learning methods can benefit from transfer learning, which alleviates the need for extensive training data by sharing knowledge across subjects. This approach enhances recognition accuracy and reduces reliance on subject-specific training, ultimately making these methods more practical for real-world applications.

## 27. Online processing for motor imagery-based brain-computer interfaces relying on EEG

**Authors:** P. Arpaia, Antonio Esposito, Nicola Moccaldi, Angela Natalizio, M. Parvis (2023)
**DOI/URL:** 10.1109/I2MTC53148.2023.10176052

This manuscript reports a comparison among three possible strategies for online processing of electroencephalo-graphic signals, in terms of their impact on the online classification accuracy. The comparison was carried out in the framework of brain-computer interfaces based on motor imagery. Filter bank common spatial pattern was exploited as a standard feature extraction technique along with a support vector machine for classification of the brain signals. This machine learning-based algorithm was trained offline and evaluated on independent evaluation data by means of the online processing strategies. Benchmark dataset were used, so that the online processing performance was compared to reference offline performances compatible with literature (at least 74 % classification accuracy). Results suggest that it is convenient to use the bigger part of the imagery period in training the algorithm prior to online classification accuracy. Moreover, using an enlarging window for evaluation appeared to be the best strategy to remain close to reference mean accuracy.

## 28. Convolutional Neural Network with a Topographic Representation Module for EEG-Based Brain—Computer Interfaces

**Authors:** Xinbin Liang, Yaru Liu, Yang Yu, Kaixuan Liu, Yadong Liu, Zongtan Zhou (2023)
**DOI/URL:** 10.3390/brainsci13020268

Convolutional neural networks (CNNs) have shown great potential in the field of brain–computer interfaces (BCIs) due to their ability to directly process raw electroencephalogram (EEG) signals without artificial feature extraction. Some CNNs have achieved better classification accuracy than that of traditional methods. Raw EEG signals are usually represented as a two-dimensional (2-D) matrix composed of channels and time points, ignoring the spatial topological information of electrodes. Our goal is to make a CNN that takes raw EEG signals as inputs have the ability to learn spatial topological features and improve its classification performance while basically maintaining its original structure. We propose an EEG topographic representation module (TRM). This module consists of (1) a mapping block from raw EEG signals to a 3-D topographic map and (2) a convolution block from the topographic map to an output with the same size as the input. According to the size of the convolutional kernel used in the convolution block, we design two types of TRMs, namely TRM-(5,5) and TRM-(3,3). We embed the two TRM types into three widely used CNNs (ShallowConvNet, DeepConvNet and EEGNet) and test them on two publicly available datasets (the Emergency Braking During Simulated Driving Dataset (EBDSDD) and the High Gamma Dataset (HGD)). Results show that the classification accuracies of all three CNNs are improved on both datasets after using the TRMs. With TRM-(5,5), the average classification accuracies of DeepConvNet, EEGNet and ShallowConvNet are improved by 6.54%, 1.72% and 2.07% on the EBDSDD and by 6.05%, 3.02% and 5.14% on the HGD, respectively; with TRM-(3,3), they are improved by 7.76%, 1.71% and 2.17% on the EBDSDD and by 7.61%, 5.06% and 6.28% on the HGD, respectively. We improve the classification performance of three CNNs on both datasets through the use of TRMs, indicating that they have the capability to mine spatial topological EEG information. More importantly, since the output of a TRM has the same size as the input, CNNs with raw EEG signals as inputs can use this module without changing their original structures.

## 29. A dynamical graph-based feature extraction approach to enhance mental task classification in brain-computer interfaces

**Authors:** Shaotong Zhu, S. Hosni, Xiaofei Huang, Michael Wan, S. B. Borgheai, J. McLinden, Y. Shahriari, S. Ostadabbas (2022)
**DOI/URL:** 10.2139/ssrn.4170113

Graph theoretic approaches in analyzing spatiotemporal dynamics of brain activities are under-studied but could be very promising directions in developing effective brain-computer interfaces (BCIs). Many existing BCI systems use electroencephalogram (EEG) signals to record and decode human neural activities noninvasively. Often, however, the features extracted from the EEG signals ignore the topological information hidden in the EEG temporal dynamics. Moreover, existing graph theoretic approaches are mostly used to reveal the topological patterns of brain functional networks based on synchronization between signals from distinctive spatial regions, instead of interdependence between states at different timestamps. In this study, we present a robust fold-wise hyperparameter optimization framework utilizing a series of conventional graph-based measurements combined with spectral graph features and investigate its discriminative performance on classification of a designed mental task in 6 participants with amyotrophic lateral sclerosis (ALS). Across all of our participants, we reached an average accuracy of 71.1%±4.5% for mental task classification by combining the global graph-based measurements and the spectral graph features, higher than the conventional non-graph based feature performance (67.1%±7.5%). Compared to using either one of the graphic features (66.3%±6.5% for the eigenvalues and 65.9%±5.2% for the global graph features), our feature combination strategy shows considerable improvement in both accuracy and robustness performance. Our results indicate the feasibility and advantage of the presented fold-wise optimization framework utilizing graph-based features in BCI systems targeted at end-users.

## 30. EEG Signal Prediction for Motor Imagery Classification in Brain–Computer Interfaces

**Authors:** Ó. Gómez-Morales, D. Collazos-Huertas, A. Álvarez-Meza, C. Castellanos-Dominguez (2025)
**DOI/URL:** 10.3390/s25072259

Brain–computer interfaces (BCIs) based on motor imagery (MI) generally require EEG signals recorded from a large number of electrodes distributed across the cranial surface to achieve accurate MI classification. Not only does this entail long preparation times and high costs, but it also carries the risk of losing valuable information when an electrode is damaged, further limiting its practical applicability. In this study, a signal prediction-based method is proposed to achieve high accuracy in MI classification using EEG signals recorded from only a small number of electrodes. The signal prediction model was constructed using the elastic net regression technique, allowing for the estimation of EEG signals from 22 complete channels based on just 8 centrally located channels. The predicted EEG signals from the complete channels were used for feature extraction and MI classification. The results obtained indicate a notable efficacy of the proposed prediction method, showing an average performance of 78.16% in classification accuracy. The proposed method demonstrated superior performance compared to the traditional approach that used few-channel EEG and also achieved better results than the traditional method based on full-channel EEG. Although accuracy varies among subjects, from 62.30% to an impressive 95.24%, these data indicate the capability of the method to provide accurate estimates from a reduced set of electrodes. This performance highlights its potential to be implemented in practical MI-based BCI applications, thereby mitigating the time and cost constraints associated with systems that require a high density of electrodes.

## 31. Phase-Based EEG Analysis for Enhanced Imagined Speech Decoding in Brain-Computer Interfaces

**Authors:** Anand Mohan, R. S. Anand (2025)
**DOI/URL:** 10.1109/IC3ECSBHI63591.2025.10990955

Brain-computer interfaces (BCIs) enable direct communication between the brain and external devices. It provides possibilities for neurorehabilitation and assistive technologies. This study focuses on imagined speech, a challenging yet rising domain in BCI research, to decode inner speech signals from EEG data. Imagined speech aims to translate inner speech or imagined words into actionable signals without requiring overt muscle activity. Imagined speech decoding faces significant challenges, including low signal-to-noise ratios, complex inter-subject variability, and the difficulty of isolating distinct neural patterns related to specific imagined words. Phase-based feature extraction is explored to address these obstacles. The phase- based information of EEG signals, is more robust to amplitude fluctuations and noise interference. Extensive preprocessing is applied to filter out and isolate artifacts effectively. Phase-based features are then extracted from the preprocessed signals, and a machine learning model is applied to classify imagined speech accurately. Experimental results show the effectiveness of the phase-based method, showing improved accuracy in imagined word classification over traditional approaches. Hence, phase-based analysis is a powerful tool for advancing BCI performance in imagined speech applications.

## 32. Enhanced EEG signal classification in brain computer interfaces using hybrid deep learning models

**Authors:** Abir Das, Saurabh Singh, Jaejeung Kim, T. Ahanger, A. Pise (2025)
**DOI/URL:** 10.1038/s41598-025-07427-2

Brain-computer interfaces (BCIs) establish a communication pathway between the human brain and external devices by decoding neural signals. This study focuses on enhancing the classification of Motor Imagery (MI) within BCI systems by leveraging advanced machine learning and deep learning techniques. The accurate classification of electroencephalogram (EEG) data is crucial for enhancing BCI performance. The BCI architecture processes electroencephalography signals through three critical stages: data pre-processing, feature extraction, and classification. The research evaluates the performance of five traditional machine learning classifiers- K-Nearest Neighbors (KNN), Support Vector Classifier (SVC), Logistic Regression (LR), Random Forest (RF), and Naive Bayes (NB)-using the “PhysioNet EEG Motor Movement/Imagery Dataset”. This dataset encompasses EEG data from various motor tasks, including both actual and imagined movements. Among the traditional classifiers, Random Forest achieved the highest accuracy of 91%, underscoring its efficacy in motor imagery classification within BCI systems. In addition to conventional approaches, the study also explores deep learning techniques, with Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks yielding accuracies of 88.18% and 16.13%, respectively. However, the proposed hybrid model, which synergistically combines CNN and LSTM, significantly surpasses both traditional machine learning and individual deep learning methods, achieving an exceptional accuracy of 96.06%. This substantial improvement highlights the potential of hybrid deep learning models to advance the state of the art in BCI systems, offering a more robust and precise approach to motor imagery classification.

## 33. Generalization of Machine and Deep Learning Models for Brain-Computer Interfaces Across Sessions and Paradigms in a Completely Locked-In Patient

**Authors:** L. Garrote, Rute Bettencourt, João Perdiz, Gabriel Pires, Urbano J. Nunes (2025)
**DOI/URL:** 10.1109/RO-MAN63969.2025.11217899

Brain-Computer Interfaces (BCIs) are one of the few remaining communication options for individuals in a Completely Locked-In State (CLIS), where all voluntary motor functions are lost. However, decoding electroencephalographic (EEG) signals in CLIS is particularly challenging due to low signal-to-noise ratios, high intra- and inter-session variability, and cognitive fluctuations. In this study, we systematically evaluate classical and deep learning-based (DL) classification methods on a longitudinal P300-based BCI dataset acquired from a CLIS patient over ten months, comprising seven different stimulation paradigms.A systematic approach is followed to assess model generalization across BCI sessions and paradigms. Overall, more than 40 approaches are compared, including spatial filters for feature extraction with standard classifiers, as well as DL methods based on CNNs and Attention-based architectures. All methods are evaluated with raw input data and three different normalization strategies. Additionally, SMOTE data augmentation is applied to upsample the minority class. The results show high generalization performance across sessions and paradigms, with some approaches achieving nearly 100% performance. Normalization strategies significantly influence performance, while SMOTE often leads to performance degradation. These findings offer valuable insights for designing more robust BCI systems tailored to CLIS users, showing that collecting data across sessions and multiple BCI paradigms can improve BCI performance, while reducing or eliminating the need for per session calibration. Despite the very promising results, they are based on offline analysis. Thus, the best-performing approaches now require online validation for deployment in real-world CLIS scenarios.

## 34. Hierarchical attention enhanced deep learning achieves high precision motor imagery classification in brain computer interfaces

**Authors:** Zhen Chen, Ye Cao, Qiangqiang Fu, Liyang Hou (2025)
**DOI/URL:** 10.1038/s41598-025-17922-1

Motor imagery-based Brain-Computer Interfaces (BCIs) hold transformative potential for individuals with severe motor impairments, yet their clinical deployment remains constrained by the inherent complexity of electroencephalographic (EEG) signal decoding. This study presents a systematic investigation of hierarchical deep learning architectures for motor imagery classification, introducing a novel attention-enhanced convolutional-recurrent framework that achieves state-of-the-art accuracy of 97.2477% on a custom four-class motor imagery dataset comprising 4,320 trials from 15 participants. By synergistically integrating spatial feature extraction through convolutional layers, temporal dynamics modeling via long short-term memory networks, and selective attention mechanisms for adaptive feature weighting, our approach significantly outperforms conventional methods while providing interpretable insights into the spatiotemporal signatures of motor imagery. Beyond demonstrating competitive performance, this work elucidates the critical role of attention mechanisms in capturing task-relevant neural patterns amidst the high-dimensional, non-stationary nature of EEG signals. Our findings demonstrate that biomimetic computational architectures that mirror the brain’s own selective processing strategies can substantially enhance BCI reliability, offering immediate implications for neurorehabilitation technologies and broader applications in restorative neuroscience. Our code is available at https://github.com/Laboratory-EverythingAI/-EEG_Classification.

## 35. EEG feature extraction methods in motor imagery brain computer interface

**Authors:** Fengge Bao, Weiheng Liu (2023)
**DOI/URL:** 10.1117/12.2667875

Brain-computer interface (BCI) is a link between the human brain and a computer or other peripheral devices for communication and control. The most frequently utilized BCI paradigms at the time are motor imagination (MI) BCI. In the procedure of MI-BCI, one of the most important roles is the feature extraction of EEG signals. This article examines various feature extraction approaches in four distinct domains: time, frequency, time-frequency, and spatial. Various approaches are introduced in each domain, including the ERD/ERS computation, the FFT method, the Wavelet Transform (WT), the Discrete Wavelet Transform (DWT), Common Spatial Patterns (CSP), and Sub-band Common Spatial Patterns (SBCSP). This paper also compares the advantages and disadvantages of different methods in practical application, which can provide reference for future research.

## 36. EEG-based brain-computer interface methods with the aim of rehabilitating advanced stage ALS patients

**Authors:** Alireza Pirasteh, Manouchehr Shamseini Ghiyasvand, Majid Pouladian (2024)
**DOI/URL:** 10.1080/17483107.2024.2316312

Abstract Amyotrophic Lateral Sclerosis (ALS) is a neurodegenerative disease that leads to progressive muscle weakness and paralysis, ultimately resulting in the loss of ability to communicate and control the environment. EEG-based Brain-Computer Interface (BCI) methods have shown promise in providing communication and control with the aim of rehabilitating ALS patients. In particular, P300-based BCI has been widely studied and used for ALS rehabilitation. Other EEG-based BCI methods, such as Motor Imagery (MI) based BCI and Hybrid BCI, have also shown promise in ALS rehabilitation. Nonetheless, EEG-based BCI methods hold great potential for improvement. This review article introduces and reviews FFT, WPD, CSP, CSSP, CSP, and GC feature extraction methods. The Common Spatial Pattern (CSP) is an efficient and common technique for extracting data properties used in BCI systems. In addition, Linear Discriminant Analysis (LDA), Support Vector Machine (SVM), Neural Networks (NN), and Deep Learning (DL) classification methods were introduced and reviewed. SVM is the most appropriate classifier due to its insensitivity to the curse of dimensionality. Also, DL is used in the design of BCI systems and is a good choice for BCI systems based on motor imagery with big datasets. Despite the progress made in the field, there are still challenges to overcome, such as improving the accuracy and reliability of EEG signal detection and developing more intuitive and user-friendly interfaces By using BCI, disabled patients can communicate with their caregivers and control their environment using various devices, including wheelchairs, and robotic arms. IMPLICATIONS FOR REHABILITATION Electroencephalography (EEG)-based Brain-Computer Interface (BCI) methods have shown promise in providing communication and control for Amyotrophic Lateral Sclerosis (ALS) patients. EEG constitutes the most significant input in BCIs and can be successfully used in the neuro-rehabilitation of patients with stroke symptoms and amyotrophic lateral sclerosis. EEG based BCIs have the potential to provide a means of communication and control for individuals with severe disabilities.a variety of EEG-based BCI methods have been developed with the aim of rehabilitating disabled patients.

## 37. Joint multi-feature extraction and transfer learning in motor imagery brain computer interface.

**Authors:** Miao Cai, Jie Hong (2024)
**DOI/URL:** 10.1080/10255842.2024.2404541

Motor imagery brain computer interface (BCI) systems are considered one of the most crucial paradigms and have received extensive attention from researchers worldwide. However, the non-stationary from subject-to-subject transfer is a substantial challenge for robust BCI operations. To address this issue, this paper proposes a novel approach that integrates joint multi-feature extraction, specifically combining common spatial patterns (CSP) and wavelet packet transforms (WPT), along with transfer learning (TL) in motor imagery BCI systems. This approach leverages the time-frequency characteristics of WPT and the spatial characteristics of CSP while utilizing transfer learning to facilitate EEG identification for target subjects based on knowledge acquired from non-target subjects. Using dataset IVa from BCI Competition III, our proposed approach achieves an impressive average classification accuracy of 93.4%, outperforming five kinds of state-of-the-art approaches. Furthermore, it offers the advantage of enabling the design of various auxiliary problems to learn different aspects of the target problem from unlabeled data through transfer learning, thereby facilitating the implementation of innovative ideas within our proposed approach. Simultaneously, it demonstrates that integrating CSP and WPT while transferring knowledge from other subjects is highly effective in enhancing the average classification accuracy of EEG signals and it provides a novel solution to address subject-to-subject transfer challenges in motor imagery BCI systems.

## 38. Feature Interpretability in Motor Imagery Brain Computer Interfaces: A Meta-Analysis Across Connectivity, Spatial Filtering, and Riemannian Methods.

**Authors:** Juliana Gonzalez-Astudillo, Fabrizio de Vico Fallani (2025)
**DOI/URL:** 10.1177/21580014251392230

Introduction: Brain-computer interfaces (BCIs) translate brain activity into commands, enabling applications in communication, control, and neurorehabilitation. A major challenge in noninvasive BCIs is balancing classification performance with interpretability, as many approaches prioritize accuracy while overlooking the neural mechanisms underlying their predictions. Methods: In this study, we conduct a meta-analysis of feature interpretability across widely used methods in motor imagery (MI)-based BCIs, including power spectral density, common spatial patterns (CSP), Riemannian geometry, and functional connectivity. Specifically, we explore how network topology and spatial organization contribute to MI decoding by investigating brain network lateralization. Results: Through evaluations on multiple EEG-based BCI datasets, our results confirm the superior classification performance of CSP and Riemannian methods. However, network lateralization provides stronger neurophysiological plausibility, revealing robust lateralization patterns in sensorimotor and frontal regions contralateral to imagined movements. Discussion: These findings underscore the potential of connectivity-based features as a complementary tool for enhancing interpretability, supporting the development of more transparent and clinically relevant MI-based BCIs. Impact Statement This study addresses a critical gap in motor imagery-based brain-computer interfaces (BCIs) by systematically evaluating and comparing the interpretability of widely used methods, including power spectral density, common spatial pattern, Riemannian geometry, and functional connectivity. By analyzing these approaches across wide-ranging datasets, we offer valuable insights into the underlying neural mechanisms driving their performance. Our findings contribute to enhancing the transparency and biological relevance of BCI systems, ultimately advancing the development of more clinically meaningful and neurophysiologically interpretable BCIs.

## 39. Feature Selection Combining Filter and Wrapper Methods for Motor-Imagery Based Brain-Computer Interfaces

**Authors:** Hao Sun, Jing Jin, Ren Xu, A. Cichocki (2021)
**DOI/URL:** 10.1142/S0129065721500404

Motor imagery (MI) based brain-computer interfaces help patients with movement disorders to regain the ability to control external devices. Common spatial pattern (CSP) is a popular algorithm for feature extraction in decoding MI tasks. However, due to noise and nonstationarity in electroencephalography (EEG), it is not optimal to combine the corresponding features obtained from the traditional CSP algorithm. In this paper, we designed a novel CSP feature selection framework that combines the filter method and the wrapper method. We first evaluated the importance of every CSP feature by the infinite latent feature selection method. Meanwhile, we calculated Wasserstein distance between feature distributions of the same feature under different tasks. Then, we redefined the importance of every CSP feature based on two indicators mentioned above, which eliminates half of CSP features to create a new CSP feature subspace according to the new importance indicator. At last, we designed the improved binary gravitational search algorithm (IBGSA) by rebuilding its transfer function and applied IBGSA on the new CSP feature subspace to find the optimal feature set. To validate the proposed method, we conducted experiments on three public BCI datasets and performed a numerical analysis of the proposed algorithm for MI classification. The accuracies were comparable to those reported in related studies and the presented model outperformed other methods in literature on the same underlying data.

## 40. PyNoetic: A modular python framework for no-code development of EEG brain-computer interfaces

**Authors:** Gursimran Singh, Aviral Chharia, Rahul Upadhyay, Vinay Kumar, Luca Longo (2025)
**DOI/URL:** 10.1371/journal.pone.0327791

Electroencephalography (EEG)-based Brain-Computer Interfaces (BCIs) have emerged as a transformative technology with applications spanning robotics, virtual reality, medicine, and rehabilitation. However, existing BCI frameworks face several limitations, including a lack of stage-wise flexibility essential for experimental research, steep learning curves for researchers without programming expertise, elevated costs due to reliance on proprietary software, and a lack of all-inclusive features leading to the use of multiple external tools affecting research outcomes. To address these challenges, we present PyNoetic, a modular BCI framework designed to cater to the diverse needs of BCI research. PyNoetic is one of the very few frameworks in Python that encompasses the entire BCI design pipeline, from stimulus presentation and data acquisition to channel selection, filtering, feature extraction, artifact removal, and finally simulation and visualization. Notably, PyNoetic introduces an intuitive and end-to-end GUI coupled with a unique pick-and-place configurable flowchart for no-code BCI design, making it accessible to researchers with minimal programming experience. For advanced users, it facilitates the seamless integration of custom functionalities and novel algorithms with minimal coding, ensuring adaptability at each design stage. PyNoetic also includes a rich array of analytical tools such as machine learning models, brain-connectivity indices, systematic testing functionalities via simulation, and evaluation methods of novel paradigms. PyNoetic’s strengths lie in its versatility for both offline and real-time BCI development, which streamlines the design process, allowing researchers to focus on more intricate aspects of BCI development and thus accelerate their research endeavors.

## 41. Exploring Feature Selection and Classification Techniques to Improve the Performance of an Electroencephalography-Based Motor Imagery Brain–Computer Interface System

**Authors:** Humaun Kabir, Nadim Ibne Akhtar, Nishat Tasnim, Abu Saleh Musa Miah, Hyoun-Sup Lee, Si-Woong Jang, Jungpil Shin (2024)
**DOI/URL:** 10.3390/s24154989

The accuracy of classifying motor imagery (MI) activities is a significant challenge when using brain–computer interfaces (BCIs). BCIs allow people with motor impairments to control external devices directly with their brains using electroencephalogram (EEG) patterns that translate brain activity into control signals. Many researchers have been working to develop MI-based BCI recognition systems using various time-frequency feature extraction and classification approaches. However, the existing systems still face challenges in achieving satisfactory performance due to large amount of non-discriminative and ineffective features. To get around these problems, we suggested a multiband decomposition-based feature extraction and classification method that works well, along with a strong feature selection method for MI tasks. Our method starts by splitting the preprocessed EEG signal into four sub-bands. In each sub-band, we then used a common spatial pattern (CSP) technique to pull out narrowband-oriented useful features, which gives us a high-dimensional feature vector. Subsequently, we utilized an effective feature selection method, Relief-F, which reduces the dimensionality of the final features. Finally, incorporating advanced classification techniques, we classified the final reduced feature vector. To evaluate the proposed model, we used the three different EEG-based MI benchmark datasets, and our proposed model achieved better performance accuracy than existing systems. Our model’s strong points include its ability to effectively reduce feature dimensionality and improve classification accuracy through advanced feature extraction and selection methods.

## 42. A Systematic Deep Learning Model Selection for P300-Based Brain–Computer Interfaces

**Authors:** B. Abibullaev, A. Zollanvari (2021)
**DOI/URL:** 10.1109/TSMC.2021.3051136

Predicting attention-modulated brain responses is a major area of investigation in brain–computer interface (BCI) research that aims to translate neural activities into useful control and communication commands. Such studies involve collecting electroencephalographic (EEG) data from subjects to train classifiers for decoding users’ mental states. However, various sources of inter or intrasubject variabilities in brain signals render training classifiers in BCI systems challenging. From a machine learning perspective, this model training generally follows a common methodology: 1) apply some type of feature extraction, which can be time-consuming and may require domain knowledge and 2) train a classifier using extracted features. The advent of deep learning technologies has offered unprecedented opportunities to not only construct remarkably accurate classifiers but also to integrate the feature extraction stage into the classifier construction. Although integrating feature extraction, which is generally domain-dependent, into the classifier construction is a considerable advantage of deep learning models, the process of architecture selection for BCIs generally depends on domain knowledge. In this study, we examine the feasibility of conducting a systematic model selection combined with mainstream deep learning architectures to construct accurate classifiers for decoding P300 event-related potentials. In particular, we present the results of 232 convolutional neural networks (CNNs) (4 datasets $\times58$ structures), 36 long short-term memory cells (LSTMs) (4 datasets $\times9$ structures), and 320 hybrid CNN-LSTM models (4 datasets $\times80$ structures) of varying complexity. Our empirical results show that in the classification of P300 waveforms, the constructed predictive models can outperform the current state-of-the-art deep learning architectures, which are partially or entirely inspired by domain knowledge. The source codes and constructed models are available at https://github.com/berdakh/P3Net.

## 43. Enhancing Motor Imagery based Brain Computer Interfaces for Stroke Rehabilitation

**Authors:** Saher Soni, Shivam Chaudhary, K. Miyapuram (2024)
**DOI/URL:** 10.1145/3632410.3632441

Globally, the prevalence of disabilities among stroke survivors exceeds 80%, with upper-limb movement impairments affecting over 85% of individuals. To address this challenge, motor imagery (MI) based brain-computer interface (BCI) has emerged as a promising approach for translating the imagined motor intentions of individuals into control signals for external devices. Electroencephalography (EEG) signals are commonly used in MI-BCIs due to their non-invasiveness, portability, high temporal resolution, and affordability. The present study utilized the publicly available Electroencephalography Motor Movement/Imagery Dataset (EEGMMIDB), comprising 64-channel EEG recordings from 109 participants sampled at 160 Hz. The aim was to classify between the opening/closing of palms and feet using the Long Short Term Memory (LSTM) network directly on cleaned EEG signals, bypassing traditional feature-extraction methods that are computationally intensive and time-consuming. We achieved an average classification accuracy of 71.2% across subjects by tuning the hyperparameters related to epochs and segment length. This research emphasizes the efficacy of deep learning approaches in generating robust control signals for predicting motor intentions using EEG signals, eliminating the necessity of laborious feature extraction methods. By leveraging deep learning models, MI-BCI devices can advance neuro-rehabilitation, especially in stroke, by providing motor assistance, enabling patients to execute movements solely through the power of imagination.

## 44. MOCNN: A Multiscale Deep Convolutional Neural Network for ERP-Based Brain-Computer Interfaces

**Authors:** Jing Jin, Ruitian Xu, Ian Daly, Xueqing Zhao, Xingyu Wang, Andrzej Cichocki (2024)
**DOI/URL:** 10.1109/TCYB.2024.3390805

Event-related potentials (ERPs) reflect neurophysiological changes of the brain in response to external events and their associated underlying complex spatiotemporal feature information is governed by ongoing oscillatory activity within the brain. Deep learning methods have been increasingly adopted for ERP-based brain-computer interfaces (BCIs) due to their excellent feature representation abilities, which allow for deep analysis of oscillatory activity within the brain. Features with higher spatiotemporal frequencies usually represent detailed and localized information, while features with lower spatiotemporal frequencies usually represent global structures. Mining EEG features from multiple spatiotemporal frequencies is conducive to obtaining more discriminative information. A multiscale feature fusion octave convolution neural network (MOCNN) is proposed in this article. MOCNN divides the ERP signals into high-, medium- and low-frequency components corresponding to different resolutions and processes them in different branches. By adding mid- and low-frequency components, the feature information used by MOCNN can be enriched, and the required amount of calculations can be reduced. After successive feature mapping using temporal and spatial convolutions, MOCNN realizes interactive learning among different components through the exchange of feature information among branches. Classification is accomplished by feeding the fused deep spatiotemporal features from various components into a fully connected layer. The results, obtained on two public datasets and a self-collected ERP dataset, show that MOCNN can achieve state-of-the-art ERP classification performance. In this study, the generalized concept of octave convolution is introduced into the field of ERP-BCI research, which allows effective spatiotemporal features to be extracted from multiscale networks through branch width optimization and information interaction at various scales.

## 45. Review of epileptic EEG feature extraction methods

**Authors:** Yongqiang Yu (2022)
**DOI/URL:** 10.54097/fcis.v1i3.1907

Epilepsy is a typical non-contagious chronic disease of the brain. Electroencephalogram (EEG) is an important tool for clinical epilepsy diagnosis, so the use of machine learning and deep learning models to diagnose and treat epilepsy has become a popular method, of which epilepsy EEG feature extraction is the basis for establishing a model. In this paper, several methods of epilepsy EEG feature extraction are summarized from four aspects: time domain analysis, frequency domain analysis, time frequency analysis and nonlinear dynamics, and each method is systematically summarized.

## 46. Improving the Performance of Electrotactile Brain–Computer Interface Using Machine Learning Methods on Multi-Channel Features of Somatosensory Event-Related Potentials

**Authors:** Marija Novičić, O. Djordjević, Vera Miler-Jerković, L. Konstantinović, Andrej M Savić (2024)
**DOI/URL:** 10.3390/s24248048

Traditional tactile brain–computer interfaces (BCIs), particularly those based on steady-state somatosensory–evoked potentials, face challenges such as lower accuracy, reduced bit rates, and the need for spatially distant stimulation points. In contrast, using transient electrical stimuli offers a promising alternative for generating tactile BCI control signals: somatosensory event-related potentials (sERPs). This study aimed to optimize the performance of a novel electrotactile BCI by employing advanced feature extraction and machine learning techniques on sERP signals for the classification of users’ selective tactile attention. The experimental protocol involved ten healthy subjects performing a tactile attention task, with EEG signals recorded from five EEG channels over the sensory–motor cortex. We employed sequential forward selection (SFS) of features from temporal sERP waveforms of all EEG channels. We systematically tested classification performance using machine learning algorithms, including logistic regression, k-nearest neighbors, support vector machines, random forests, and artificial neural networks. We explored the effects of the number of stimuli required to obtain sERP features for classification and their influence on accuracy and information transfer rate. Our approach indicated significant improvements in classification accuracy compared to previous studies. We demonstrated that the number of stimuli for sERP generation can be reduced while increasing the information transfer rate without a statistically significant decrease in classification accuracy. In the case of the support vector machine classifier, we achieved a mean accuracy over 90% for 10 electrical stimuli, while for 6 stimuli, the accuracy decreased by less than 7%, and the information transfer rate increased by 60%. This research advances methods for tactile BCI control based on event-related potentials. This work is significant since tactile stimulation is an understudied modality for BCI control, and electrically induced sERPs are the least studied control signals in reactive BCIs. Exploring and optimizing the parameters of sERP elicitation, as well as feature extraction and classification methods, is crucial for addressing the accuracy versus speed trade-off in various assistive BCI applications where the tactile modality may have added value.

## 47. Instrumentation, Measurement, and Signal Processing in Electroencephalography-Based Brain-Computer Interfaces: Situations and Prospects

**Authors:** Zifan Xue, Yunfan Zhang, Hui Li, Hongbin Chen, Shengnan Shen, Hejun Du (2024)
**DOI/URL:** 10.1109/TIM.2024.3417598

Proper signal measurement and processing are crucial in electroencephalography (EEG)-based brain-computer interfaces (BCIs), as they form the basis of brain insight and precise BCI control. Currently, extensive papers have reported their progress and successful applications in this field. Nevertheless, a systematic review of progress and challenges in this field is still lacking, and the research challenges have not been thoroughly discussed. Herein, a systematic review of instrumentation, measurement, and signal processing in EEG-based BCIs is proposed. First, EEG signals and the application of EEG-based BCIs are introduced. Then, the components and products related to the measurement, processing, and control of EEG signals are analyzed. Specifically, detailed discussions are provided on the measurement methods and results. Moreover, typical EEG paradigms and the processing methods of EEG signals are analyzed. Finally, four major challenges in this field are proposed and discussed: BCIs for acquiring high-quality EEG signals, EEG-based BCIs for long-term tasks, EEG-based BCIs for mobile or dynamic scenarios, and EEG-based BCIs with user-centered designs. This study offers practitioners a comprehensive guide for the measurement and processing of EEG signals, encompassing instrument selection, methodology implementation, current challenges, and future considerations.

## 48. A novel strategy for driving car brain–computer interfaces: Discrimination of EEG-based visual-motor imagery

**Authors:** Zhouzhou Zhou, Anmin Gong, Qian Qian, Lei Su, Lei Zhao, Yunfa Fu (2021)
**DOI/URL:** 10.1515/tnsci-2020-0199

Abstract A brain–computer interface (BCI) based on kinesthetic motor imagery has a potential of becoming a groundbreaking technology in a clinical setting. However, few studies focus on a visual-motor imagery (VMI) paradigm driving BCI. The VMI-BCI feature extraction methods are yet to be explored in depth. In this study, a novel VMI-BCI paradigm is proposed to execute four VMI tasks: imagining a car moving forward, reversing, turning left, and turning right. These mental strategies can naturally control a car or robot to move forward, backward, left, and right. Electroencephalogram (EEG) data from 25 subjects were collected. After the raw EEG signal baseline was corrected, the alpha band was extracted using bandpass filtering. The artifacts were removed by independent component analysis. Then, the EEG average instantaneous energy induced by VMI (VMI-EEG) was calculated using the Hilbert–Huang transform (HHT). The autoregressive model was extracted to construct a 12-dimensional feature vector to a support vector machine suitable for small sample classification. This was classified into two-class tasks: visual imagination of driving the car forward versus reversing, driving forward versus turning left, driving forward versus turning right, reversing versus turning left, reversing versus turning right, and turning left versus turning right. The results showed that the average classification accuracy of these two-class tasks was 62.68 ± 5.08%, and the highest classification accuracy was 73.66 ± 6.80%. The study showed that EEG features of O1 and O2 electrodes in the occipital region extracted by HHT were separable for these VMI tasks.

## 49. Systematic Review of EEG-Based Imagined Speech Classification Methods

**Authors:** Salwa Alzahrani, H. Banjar, Rsha Mirza (2024)
**DOI/URL:** 10.3390/s24248168

This systematic review examines EEG-based imagined speech classification, emphasizing directional words essential for development in the brain–computer interface (BCI). This study employed a structured methodology to analyze approaches using public datasets, ensuring systematic evaluation and validation of results. This review highlights the feature extraction techniques that are pivotal to classification performance. These include deep learning, adaptive optimization, and frequency-specific decomposition, which enhance accuracy and robustness. Classification methods were explored by comparing traditional machine learning with deep learning and emphasizing the role of brain lateralization in imagined speech for effective recognition and classification. This study discusses the challenges of generalizability and scalability in imagined speech recognition, focusing on subject-independent approaches and multiclass scalability. Performance benchmarking across various datasets and methodologies revealed varied classification accuracies, reflecting the complexity and variability of EEG signals. This review concludes that challenges remain despite progress, particularly in classifying directional words. Future research directions include improved signal processing techniques, advanced neural network architectures, and more personalized, adaptive BCI systems. This review is critical for future efforts to develop practical communication tools for individuals with speech and motor impairments using EEG-based BCIs.

## 50. Deep Temporal-Spatial Feature Learning for Motor Imagery-Based Brain–Computer Interfaces

**Authors:** Junjian Chen, Zhuliang Yu, Z. Gu, Yuanqing Li (2020)
**DOI/URL:** 10.1109/TNSRE.2020.3023417

Motor imagery (MI) decoding is an important part of brain-computer interface (BCI) research, which translates the subject’s intentions into commands that external devices can execute. The traditional methods for discriminative feature extraction, such as common spatial pattern (CSP) and filter bank common spatial pattern (FBCSP), have only focused on the energy features of the electroencephalography (EEG) and thus ignored the further exploration of temporal information. However, the temporal information of spatially filtered EEG may be critical to the performance improvement of MI decoding. In this paper, we proposed a deep learning approach termed filter-bank spatial filtering and temporal-spatial convolutional neural network (FBSF-TSCNN) for MI decoding, where the FBSF block transforms the raw EEG signals into an appropriate intermediate EEG presentation, and then the TSCNN block decodes the intermediate EEG signals. Moreover, a novel stage-wise training strategy is proposed to mitigate the difficult optimization problem of the TSCNN block in the case of insufficient training samples. Firstly, the feature extraction layers are trained by optimization of the triplet loss. Then, the classification layers are trained by optimization of the cross-entropy loss. Finally, the entire network (TSCNN) is fine-tuned by the back-propagation (BP) algorithm. Experimental evaluations on the BCI IV 2a and SMR-BCI datasets reveal that the proposed stage-wise training strategy yields significant performance improvement compared with the conventional end-to-end training strategy, and the proposed approach is comparable with the state-of-the-art method.

## 51. Open multi-session and multi-task EEG cognitive Dataset for passive brain-computer Interface Applications

**Authors:** Marcel F. Hinss, E. Jahanpour, B. Somon, Lou Pluchon, F. Dehais, R. Roy (2023)
**DOI/URL:** 10.1038/s41597-022-01898-y

Brain-Computer Interfaces and especially passive Brain-Computer interfaces (pBCI), with their ability to estimate and monitor user mental states, are receiving increasing attention from both the fundamental research and the applied research and development communities. Testing new pipelines and benchmarking classifiers and feature extraction algorithms is central to further research within this domain. Unfortunately, data sharing in pBCI research is still scarce. The COG-BCI database encompasses the recordings of 29 participants over 3 separate sessions with 4 different tasks (MATB, N-Back, PVT, Flanker) designed to elicit different mental states, for a total of over 100 hours of open EEG data. This dataset was validated on a subjective, behavioral and physiological level, to ensure its usefulness to the pBCI community. Furthermore, a proof of concept is given with an example of mental workload estimation pipeline and results, to ensure that the data can be used for the design and evaluation of pBCI pipelines. This body of work presents a large effort to promote the use of pBCIs in an open science framework.

## 52. Exploring inter-trial coherence for inner speech classification in EEG-based brain–computer interface

**Authors:** Diego Lopez-Bernal, David C. Balderas, Pedro Ponce, Arturo Molina (2024)
**DOI/URL:** 10.1088/1741-2552/ad3f50

Objective. In recent years, electroencephalogram (EEG)-based brain–computer interfaces (BCIs) applied to inner speech classification have gathered attention for their potential to provide a communication channel for individuals with speech disabilities. However, existing methodologies for this task fall short in achieving acceptable accuracy for real-life implementation. This paper concentrated on exploring the possibility of using inter-trial coherence (ITC) as a feature extraction technique to enhance inner speech classification accuracy in EEG-based BCIs. Approach. To address the objective, this work presents a novel methodology that employs ITC for feature extraction within a complex Morlet time-frequency representation. The study involves a dataset comprising EEG recordings of four different words for ten subjects, with three recording sessions per subject. The extracted features are then classified using k-nearest-neighbors (kNNs) and support vector machine (SVM). Main results. The average classification accuracy achieved using the proposed methodology is 56.08% for kNN and 59.55% for SVM. These results demonstrate comparable or superior performance in comparison to previous works. The exploration of inter-trial phase coherence as a feature extraction technique proves promising for enhancing accuracy in inner speech classification within EEG-based BCIs. Significance. This study contributes to the advancement of EEG-based BCIs for inner speech classification by introducing a feature extraction methodology using ITC. The obtained results, on par or superior to previous works, highlight the potential significance of this approach in improving the accuracy of BCI systems. The exploration of this technique lays the groundwork for further research toward inner speech decoding.

## 53. Hybrid EEG-fNIRS Brain Computer Interface Based on Common Spatial Pattern by Using EEG-Informed General Linear Model

**Authors:** Yunyuan Gao, Biao Jia, Michael Houston, Yingchun Zhang (2023)
**DOI/URL:** 10.1109/TIM.2023.3276509

Hybrid brain–computer interfaces (BCI) utilizing the high temporal resolution of electroencephalography (EEG) and the high spatial resolution of functional near-infrared spectroscopy (fNIRS) are preferred over single-modal BCIs. However, due to the large dimensionality of the multiclass statistical features commonly used in fNIRS signals, it is easy to cause overfitting of the EEG-fNIRS hybrid BCI classifier. Therefore, a low-dimensional feature extraction method for fNIRS based on the EEG-informed fNIRS general linear model (GLM) analysis is proposed in this article. First, a regression coefficient matrix is obtained by using the EEG-informed fNIRS GLM with a time window added, and the common spatial pattern (CSP) features of this regression coefficient matrix are extracted as the fNIRS features. Finally, the fNIRS features were combined with the CSP features extracted from the optimal narrowband of EEG as hybrid features, and the support vector machine (SVM) method is used to classify the samples with hybrid features. The proposed method was tested on a publicly available motor imagery dataset. The classification accuracy using fNIRS signals alone reached 68.79% [oxygenated hemoglobin (HbO)] and 68.62% [deoxygenated hemoglobin (HbR)], and the classification accuracy of combining EEG-fNIRS features reached 79.48%, which was higher than other existing methods using the same dataset. By using this fNIRS feature extraction method, the problem of poor performance of CSP on fNIRS signals is solved, which not only enriches the processing methods of fNIRS signals but also improves the classification accuracy of hybrid EEG-fNIRS BCI in motor imagery tasks.

## 54. EEG-TCNTransformer: A Temporal Convolutional Transformer for Motor Imagery Brain–Computer Interfaces

**Authors:** Anh Hoang Phuc Nguyen, Oluwabunmi Oyefisayo, Maximilian Achim Pfeffer, Sai-Ho Ling (2024)
**DOI/URL:** 10.3390/signals5030034

In brain–computer interface motor imagery (BCI-MI) systems, convolutional neural networks (CNNs) have traditionally dominated as the deep learning method of choice, demonstrating significant advancements in state-of-the-art studies. Recently, Transformer models with attention mechanisms have emerged as a sophisticated technique, enhancing the capture of long-term dependencies and intricate feature relationships in BCI-MI. This research investigates the performance of EEG-TCNet and EEG-Conformer models, which are trained and validated using various hyperparameters and bandpass filters during preprocessing to assess improvements in model accuracy. Additionally, this study introduces EEG-TCNTransformer, a novel model that integrates the convolutional architecture of EEG-TCNet with a series of self-attention blocks employing a multi-head structure. EEG-TCNTransformer achieves an accuracy of 83.41% without the application of bandpass filtering.

## 55. Fuzzy Divergence Based Analysis for Eeg Drowsiness Detection Brain Computer Interfaces

**Authors:** Tharun Kumar Reddy, Vipul Arora, L. Behera, Yu-kai Wang, Chin-Teng Lin (2020)
**DOI/URL:** 10.1109/FUZZ48607.2020.9177833

EEG signals can be processed and classified into commands for brain-computer interface (BCI). Stable deciphering of EEG is one of the leading challenges in BCI design owing to low signal to noise ratio and non-stationarities. Presence of non-stationarities in the EEG signals significantly perturb the feature distribution thus deteriorating the performance of Brain Computer Interface. Stationary Subspace methods discover subspaces in which data distribution remains steady over time. In this paper, we develop novel spatial filtering based feature extraction methods for dealing with nonstationarity in EEG signals from a drowsiness detection problem (a machine learning regression problem). The proposed method: DivOVR-FuzzyCSP-WS based features clearly outperformed fuzzy CSP based baseline features in terms of both RMSE and CC performance metrics. It is hoped that the proposed feature extraction method based on DivOVR-FuzzyCSP-WS will bring in a lot of interest in researchers working in developing algorithms for signal processing, in general, for BCI regression problems.

## 56. Brain-Computer Interface: Feature Extraction and Classification of Motor Imagery-Based Cognitive Tasks

**Authors:** H. Nisar, Kee Wee Boon, Yeap Kim Ho, Teoh Shen Khang (2022)
**DOI/URL:** 10.1109/i2cacis54679.2022.9815460

Decoding motor imagery (MI) signals accurately is important for Brain-Computer Interface (BCI) systems for healthcare applications. Electroencephalography (EEG) decoding is a challenging task because of its complexity, and dynamic nature. By improving EEG signal classification, the performance of MI-based BCI can be enhanced. In this paper, five features (Band Power (BP), Approximate Entropy (ApEn), statistical features, wavelet-based features, and Common Spatial Pattern (CSP)) are extracted from EEG signals. For classification, Decision Tree (DT), Random Forest (RF), Support Vector Machine (SVM), K-Nearest Neighbors (KNN), and Artificial Neural Network (ANN) are used. These methods are tested on a publicly available Physionet motor imagery database. The EEG signals are recorded from 64 channels for 50 subjects, while the subject is performing four different MI tasks. The proposed method achieved an accuracy of 98.53% for left and right hands MI tasks with ApEn feature (overlapping ratio~ 0.8) and SVM classifier. Hence the proposed method shows better results than several EEG MI classification methods proposed in the literature.

## 57. Methods for motion artifact reduction in online brain-computer interface experiments: a systematic review

**Authors:** Mathias Schmoigl-Tonis, Christoph Schranz, Gernot R. Müller-Putz (2023)
**DOI/URL:** 10.3389/fnhum.2023.1251690

Brain-computer interfaces (BCIs) have emerged as a promising technology for enhancing communication between the human brain and external devices. Electroencephalography (EEG) is particularly promising in this regard because it has high temporal resolution and can be easily worn on the head in everyday life. However, motion artifacts caused by muscle activity, fasciculation, cable swings, or magnetic induction pose significant challenges in real-world BCI applications. In this paper, we present a systematic review of methods for motion artifact reduction in online BCI experiments. Using the PRISMA filter method, we conducted a comprehensive literature search on PubMed, focusing on open access publications from 1966 to 2022. We evaluated 2,333 publications based on predefined filtering rules to identify existing methods and pipelines for motion artifact reduction in EEG data. We present a lookup table of all papers that passed the defined filters, all used methods, and pipelines and compare their overall performance and suitability for online BCI experiments. We summarize suitable methods, algorithms, and concepts for motion artifact reduction in online BCI applications, highlight potential research gaps, and discuss existing community consensus. This review aims to provide a comprehensive overview of the current state of the field and guide researchers in selecting appropriate methods for motion artifact reduction in online BCI experiments.

## 58. Decoding Multi-Brain Motor Imagery From EEG Using Coupling Feature Extraction and Few-Shot Learning

**Authors:** Li Zhu, Youyang Liu, Riheng Liu, Yong Peng, Jianting Cao, Junhua Li, Wanzeng Kong (2023)
**DOI/URL:** 10.1109/TNSRE.2023.3336356

Electroencephalography (EEG)-based motor imagery (MI) is one of brain computer interface (BCI) paradigms, which aims to build a direct communication pathway between human brain and external devices by decoding the brain activities. In a traditional way, MI BCI replies on a single brain, which suffers from the limitations, such as low accuracy and weak stability. To alleviate these limitations, multi-brain BCI has emerged based on the integration of multiple individuals’ intelligence. Nevertheless, the existing decoding methods mainly use linear averaging or feature integration learning from multi-brain EEG data, and do not effectively utilize coupling relationship features, resulting in undesired decoding accuracy. To overcome these challenges, we proposed an EEG-based multi-brain MI decoding method, which utilizes coupling feature extraction and few-shot learning to capture coupling relationship features among multi-brains with only limited EEG data. We performed an experiment to collect EEG data from multiple persons who engaged in the same task simultaneously and compared the methods on the collected data. The comparison results showed that our proposed method improved the performance by 14.23% compared to the single-brain mode in the 10-shot three-class decoding task. It demonstrated the effectiveness of the proposed method and usability of the method in the context of only small amount of EEG data available.

## 59. Double Stage Transfer Learning for Brain–Computer Interfaces

**Authors:** Yunyuan Gao, Mengting Li, Yun Peng, Feng Fang, Yingchun Zhang (2023)
**DOI/URL:** 10.1109/TNSRE.2023.3241301

In the application of brain-computer interfaces (BCIs), electroencephalogram (EEG) signals are difficult to collect in large quantities due to the non-stationary nature and long calibration time required. Transfer learning (TL), which transfers knowledge learned from existing subjects to new subjects, can be applied to solve this problem. Some existing EEG-based TL algorithms cannot achieve good results because they only extract partial features. To achieve effective transfer, a double-stage transfer learning (DSTL) algorithm which applied transfer learning to both preprocessing stage and feature extraction stage of typical BCIs was proposed. First, Euclidean alignment (EA) was used to align EEG trials from different subjects. Second, aligned EEG trials in the source domain were reweighted by the distance between the covariance matrix of each trial in the source domain and the mean covariance matrix of the target domain. Lastly, after extracting spatial features with common spatial patterns (CSP), transfer component analysis (TCA) was adopted to reduce the differences between different domains further. Experiments on two public datasets in two transfer paradigms (multi-source to single-target (MTS) and single-source to single-target (STS)) verified the effectiveness of the proposed method. The proposed DSTL achieved better classification accuracy on two datasets: 84.64% and 77.16% in MTS, 73.38% and 68.58% in STS, which shows that DSTL performs better than other state-of-the-art methods. The proposed DSTL can reduce the difference between the source domain and the target domain, providing a new method for EEG data classification without training dataset.

## 60. Learning Advanced Brain Computer Interface Technology: Comparing CSP Algorithm and WPA Algorithm for EEG Feature Extraction

**Authors:** Tao Wang, Linyan Wu, Yanping Li, Nuo Gao, Zhang Weiran (2019)
**DOI/URL:** 10.4018/IJTHI.2019070102

Feature extraction is an important step in electroencephalogram (EEG) processing of motor imagery, and the feature extraction of EEG directly affects the final classification results. Through the analysis of various feature extraction methods, this article finally selects Common Spatial Patterns (CSP) and wavelet packet analysis (WPA) to extract the feature and uses Support Vector Machine (SVM) to classify and compare these extracted features. For the EEG data provided by GRAZ University, the accuracy rate of feature extraction using CSP algorithm is 85.5%, and the accuracy rate of feature extraction using wavelet packet analysis is 92%. Then this paper analyzes the EEG data collected by Emotiv epoc+ system. The classification accuracy of wavelet packet extracted features can still be maintained at more than 80%, while the classification accuracy of CSP extracted feature is decreased obviously. Experimental results show that the method of wavelet packet analysis towards competition data and Emotiv epoc+ system data can both get a desirable outcome.

## 61. EEG Feature Extraction and Data Augmentation in Emotion Recognition

**Authors:** Mahsa Pourhosein Kalashami, M. Pedram, H. Sadr (2022)
**DOI/URL:** 10.1155/2022/7028517

Emotion recognition is a challenging problem in Brain-Computer Interaction (BCI). Electroencephalogram (EEG) gives unique information about brain activities that are created due to emotional stimuli. This is one of the most substantial advantages of brain signals in comparison to facial expression, tone of voice, or speech in emotion recognition tasks. However, the lack of EEG data and high dimensional EEG recordings lead to difficulties in building effective classifiers with high accuracy. In this study, data augmentation and feature extraction techniques are proposed to solve the lack of data problem and high dimensionality of data, respectively. In this study, the proposed method is based on deep generative models and a data augmentation strategy called Conditional Wasserstein GAN (CWGAN), which is applied to the extracted features to regenerate additional EEG features. DEAP dataset is used to evaluate the effectiveness of the proposed method. Finally, a standard support vector machine and a deep neural network with different tunes were implemented to build effective models. Experimental results show that using the additional augmented data enhances the performance of EEG-based emotion recognition models. Furthermore, the mean accuracy of classification after data augmentation is increased 6.5% for valence and 3.0% for arousal, respectively.

## 62. Trends in EEG signal feature extraction applications

**Authors:** Anup Singh, S. Krishnan (2023)
**DOI/URL:** 10.3389/frai.2022.1072801

This paper will focus on electroencephalogram (EEG) signal analysis with an emphasis on common feature extraction techniques mentioned in the research literature, as well as a variety of applications that this can be applied to. In this review, we cover single and multi-dimensional EEG signal processing and feature extraction techniques in the time domain, frequency domain, decomposition domain, time-frequency domain, and spatial domain. We also provide pseudocode for the methods discussed so that they can be replicated by practitioners and researchers in their specific areas of biomedical work. Furthermore, we discuss artificial intelligence applications such as assistive technology, neurological disease classification, brain-computer interface systems, as well as their machine learning integration counterparts, to complete the overall pipeline design for EEG signal analysis. Finally, we discuss future work that can be innovated in the feature extraction domain for EEG signal analysis.

## 63. JOINT APPROXIMATE DIAGONALIZATION DIVERGENCE BASED SCHEME FOR EEG DROWSINESS DETECTION BRAIN COMPUTER INTERFACES

**Authors:** Tharun Kumar Reddy, Yu-kai Wang, Chin-Teng Lin, Javier Andreu-Perez (2021)
**DOI/URL:** 10.1109/FUZZ45933.2021.9494500

Neurons usually converse through electrochemical signals and pooled neuronal firings feasibly be recorded on the scalp through the medium of electroencephalogram (EEG). EEG waveforms are recorded, analysed and categorized across directives concerning a Brain-Computer Interface (BCI). Deteriorated signal to noise ratio and non-stationarities stand as a paramount obstacle in steady decoding of EEG. Appearance of non-stationarities across EEG patterns notably upset the feature waveforms thus worsening the functioning of detection block and as a whole the Brain Computer Interface. Stationary Subspace schemes bring to light subspaces within which data distribution persists stably over time. Current work focuses on the development of a novel spatial transform based feature extraction scheme to address nonstationarity in EEG signals recorded against a drowsiness detection problem (a machine learning regression scenario). The presented approach: F-DIV-IT-JAD-WS derived features distinctly surpassed DivOVR-FuzzyCSP-WS based standard features across RMSE and CC performance criteria pair. We construe that the propounded feature derivation approach based on F-DIV-IT-JAD-WS will usher a significant attention in researchers who are developing algorithms for signal processing, specifically, for BCI regression scenarios.

## 64. Discrepancy between inter- and intra-subject variability in EEG-based motor imagery brain-computer interface: Evidence from multiple perspectives

**Authors:** Gan Huang, Zhiheng Zhao, Shaorong Zhang, Zhenxing Hu, Jiaming Fan, Meisong Fu, Jiale Chen, Yaqiong Xiao, Jun Wang, Guo Dan (2023)
**DOI/URL:** 10.3389/fnins.2023.1122661

Introduction Inter- and intra-subject variability are caused by the variability of the psychological and neurophysiological factors over time and across subjects. In the application of in Brain-Computer Interfaces (BCI), the existence of inter- and intra-subject variability reduced the generalization ability of machine learning models seriously, which further limited the use of BCI in real life. Although many transfer learning methods can compensate for the inter- and intra-subject variability to some extent, there is still a lack of clear understanding about the change of feature distribution between the cross-subject and cross-session electroencephalography (EEG) signal. Methods To investigate this issue, an online platform for motor-imagery BCI decoding has been built in this work. The EEG signal from both the multi-subject (Exp1) and multi-session (Exp2) experiments has been analyzed from multiple perspectives. Results Firstly we found that with the similar variability of classification results, the time-frequency response of the EEG signal within-subject in Exp2 is more consistent than cross-subject results in Exp1. Secondly, the standard deviation of the common spatial pattern (CSP) feature has a significant difference between Exp1 and Exp2. Thirdly, for model training, different strategies for the training sample selection should be applied for the cross-subject and cross-session tasks. Discussion All these findings have deepened the understanding of inter- and intra-subject variability. They can also guide practice for the new transfer learning methods development in EEG-based BCI. In addition, these results also proved that BCI inefficiency was not caused by the subject’s unable to generate the event-related desynchronization/synchronization (ERD/ERS) signal during the motor imagery.

## 65. Exploring Imagined Movement for Brain–Computer Interface Control: An fNIRS and EEG Review

**Authors:** Robert Finnis, Adeel Mehmood, Henning Holle, Jamshed Iqbal (2025)
**DOI/URL:** 10.3390/brainsci15091013

Brain–Computer Interfaces (BCIs) offer a non-invasive pathway for restoring motor function, particularly for individuals with limb loss. This review explored the effectiveness of Electroencephalography (EEG) and function Near-Infrared Spectroscopy (fNIRS) in decoding Motor Imagery (MI) movements for both offline and online BCI systems. EEG has been the dominant non-invasive neuroimaging modality due to its high temporal resolution and accessibility; however, it is limited by high susceptibility to electrical noise and motion artifacts, particularly in real-world settings. fNIRS offers improved robustness to electrical and motion noise, making it increasingly viable in prosthetic control tasks; however, it has an inherent physiological delay. The review categorizes experimental approaches based on modality, paradigm, and study type, highlighting the methods used for signal acquisition, feature extraction, and classification. Results show that while offline studies achieve higher classification accuracy due to fewer time constraints and richer data processing, recent advancements in machine learning—particularly deep learning—have improved the feasibility of online MI decoding. Hybrid EEG–fNIRS systems further enhance performance by combining the temporal precision of EEG with the spatial specificity of fNIRS. Overall, the review finds that predicting online imagined movement is feasible, though still less reliable than motor execution, and continued improvements in neuroimaging integration and classification methods are essential for real-world BCI applications. Broader dissemination of recent advancements in MI-based BCI research is expected to stimulate further interdisciplinary collaboration among roboticists, neuroscientists, and clinicians, accelerating progress toward practical and transformative neuroprosthetic technologies.

## 66. Improving Common Spatial Patterns in Brain-Computer Interface Using Dynamic Time Warping and EEG Normalization

**Authors:** Mohamed A A Mohamed, Salem Mansour, P. Soulatiantork, K. Ang, K. Phua, M. Arvaneh (2023)
**DOI/URL:** 10.1109/MetroXRAINE58569.2023.10405776

Common spatial patterns (CSP) is widely employed for spatial filtering and feature extraction in electroencephalogram (EEG)-based brain-computer interfaces (BCIs), However, the non-stationary nature of EEG signals can lead to poor estimation of CSP. To address this drawback, this paper proposes a novel algorithm called scaled and warped CSP (SW-CSP). The proposed algorithm enhances the classical CSP by reducing within EEG class non-stationarity across both time and amplitude domains, followed by automatically selecting the most discriminative features. First, the maximum-minimum scaling is applied to align amplitude of each EEG trial to its class average. Next, dynamic time warping (DTW) temporally aligns each scaled EEG trial to its class average. Thereafter, the scaled and warped EEG trials are used to compute the CSP covariance matrices. Finally, the proposed Fisher's score is used to select most discriminative SW-CSP filters. The proposed SW-CSP algorithm is evaluated using two datasets, and compared with the CSP algorithm and the previously proposed DTW-CSP. The results showed that the SW-CSP significantly outperformed both CSP and DTW-CSP (p<0.003). Notably, an improvement above 10% was observed in 20 % of the participants.

## 67. EEG-Based Brain-Computer Interfaces Using Motor-Imagery: Techniques and Challenges

**Authors:** Natasha M. J. Padfield, J. Zabalza, Huimin Zhao, Valentin Masero Vargas, J. Ren (2019)
**DOI/URL:** 10.3390/s19061423

Electroencephalography (EEG)-based brain-computer interfaces (BCIs), particularly those using motor-imagery (MI) data, have the potential to become groundbreaking technologies in both clinical and entertainment settings. MI data is generated when a subject imagines the movement of a limb. This paper reviews state-of-the-art signal processing techniques for MI EEG-based BCIs, with a particular focus on the feature extraction, feature selection and classification techniques used. It also summarizes the main applications of EEG-based BCIs, particularly those based on MI data, and finally presents a detailed discussion of the most prevalent challenges impeding the development and commercialization of EEG-based BCIs.

## 68. Input Shape Effect on Classification Performance of Raw EEG Motor Imagery Signals with Convolutional Neural Networks for Use in Brain—Computer Interfaces

**Authors:** Emre Arı, E. Taçgın (2023)
**DOI/URL:** 10.3390/brainsci13020240

EEG signals are interpreted, analyzed and classified by many researchers for use in brain–computer interfaces. Although there are many different EEG signal acquisition methods, one of the most interesting is motor imagery signals. Many different signal processing methods, machine learning and deep learning models have been developed for the classification of motor imagery signals. Among these, Convolutional Neural Network models generally achieve better results than other models. Because the size and shape of the data is important for training Convolutional Neural Network models and discovering the right relationships, researchers have designed and experimented with many different input shape structures. However, no study has been found in the literature evaluating the effect of different input shapes on model performance and accuracy. In this study, the effects of different input shapes on model performance and accuracy in the classification of EEG motor imagery signals were investigated, which had not been specifically studied before. In addition, signal preprocessing methods, which take a long time before classification, were not used; rather, two CNN models were developed for training and classification using raw data. Two different datasets, BCI Competition IV 2A and 2B, were used in classification processes. For different input shapes, 53.03–89.29% classification accuracy and 2–23 s epoch time were obtained for 2A dataset, 64.84–84.94% classification accuracy and 4–10 s epoch time were obtained for 2B dataset. This study showed that the input shape has a significant effect on the classification performance, and when the correct input shape is selected and the correct CNN architecture is developed, feature extraction and classification can be done well by the CNN architecture without any signal preprocessing.

## 69. EEG-Based Feature Classification Combining 3D-Convolutional Neural Networks with Generative Adversarial Networks for Motor Imagery.

**Authors:** Chengcheng Fan, Banghua Yang, Xiaoou Li, Shouwei Gao, Peng Zan (2024)
**DOI/URL:** 10.31083/j.jin2308153

BACKGROUND
The adoption of convolutional neural networks (CNNs) for decoding electroencephalogram (EEG)-based motor imagery (MI) in brain-computer interfaces has significantly increased recently. The effective extraction of motor imagery features is vital due to the variability among individuals and temporal states.


METHODS
This study introduces a novel network architecture, 3D-convolutional neural network-generative adversarial network (3D-CNN-GAN), for decoding both within-session and cross-session motor imagery. Initially, EEG signals were extracted over various time intervals using a sliding window technique, capturing temporal, frequency, and phase features to construct a temporal-frequency-phase feature (TFPF) three-dimensional feature map. Generative adversarial networks (GANs) were then employed to synthesize artificial data, which, when combined with the original datasets, expanded the data capacity and enhanced functional connectivity. Moreover, GANs proved capable of learning and amplifying the brain connectivity patterns present in the existing data, generating more distinctive brain network features. A compact, two-layer 3D-CNN model was subsequently developed to efficiently decode these TFPF features.


RESULTS
Taking into account session and individual differences in EEG data, tests were conducted on both the public GigaDB dataset and the SHU laboratory dataset. On the GigaDB dataset, our 3D-CNN and 3D-CNN-GAN models achieved two-class within-session motor imagery accuracies of 76.49% and 77.03%, respectively, demonstrating the algorithm's effectiveness and the improvement provided by data augmentation. Furthermore, on the SHU dataset, the 3D-CNN and 3D-CNN-GAN models yielded two-class within-session motor imagery accuracies of 67.64% and 71.63%, and cross-session motor imagery accuracies of 58.06% and 63.04%, respectively.


CONCLUSIONS
The 3D-CNN-GAN algorithm significantly enhances the generalizability of EEG-based motor imagery brain-computer interfaces (BCIs). Additionally, this research offers valuable insights into the potential applications of motor imagery BCIs.

## 70. Classification of Motor Imagery Using Combination of Feature Extraction and Reduction Methods for Brain-Computer Interface

**Authors:** V. Jusas, Sam Gilvine Samuvel (2019)
**DOI/URL:** 10.5755/J01.ITC.48.2.23091

The motor imagery (MI) based brain-computer interface systems (BCIs) can help with new communication ways. A typical electroencephalography (EEG)-based BCI system consists of several components including signal acquisition, signal pre-processing, feature extraction and feature classification. This paper focuses on the feature extraction step and proposes to use a combination of different feature extraction and feature reduction methods. The research presented in the paper explores the methods of band power, time domain parameters, fast Fourier transform and channel variance for feature extraction. These methods are investigated by combining them in pairs. The application of two feature extraction methods increases the number of selected features that can be redundant or irrelevant. The utilization of too many features can lead to wrong classification results. Therefore, the methods of feature reduction have to be applied. The following feature reduction methods are investigated: principal component analysis, sequential forward selection, sequential backward selection, locality preserving projections and local Fisher discriminant analysis. The combination of the methods of fast Fourier transform, channel variance and principal component analysis performed the best among the combinations of methods. The obtained classification accuracy of the above-mentioned combination of the methods is much higher than that of the individual feature extraction method. The novelty of the approach is based on consolidated sequence of methods for feature extraction and feature reduction.

## 71. Artificial Intelligence Algorithms in Visual Evoked Potential-Based Brain-Computer Interfaces for Motor Rehabilitation Applications: Systematic Review and Future Directions

**Authors:** J. Gutiérrez-Martínez, J. A. Mercado-Gutiérrez, B. Carvajal-Gámez, J. L. Rosas-Trigueros, A. Contreras-Martínez (2021)
**DOI/URL:** 10.3389/fnhum.2021.772837

Brain-Computer Interface (BCI) is a technology that uses electroencephalographic (EEG) signals to control external devices, such as Functional Electrical Stimulation (FES). Visual BCI paradigms based on P300 and Steady State Visually Evoked potentials (SSVEP) have shown high potential for clinical purposes. Numerous studies have been published on P300- and SSVEP-based non-invasive BCIs, but many of them present two shortcomings: (1) they are not aimed for motor rehabilitation applications, and (2) they do not report in detail the artificial intelligence (AI) methods used for classification, or their performance metrics. To address this gap, in this paper the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) methodology was applied to prepare a systematic literature review (SLR). Papers older than 10 years, repeated or not related to a motor rehabilitation application, were excluded. Of all the studies, 51.02% referred to theoretical analysis of classification algorithms. Of the remaining, 28.48% were for spelling, 12.73% for diverse applications (control of wheelchair or home appliances), and only 7.77% were focused on motor rehabilitation. After the inclusion and exclusion criteria were applied and quality screening was performed, 34 articles were selected. Of them, 26.47% used the P300 and 55.8% the SSVEP signal. Five applications categories were established: Rehabilitation Systems (17.64%), Virtual Reality environments (23.52%), FES (17.64%), Orthosis (29.41%), and Prosthesis (11.76%). Of all the works, only four performed tests with patients. The most reported machine learning (ML) algorithms used for classification were linear discriminant analysis (LDA) (48.64%) and support vector machine (16.21%), while only one study used a deep learning algorithm: a Convolutional Neural Network (CNN). The reported accuracy ranged from 38.02 to 100%, and the Information Transfer Rate from 1.55 to 49.25 bits per minute. While LDA is still the most used AI algorithm, CNN has shown promising results, but due to their high technical implementation requirements, many researchers do not justify its implementation as worthwile. To achieve quick and accurate online BCIs for motor rehabilitation applications, future works on SSVEP-, P300-based and hybrid BCIs should focus on optimizing the visual stimulation module and the training stage of ML and DL algorithms.

## 72. EEG-based affective brain–computer interfaces: recent advancements and future challenges

**Authors:** Yuxin Chen, Yong Peng, Jiajia Tang, Tracey A. Camilleri, Kenneth P. Camilleri, Wangzeng Kong, Andrzej Cichocki (2025)
**DOI/URL:** 10.1088/1741-2552/ade290

Objective. As one of the most popular brain–computer interface (BCI) paradigms, affective BCI (aBCI) decodes the human emotional states from brain signals and imposes necessary feedback to achieve neural regulation when negative emotional states (i.e. depression, anxiety) are detected, which are considered as the two basic functions of aBCI systems. Electroencephalogram (EEG) is the scalp reflection of neural activities and has been regarded as the gold standard of emotional effects. Recently, rapid progresses have been made for emotion recognition and regulation with the purpose of constructing a high-performance closed-loop EEG-based aBCI system. Therefore, it is necessary to make a timely review for aBCI research by summarizing the current progresses as well as challenges and opportunities, to draw the attention from both academia and industry. Toward this goal, a systematic literature review was performed to summarize not only the recent progresses in emotion recognition and regulation from the perspective of closed-loop aBCI, but also the main challenges and future research focuses to narrow the gap between the current research and real applications of aBCI systems. Approach. A systematic literature review on EEG-based emotion recognition and regulation was performed on Web of Science and related databases, resulting in more than 100 identified studies. These studies were analyzed according to the experimental paradigm, emotion recognition methods in terms of different scenarios, and the applications of emotion recognition in diagnosis and regulation of affective disorders. Main results. Based on the literature review, advancements for EEG-based aBCI research were extensively summarized from six aspects including the ‘emotion elicitation paradigms and data sets’, ‘inner exploration of EEG information’, ‘outer extension of fusing EEG with other data modalities’, ‘cross-scene emotion recognition’, ‘emotion recognition by considering real scenarios’, and ‘diagnosis and regulation of affective disorders’. In addition, future opportunities were concluded by focusing on the main challenges in hindering the aBCI system to move from laboratory to real applications. Moreover, the neural mechanisms and theoretical basis behind EEG emotion recognition and regulation are also introduced to provide support for the advancements and challenges in aBCI. Significance. This review summarizes the current practices and performance outcomes in emotion recognition and regulation. Future directions in response to the existing challenges are provided with the expectation of guiding the aBCI research to focus on the necessary key technologies of aBCI systems in practical deployment.

## 73. Siamese Neural Networks for EEG-based Brain-computer Interfaces

**Authors:** Soroosh Shahtalebi, A. Asif, Arash Mohammadi (2020)
**DOI/URL:** 10.1109/EMBC44109.2020.9176001

Motivated by the inconceivable capability of human brain in simultaneously processing multi-modal signals and its real-time feedback to the outer world events, there has been a surge of interest in establishing a communication bridge between the human brain and a computer, which are referred to as Brain-computer Interfaces (BCI). To this aim, monitoring the electrical activity of brain through Electroencephalogram (EEG) has emerged as the prime choice for BCI systems. To discover the underlying and specific features of brain signals for different mental tasks, a considerable number of research works are developed based on statistical and data-driven techniques. However, a major bottleneck in development of practical and commercial BCI systems is their limited performance when the number of mental tasks for classification is increased. In this work, we propose a new EEG processing and feature extraction paradigm based on Siamese neural networks, which can be conveniently merged and scaled up for multi-class problems. The idea of Siamese networks is to train a double-input neural network based on a contrastive loss-function, which provides the capability of verifying if two input EEG trials are from the same class or not. In this work, a Siamese architecture, which is developed based on Convolutional Neural Networks (CNN) and provides a binary output on the similarity of two inputs, is combined with One vs. Rest (OVR) and One vs. One (OVO) techniques to scale up for multi-class problems. The efficacy of this architecture is evaluated on a 4-class Motor Imagery (MI) dataset from BCI Competition IV2a and the results suggest a promising performance compared to its counterparts.

## 74. A systematic mapping of feature extraction and feature selection methods of electroencephalogram signals for neurological diseases diagnostic assistance

**Authors:** Wallace Faveron de Almeida, Clodoaldo Aparecido de Moraes Lima, Sarajane Marques Peres (2021)
**DOI/URL:** 10.1109/TLA.2021.9448287

Electroencephalogram (EEG) is a non-invasive tool used to monitor the electrical activities of the brain. EEG signal analysis has several applications in the medical field. It is widely used for clinical diagnostics and for advances in the Brain-Computer Interface (BCI) area. In recent years, several studies about the automatic execution of this analysis have been proposed, motivated by the fact that the visual inspection demands a long time from an expert, besides being subject to a misdiagnosis. In order to extract and select relevant information from recordings of brain electrical activity, many computerized analysis methods have been developed based on different approaches. Although some proposed methods have achieved good performance, many of them are not suitable for real-world application due to their high computational cost. Thus, there is opportunity in the area to identify and categorize techniques in order to support studies about the influence of these techniques on diagnostic performance and to propose the optimization of this task. In this context, this Systematic Mapping evaluates the 144 primary studies identified according to the criteria defined in the protocol. The purpose is to highlight which neurological disorders have been studied in recent years and which techniques for feature extraction and feature selection have been applied during signal analysis, individually or jointly, to provide specifically an automatic diagnosis of a neurological disorder using a classifier.

## 75. EEG Dataset for RSVP and P300 Speller Brain-Computer Interfaces

**Authors:** K. Won, Moonyoung Kwon, M. Ahn, S. Jun (2022)
**DOI/URL:** 10.1038/s41597-022-01509-w

As attention to deep learning techniques has grown, many researchers have attempted to develop ready-to-go brain-computer interfaces (BCIs) that include automatic processing pipelines. However, to do so, a large and clear dataset is essential to increase the model’s reliability and performance. Accordingly, our electroencephalogram (EEG) dataset for rapid serial visual representation (RSVP) and P300 speller may contribute to increasing such BCI research. We validated our dataset with respect to features and accuracy. For the RSVP, the participants (N = 50) achieved about 92% mean target detection accuracy. At the feature level, we observed notable ERPs (at 315 ms in the RSVP; at 262 ms in the P300 speller) during target events compared to non-target events. Regarding P300 speller performance, the participants (N = 55) achieved about 92% mean accuracy. In addition, P300 speller performance over trial repetitions up to 15 was explored. The presented dataset could potentially improve P300 speller applications. Further, it may be used to evaluate feature extraction and classification algorithm effectively, such as for cross-subjects/cross-datasets, and even for the cross-paradigm BCI model. Measurement(s) Electroencephalography Technology Type(s) electroencephalography (EEG) Sample Characteristic - Organism Homo sapiens Measurement(s) Electroencephalography Technology Type(s) electroencephalography (EEG) Sample Characteristic - Organism Homo sapiens

## 76. Generalized Optimal EEG Channels Selection for Motor Imagery Brain–Computer Interface

**Authors:** Hsiang-Chen Lee, Ching‐Hung Lee (2023)
**DOI/URL:** 10.1109/JSEN.2023.3313236

Brain–computer interfaces (BCI) enable people to communicate with external instruments through brain activity recorded by electroencephalography (EEG). BCI based on motor imagery (MI) can distinguish activation of specific brain regions by decoding EEG signals and then applying them to different situations. Because the activation regions of the brain are specific, using all EEG channels for classification is redundant and may lead to feature confusion and inconvenience for users when applying EEG. Current EEG channel selection methods focus primarily on a single subject and require the data from the subject to generate the chosen channel, which is inconvenient on the application side to determine suitable channels for new subjects. Therefore, this study introduces a novel method for generalized EEG channel selection. Two datasets are used: the BCI competition IV 2a dataset for generating generalized EEG channels and the OpenBMI dataset for validation by numerous subjects. First, the signals from each channel are fed into EEG-Net for classification and ranked by loss to generate optimal EEG channels. Then, the methods of ranking and non-dominated sorting genetic algorithm (NSGA)-II are used to find different combinations of optimal potential differences. Finally, the generalized EEG channels are generated and validated by EEG-Net again. The validation results show that 88.5% of the subjects can be well-classified in one session, including MI-illiteracy, defined by the dataset. The average accuracy is 77.7% and 79.26% in Sessions 1 and 2, using the average channel number around 5, instead of channels from the motor cortex region or all placed EEG channels.

## 77. Single-Trial EEG Classification Using Spatio-Temporal Weighting and Correlation Analysis for RSVP-Based Collaborative Brain Computer Interface

**Authors:** Ziwei Zhao, Yanfei Lin, Yijun Wang, Xiaorong Gao (2023)
**DOI/URL:** 10.1109/TBME.2023.3309255

Objective: Since single brain computer interface (BCI) is limited in performance, it is necessary to develop collaborative BCI (cBCI) systems which integrate multi-user electroencephalogram (EEG) information to improve system performance. However, there are still some challenges in cBCI systems, including effective discriminant feature extraction of multi-user EEG data, fusion algorithms, time reduction of system calibration, etc. Methods: This study proposed an event-related potential (ERP) feature extraction and classification algorithm of spatio-temporal weighting and correlation analysis (STC) to improve the performance of cBCI systems. The proposed STC algorithm consisted of three modules. First, source extraction and interval modeling were used to overcome the problem of inter-trial variability. Second, spatio-temporal weighting and temporal projection were utilized to extract effective discriminant features for multi-user information fusion and cross-session transfer. Third, correlation analysis was conducted to match target/non-target templates for classification of multi-user and cross-session datasets. Results: The collaborative cross-session datasets of rapid serial visual presentation (RSVP) from 14 subjects were used to evaluate the performance of the EEG classification algorithm. For single-user/collaborative EEG classification of within-session and cross-session datasets, STC had significantly higher performance than the existing state-of-the-art machine learning algorithms. Conclusion: It was demonstrated that STC was effective to improve the classification performance of multi-user collaboration and cross-session transfer for RSVP-based BCI systems, and was helpful to reduce the system calibration time.

## 78. Feature Extraction of Motor Imagery EEG via Discrete Wavelet Transform and Generalized Maximum Fuzzy Membership Difference Entropy: A Comparative Study

**Authors:** Yinan Wang, Chengxin Song, Tao Zhang, Zongwei Yao, Zhiyong Chang, Deping Wang (2023)
**DOI/URL:** 10.3390/electronics12102207

Identifying motor imagery (MI) electroencephalogram (EEG) is an important way to achieve brain–computer interface (BCI), but its applicability is heavily dependent on the performance of feature extraction procedure. In this paper, a feature extraction method based on generalized maximum fuzzy membership difference entropy (GMFMDE) and discrete wavelet transform (DWT) was proposed for the feature extraction of EEG signals. The influence of different distance calculation methods, embedding dimensions and tolerances were studied to find the best configuration of GMFMDE for the feature extraction of MI–EEG. The gradient boosting decision tree (GBDT) classifier was used to classify the features extracted from GMFMDE and DWT. The average classification accuracy of 93.71% and the maximum classification accuracy of 96.96% were obtained, which proved the effectiveness of the proposed feature extraction method for EEG signal feature extraction.

## 79. EBi-LSTM: an enhanced bi-directional LSTM for time-series data classification by heuristic development of optimal feature integration in brain computer interface

**Authors:** Mala Saraswat, A. Dubey (2023)
**DOI/URL:** 10.1080/10255842.2023.2187662

Abstract Generally, time series data is referred to as the sequential representation of data that observes from different applications. Therefore, such expertise can use Electroencephalography (EEG) signals to fetch data regarding brain neural activities in brain–computer interface (BCI) systems. Due to massive and myriads data, the signals are appealed in a non-stationary format that ends with a poor quality resolution. To overcome this existing issue, a new framework of enhanced deep learning methods is proposed. The source signals are collected and undergo feature extraction in four ways. Hence, the features are concatenated to enhance the performance. Subsequently, the concatenated features are given to probability ratio-based Reptile Search Algorithm (PR-RSA) to select the optimal features. Finally, the classification is conducted using Enhanced Bi-directional Long Short-Term Memory (EBi-LSTM), where the hyperparameters are optimized by PR-RSA. Throughout the result analysis, it is confirmed that the offered model obtains elevated classification accuracy, and thus tends to increase the performance.

## 80. A Comparative Study of Different Feature Extraction Methods for Motor Imagery EEG Decoding within the Same Upper Extremity

**Authors:** Yaqi Chu, Xingang Zhao, Yijun Zou, He Zhang, Weiliang Xu, Yiwen Zhao (2018)
**DOI/URL:** 10.1109/CAC.2018.8623624

Compared to other electroencephalogram (EEG) modalities, motor imagery (MI) based brain-computer interfaces (BCls) can provide more natural and intuitive communication between human intentions and external machines. However, this type of BCI depends heavily on effective signal processing to discriminate EEG patterns corresponding to various MI tasks, especially feature extraction procedures. In this study, a comparison of different feature extraction methods was conducted for EEG classification of imaginary movements within the same upper extremity. Unlike traditional MI tasks (left/right hand), six imaginary movements from the same unilateral upper extremity were proposed and evaluated, including elbow extension/flexion, wrist pronation/supination, and hand open/grasp. To tackle the classification challenge of MI tasks within the same limb, four types of feature extraction methods were implemented and compared in combination with support vector machine (SVM) and linear discriminant analysis (LDA) classifiers, such as wavelet transformation, power spectrum, autoregressive model, common spatial patterns (CSP) and variants of filter-bank CSP (FBCSP), regularized CSP (RCSP). The overall accuracies of the CSP were significant higher than other three types of feature extraction on a dataset collected from 8 individuals, particularly the SVM with FBCSP had the best performance with an average accuracy of 71.78%. These decoding results of MI tasks during single upper extremity are encouraging and promising in the context of more natural MI-BCI for controlling assisted devices, such as a neuroprosthetic or robotic arm for motor disabled individuals with highly impaired upper extremity.

## 81. Application of Transfer Learning in EEG Decoding Based on Brain-Computer Interfaces: A Review

**Authors:** Kai Zhang, Guanghua Xu, Xiaowei Zheng, Huanzhong Li, Sicong Zhang, Yunhui Yu, Renghao Liang (2020)
**DOI/URL:** 10.3390/s20216321

The algorithms of electroencephalography (EEG) decoding are mainly based on machine learning in current research. One of the main assumptions of machine learning is that training and test data belong to the same feature space and are subject to the same probability distribution. However, this may be violated in EEG processing. Variations across sessions/subjects result in a deviation of the feature distribution of EEG signals in the same task, which reduces the accuracy of the decoding model for mental tasks. Recently, transfer learning (TL) has shown great potential in processing EEG signals across sessions/subjects. In this work, we reviewed 80 related published studies from 2010 to 2020 about TL application for EEG decoding. Herein, we report what kind of TL methods have been used (e.g., instance knowledge, feature representation knowledge, and model parameter knowledge), describe which types of EEG paradigms have been analyzed, and summarize the datasets that have been used to evaluate performance. Moreover, we discuss the state-of-the-art and future development of TL for EEG decoding. The results show that TL can significantly improve the performance of decoding models across subjects/sessions and can reduce the calibration time of brain–computer interface (BCI) systems. This review summarizes the current practical suggestions and performance outcomes in the hope that it will provide guidance and help for EEG research in the future.

## 82. Hybrid EEG Feature Learning Method for Cross-Session Human Mental Attention State Classification

**Authors:** Xu Chen, Xingtong Bao, Kailun Jitian, Ruihan Li, Li Zhu, Wanzeng Kong (2025)
**DOI/URL:** 10.3390/brainsci15080805

Background: Decoding mental attention states from electroencephalogram (EEG) signals is crucial for numerous applications such as cognitive monitoring, adaptive human–computer interaction, and brain–computer interfaces (BCIs). However, conventional EEG-based approaches often focus on channel-wise processing and are limited to intra-session or subject-specific scenarios, lacking robustness in cross-session or inter-subject conditions. Methods: In this study, we propose a hybrid feature learning framework for robust classification of mental attention states, including focused, unfocused, and drowsy conditions, across both sessions and individuals. Our method integrates preprocessing, feature extraction, feature selection, and classification in a unified pipeline. We extract channel-wise spectral features using short-time Fourier transform (STFT) and further incorporate both functional and structural connectivity features to capture inter-regional interactions in the brain. A two-stage feature selection strategy, combining correlation-based filtering and random forest ranking, is adopted to enhance feature relevance and reduce dimensionality. Support vector machine (SVM) is employed for final classification due to its efficiency and generalization capability. Results: Experimental results on two cross-session and inter-subject EEG datasets demonstrate that our approach achieves classification accuracy of 86.27% and 94.01%, respectively, significantly outperforming traditional methods. Conclusions: These findings suggest that integrating connectivity-aware features with spectral analysis can enhance the generalizability of attention decoding models. The proposed framework provides a promising foundation for the development of practical EEG-based systems for continuous mental state monitoring and adaptive BCIs in real-world environments.

## 83. EEG Feature Extraction Based on a Bilevel Network: Minimum Spanning Tree and Regional Network

**Authors:** Zhizeng Luo, Xianju Lu, Xugang Xi (2020)
**DOI/URL:** 10.3390/electronics9020203

Feature extraction is essential for classifying different motor imagery (MI) tasks in a brain–computer interface (BCI). Although the methods of brain network analysis have been widely studied in the BCI field, these methods are limited by differences in network size, density, and standardization. To address this issue and improve classification accuracy, we propose a novel method, in which the hybrid features of the brain function based on the bilevel network are extracted. Minimum spanning tree (MST) based on electroencephalogram (EEG) signal nodes in different MIs is constructed as the first network layer to solve the global network connectivity problem. In addition, the regional network in different movement patterns is constructed as the second network layer to determine the network characteristics, which is consistent with the correspondence between limb movement patterns and cerebral cortex in neurophysiology. We attempt to apply MST to the classification of the MI EEG signals, and the bilevel network has better interpretability. Thereafter, a vector is formed by combining the MST fundamental features with the directional features of the regional network. Our method is validated using the BCI Competition IV Dataset I. Experimental results verify the feasibility of the bilevel network framework. Furthermore, the average classification performance of the proposed method reaches 89.50%, which is higher than that of other competing methods, thereby indicating that the bilevel network is effective for MI classification.

## 84. A Tensor-Based Frequency Features Combination Method for Brain–Computer Interfaces

**Authors:** Yu Pei, Zhiguo Luo, Hongyu Zhao, Dengke Xu, Weiguo Li, Ye Yan, Huijiong Yan, Liang Xie, Minpeng Xu, E. Yin (2021)
**DOI/URL:** 10.1109/TNSRE.2021.3125386

With the development of the brain-computer interface (BCI) community, motor imagery-based BCI system using electroencephalogram (EEG) has attracted increasing attention because of its portability and low cost. Concerning the multi-channel EEG, the frequency component is one of the most critical features. However, insufficient extraction hinders the development and application of MI-BCIs. To deeply mine the frequency information, we proposed a method called tensor-based frequency feature combination (TFFC). It combined tensor-to-vector projection (TVP), fast fourier transform (FFT), common spatial pattern (CSP) and feature fusion to construct a new feature set. With two datasets, we used different classifiers to compare TFFC with the state-of-the-art feature extraction methods. The experimental results showed that our proposed TFFC could robustly improve the classification accuracy of about 5% ( ${p} < 0.01$ ). Moreover, visualization analysis implied that the TFFC was a generalization of CSP and Filter Bank CSP (FBCSP). Also, a complementarity between weighted narrowband features (wNBFs) and broadband features (BBFs) was observed from the averaged fusion ratio. This article certificates the importance of frequency information in the MI-BCI system and provides a new direction for designing a feature set of MI-EEG.

## 85. A comprehensive survey of evolutionary algorithms and metaheuristics in brain EEG-based applications

**Authors:** Muhammad Arif, Faizan ur Rehman, Lukás Sekanina, A. Malik (2024)
**DOI/URL:** 10.1088/1741-2552/ad7f8e

Electroencephalography (EEG) has emerged as a primary non-invasive and mobile modality for understanding the complex workings of the human brain, providing invaluable insights into cognitive processes, neurological disorders, and brain–computer interfaces. Nevertheless, the volume of EEG data, the presence of artifacts, the selection of optimal channels, and the need for feature extraction from EEG data present considerable challenges in achieving meaningful and distinguishing outcomes for machine learning algorithms utilized to process EEG data. Consequently, the demand for sophisticated optimization techniques has become imperative to overcome these hurdles effectively. Evolutionary algorithms (EAs) and other nature-inspired metaheuristics have been applied as powerful design and optimization tools in recent years, showcasing their significance in addressing various design and optimization problems relevant to brain EEG-based applications. This paper presents a comprehensive survey highlighting the importance of EAs and other metaheuristics in EEG-based applications. The survey is organized according to the main areas where EAs have been applied, namely artifact mitigation, channel selection, feature extraction, feature selection, and signal classification. Finally, the current challenges and future aspects of EAs in the context of EEG-based applications are discussed.

## 86. An EEG Feature Extraction Method Based on Sparse Dictionary Self-Organizing Map for Event-Related Potential Recognition

**Authors:** Shang Feng, Haifeng Li, Lin Ma, Zhongliang Xu (2020)
**DOI/URL:** 10.3390/a13100259

In the application of the brain-computer interface, feature extraction is an important part of Electroencephalography (EEG) signal classification. Using sparse modeling to extract EEG signal features is a common approach. However, the features extracted by common sparse decomposition methods are only of analytical meaning, and cannot relate to actual EEG waveforms, especially event-related potential waveforms. In this article, we propose a feature extraction method based on a self-organizing map of sparse dictionary atoms, which can aggregate event-related potential waveforms scattered inside an over-complete sparse dictionary into the code book of neurons in the self-organizing map network. Then, the cosine similarity between the EEG signal sample and the code vector is used as the classification feature. Compared with traditional feature extraction methods based on sparse decomposition, the classification features obtained by this method have more intuitive electrophysiological meaning. The experiment conducted on a public auditory event-related potential (ERP) brain-computer interface dataset showed that, after the self-organized mapping of dictionary atoms, the neurons’ code vectors in the self-organized mapping network were remarkably similar to the ERP waveform obtained after superposition and averaging. The feature extracted by the proposed method used a smaller amount of data to obtain classification accuracy comparable to the traditional method.

## 87. A Gait Imagery-Based Brain–Computer Interface With Visual Feedback for Spinal Cord Injury Rehabilitation on Lokomat

**Authors:** C. F. Blanco-Díaz, E. R. S. Serafini, T. Bastos-Filho, A. F. O. D. A. Dantas, C. D. E. Santo, D. Delisle-Rodríguez (2024)
**DOI/URL:** 10.1109/TBME.2024.3440036

<italic>Objective:</italic> Motor Imagery (MI)-based Brain-Computer Interfaces (BCIs) have been proposed for the rehabilitation of people with disabilities, being a big challenge their successful application to restore motor functions in individuals with Spinal Cord Injury (SCI). This work proposes an Electroencephalography (EEG) gait imagery-based BCI to promote motor recovery on the Lokomat platform, in order to allow a clinical intervention by acting simultaneously on both central and peripheral nervous mechanisms. <italic>Methods:</italic> As a novelty, our BCI system accurately discriminates gait imagery tasks during walking and further provides a multi-channel EEG-based Visual Neurofeedback (VNFB) linked to <inline-formula><tex-math notation="LaTeX">$\mu$</tex-math></inline-formula> (8–12 Hz) and <inline-formula><tex-math notation="LaTeX">$\beta$</tex-math></inline-formula> (15–20 Hz) rhythms around Cz. VNFB is carried out through a cluster analysis strategy-based Euclidean distance, where the weighted mean MI feature vector is used as a reference to teach individuals with SCI to modulate their cortical rhythms. <italic>Results:</italic> The developed BCI reached an average classification accuracy of 74.4%. In addition, feature analysis demonstrated a reduction in cluster variance after several sessions, whereas metrics associated with self-modulation indicated a greater distance between both classes: passive walking with gait MI and passive walking without MI. <italic>Conclusion:</italic> The results suggest that intervention with a gait MI-based BCI with VNFB may allow the individuals to appropriately modulate their rhythms of interest around Cz. <italic>Significance:</italic> This work contributes to the development of advanced systems for gait rehabilitation by integrating Machine Learning and neurofeedback techniques, to restore lower-limb functions of SCI individuals.

## 88. Human Brain Waves Study Using EEG and Deep Learning for Emotion Recognition

**Authors:** Muskan Priyadarshani, Pushpendra Kumar, Kanojia Sindhuben Babulal, Dharmendra Singh Rajput, Harshita Patel (2024)
**DOI/URL:** 10.1109/ACCESS.2024.3427822

Emotion Recognition is a critical area of research including healthcare, human-computer interaction, and psychology. While traditional methods mainly rely on facial expressions and textual analysis, they also have inherent flaws and cannot be reliable. Facial expression-based emotion recognition assumes that it represents genuine internal emotions that may be inaccurate. Similarly, textual analysis depends on the available data and needs help accurately capturing subtle emotions in text. However, electroencephalography (EEG) has emerged as a rising alternative for objective and real-time emotion recognition. Unlike facial and textual methods, EEG directly measures brain activity and provides a reliable result. To address this researchers have used basic machine learning methods that need manual feature extraction, which might miss essential data and make the process slow and less accurate. In this study, we propose a comprehensive methodology for EEG-based emotion recognition that addresses the limitations of traditional methods and basic machine learning techniques. Our approach involves preprocessing EEG signals using a butter-worth bandpass filter to eliminate noise, followed by feature extraction techniques. We then employ Principal Component Analysis (PCA) for dimensionality reduction, ensuring efficient data representation. To further enhance the model performance we explore machine learning classifiers(GaussianNB, SVM, Random Forest) and proposed an EEG-LSTM and GRU model with an accuracy of 97% and 96% respectively, that gives better results than the basic machine learning models.

## 89. Comparative Performance Analysis of Scalp EEG and Ear EEG based P300 Ambulatory Brain-Computer Interfaces using Riemannian Geometry and Convolutional Neural Networks

**Authors:** Vartika Gupta, Tushar P. Kendre, Tharun Kumar Reddy, Vipul Arora (2022)
**DOI/URL:** 10.1109/NCC55593.2022.9806815

Brain-Computer Interfaces (BCI) provide the users to communicate with computers via brain signals. Significant research within the BCI is devoted to ElectroEncephaloGraphy (EEG), which picks, on the scalp, immensely frail electrical currents delineating brain activity. This paper presents a new ambulatory classification method for EEG Event Related Poten-tials (ERP) for a Practical Brain Computer Interface (BCI). To be more specific, this paper focuses on enhancing the performance of the ERP classification using Ear EEG along with scalp EEG during walking at 1.6m/s. We demonstrate the signal quality of Ear EEG for targets and non-targets. Through a novel estimation of Covariance matrices, this work extends the use of Riemannian Geometry (RG). In addition, the utility of Ear EEG has been justified by the 5% improvement in ERP detection performance after a novel fusion of Riemannian Geometry attributes from Ear EEG and scalp EEG. Further, we also proposed a fusion of feature attributes of both scalp and Ear EEG obtained from the fully connected layer of trained EEGNet CNN model with autoencoders passed through XGBoost. This method improved the state of the art by 10%. The proposed methods serve as novel adaptations of RG and CNN methods for mobile EEG in a practical BCI setup. The proposed method was also validated on the track 5 of the International BCI competition and achieved third position in the challenge.

## 90. Improved classification performance of EEG-fNIRS multimodal brain-computer interface based on multi-domain features and multi-level progressive learning

**Authors:** Lina Qiu, Yongshi Zhong, Zhipeng He, Jiahui Pan (2022)
**DOI/URL:** 10.3389/fnhum.2022.973959

Electroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS) have potentially complementary characteristics that reflect the electrical and hemodynamic characteristics of neural responses, so EEG-fNIRS-based hybrid brain-computer interface (BCI) is the research hotspots in recent years. However, current studies lack a comprehensive systematic approach to properly fuse EEG and fNIRS data and exploit their complementary potential, which is critical for improving BCI performance. To address this issue, this study proposes a novel multimodal fusion framework based on multi-level progressive learning with multi-domain features. The framework consists of a multi-domain feature extraction process for EEG and fNIRS, a feature selection process based on atomic search optimization, and a multi-domain feature fusion process based on multi-level progressive machine learning. The proposed method was validated on EEG-fNIRS-based motor imagery (MI) and mental arithmetic (MA) tasks involving 29 subjects, and the experimental results show that multi-domain features provide better classification performance than single-domain features, and multi-modality provides better classification performance than single-modality. Furthermore, the experimental results and comparison with other methods demonstrated the effectiveness and superiority of the proposed method in EEG and fNIRS information fusion, it can achieve an average classification accuracy of 96.74% in the MI task and 98.42% in the MA task. Our proposed method may provide a general framework for future fusion processing of multimodal brain signals based on EEG-fNIRS.

## 91. The Application of Entropy in Motor Imagery Paradigms of Brain–Computer Interfaces

**Authors:** Chengzhen Wu, Bo Yao, Xin Zhang, Ting Li, Jinhai Wang, Jiangbo Pu (2025)
**DOI/URL:** 10.3390/brainsci15020168

Background: In motor imagery brain–computer interface (MI-BCI) research, electroencephalogram (EEG) signals are complex and nonlinear. This complexity and nonlinearity render signal processing and classification challenging when employing traditional linear methods. Information entropy, with its intrinsic nonlinear characteristics, effectively captures the dynamic behavior of EEG signals, thereby addressing the limitations of traditional methods in capturing linear features. However, the multitude of entropy types leads to unclear application scenarios, with a lack of systematic descriptions. Methods: This study conducted a review of 63 high-quality research articles focused on the application of entropy in MI-BCI, published between 2019 and 2023. It summarizes the names, functions, and application scopes of 13 commonly used entropy measures. Results: The findings indicate that sample entropy (16.3%), Shannon entropy (13%), fuzzy entropy (12%), permutation entropy (9.8%), and approximate entropy (7.6%) are the most frequently utilized entropy features in MI-BCI. The majority of studies employ a single entropy feature (79.7%), with dual entropy (9.4%) and triple entropy (4.7%) being the most prevalent combinations in multiple entropy applications. The incorporation of entropy features can significantly enhance pattern classification accuracy (by 8–10%). Most studies (67%) utilize public datasets for classification verification, while a minority design and conduct experiments (28%), and only 5% combine both methods. Conclusions: Future research should delve into the effects of various entropy features on specific problems to clarify their application scenarios. As research methodologies continue to evolve and advance, entropy features are poised to play a significant role in a wide array of fields and contexts.

## 92. The clinical applications of brain–computer interfaces

**Authors:** Chao-Ran Jia, Jian-Wei Huang, Ying‐Qing Hu, Hai‐Yun Zhou, Hong‐Yu Liu, Xin Liu, Hai Zhang, Zu‐Cheng Shen, Wen‐Sheng Li, Shuang-Qi Gao, Ying Guo (2025)
**DOI/URL:** 10.1002/brx2.70033

With the establishment of interdisciplinary platforms in medical engineering, the twenty‐first century has witnessed rapid advancements in brain‒computer interface (BCI) technology, demonstrating significant potential in clinical applications. The fundamental framework of BCIs encompasses signal acquisition, preprocessing, feature extraction, signal translation, and control devices. This article explores the applications of BCIs across various disorders, including post‐stroke motor recovery, consciousness disorders, mental health, and neurological diseases. Through technological innovations, BCI technology has assisted patients in overcoming communication and motor impairments resulting from neurological damage. By bypassing damaged neural pathways and enabling bidirectional interactions with brain signals, BCIs facilitate the gradual rehabilitation of motor functions in post‐stroke patients and show promise in treating psychiatric disorders such as depression. Compared with traditional treatment methods, BCI technology has several unique advantages. Despite challenges in signal processing accuracy, hardware stability, and real‐time data processing technology, technological innovation and interdisciplinary collaboration facilitate greater breakthroughs in the near future for BCIs. In summary, the clinical application of BCI technology presents unprecedented opportunities and challenges in modern healthcare, underscoring the need for continued research and development in this area.

## 93. Comparative Analysis of Neural Decoding Algorithms for Brain-Machine Interfaces

**Authors:** Olena Shevchenko, Sofiia Yeremeieva, Brokoslaw Laschowski (2024)
**DOI/URL:** 10.1101/2024.12.05.627080

Accurate neural decoding of brain dynamics remains a significant and open challenge in brain-machine interfaces. While various signal processing, feature extraction, and classification algorithms have been proposed, a systematic comparison of these is lacking. Accordingly, here we conducted one of the largest comparative studies evaluating different combinations of state-of-the-art algorithms for motor neural decoding to find the optimal combination. We studied three signal processing methods (i.e., artifact subspace reconstruction, surface Laplacian filtering, and data normalization), four feature extractors (i.e., common spatial patterns, independent component analysis, short-time Fourier transform, and no feature extraction), and four machine learning classifiers (i.e., support vector machine, linear discriminant analysis, convolutional neural networks, and long short-term memory networks). Using a large-scale EEG dataset, we optimized each combination for individual subjects (i.e., resulting in 672 total experiments) and evaluated performance based on classification accuracy. We also compared the computational and memory storage requirements, which are important for real-time embedded computing. Our comparative analysis provides novel insights that help inform the design of next-generation neural decoding algorithms for brain-machine interfaces used to interact with and control robots and computers.

## 94. Advancements in Image Feature-Based Classification of Motor Imagery EEG Data: A Comprehensive Review

**Authors:** C. Yilmaz, Bahar Hatipoglu Yilmaz (2023)
**DOI/URL:** 10.18280/ts.400507

Non-invasive acquisition and analysis of human brain signals play a crucial role in the development of brain-computer interfaces, enabling their widespread applicability in daily life. Motor imagery has emerged as a prominent technique for the advancement of such interfaces. While initial machine and deep learning studies have shown promising results in the context of motor imagery, several challenges remain to be addressed prior to their extensive adoption. Deep learning, renowned for its automated feature extraction and classification capabilities, has been successfully employed in various domains. Notably, recent research efforts have focused on processing and classifying motor imagery EEG signals using two-dimensional data formats, yielding noteworthy advancements. Although existing literature encompasses reviews primarily centered on machine learning or deep learning techniques, this paper uniquely emphasizes the review of methods for constructing two-dimensional image features, marking the first comprehensive exploration of this subject. In this study, we present an overview of datasets, survey a range of signal-to-image conversion methods, and discuss classification approaches. Furthermore, we comprehensively examine the current challenges and outline future directions for this research domain.

## 95. Online multiclass EEG feature extraction and recognition using modified convolutional neural network method

**Authors:** Haider Abdulkarim, M. Al-Faiz (2021)
**DOI/URL:** 10.11591/IJECE.V11I5.PP4016-4026

Many techniques have been introduced to improve both brain-computer interface (BCI) steps: feature extraction and classification. One of the emerging trends in this field is the implementation of deep learning algorithms. There is a limited number of studies that investigated the application of deep learning techniques in electroencephalography (EEG) feature extraction and classification. This work is intended to apply deep learning for both stages: feature extraction and classification. This paper proposes a modified convolutional neural network (CNN) feature extractorclassifier algorithm to recognize four different EEG motor imagery (MI). In addition, a four-class linear discriminant analysis (LDR) classifier model was built and compared to the proposed CNN model. The paper showed very good results with 92.8% accuracy for one EEG four-class MI set and 85.7% for another set. The results showed that the proposed CNN model outperforms multi-class linear discriminant analysis with an accuracy increase of 28.6% and 17.9% for both MI sets, respectively. Moreover, it has been shown that majority voting for five repetitions introduced an accuracy advantage of 15% and 17.2% for both EEG sets, compared with single trials. This confirms that increasing the number of trials for the same MI gesture improves the recognition accuracy

## 96. Classification of Motor Imagery Hand Movement Directions from EEG extracted Phase Locking Value features for Brain Computer Interfaces

**Authors:** VK Benzy, A. P. Vinod (2019)
**DOI/URL:** 10.1109/TENCON.2019.8929678

Brain-Computer Interface (BCI) systems translate the users intentions coded by brain activity measures into actions through a control signal without using activity of any muscles or peripheral nerves. Usually, in Electroencephalography (EEG) based BCI experiment protocols, different mental tasks are performed to elicit unique brain signal responses, which are recognized by signal processing and machine learning methods. The work presented in this paper extracts the EEG phase synchrony feature called Phase Lock Value (PLV) to decode Motor Imagery (MI) of center-out hand movement in right and left directions. At first, PLV features of all the EEG channel pairs are extracted to detect the level of synchronization corresponding to the directional hand movements. The most significant channel pairs selected from direction-specific EEG signals corresponding to the imagined hand movement showed characteristic changes in PLV features. Mean Percentage Difference of PLV features are calculated and compared in different frequency bands to identify the most discriminative frequency band for the hand movement classification. The extracted PLV features offer 5.34% improvement in classification accuracy for the 7 best performing subjects compared to the relevant method in literature.

## 97. IENet: a robust convolutional neural network for EEG based brain-computer interfaces

**Authors:** Yipeng Du, Jian Liu (2022)
**DOI/URL:** 10.1088/1741-2552/ac7257

Objective. Brain-computer interfaces (BCIs) based on electroencephalogram (EEG) develop into novel application areas with more complex scenarios, which put forward higher requirements for the robustness of EEG signal processing algorithms. Deep learning can automatically extract discriminative features and potential dependencies via deep structures, demonstrating strong analytical capabilities in numerous domains such as computer vision and natural language processing. Making full use of deep learning technology to design a robust algorithm that is capable of analyzing EEG across BCI paradigms is our main work in this paper. Approach. Inspired by InceptionV4 and InceptionTime architecture, we introduce a neural network ensemble named InceptionEEG-Net (IENet), where multi-scale convolutional layer and convolution of length 1 enable model to extract rich high-dimensional features with limited parameters. In addition, we propose the average receptive field (RF) gain for convolutional neural networks (CNNs), which optimizes IENet to detect long patterns at a smaller cost. We compare with the current state-of-the-art methods across five EEG-BCI paradigms: steady-state visual evoked potentials (VEPs), epilepsy EEG, overt attention P300 VEPs, covert attention P300 visual-EPs and movement-related cortical potentials. Main results. The classification results show that the generalizability of IENet is on par with the state-of-the-art paradigm-agnostic models on test datasets. Furthermore, the feature explainability analysis of IENet illustrates its capability to extract neurophysiologically interpretable features for different BCI paradigms, ensuring the reliability of algorithm. Significance. It can be seen from our results that IENet can generalize to different BCI paradigms. And it is essential for deep CNNs to increase the RF size using average RF gain.

## 98. Feature extraction based on microstate sequences for EEG–based emotion recognition

**Authors:** Jing Chen, Zexian Zhao, Q. Shu, Guolong Cai (2022)
**DOI/URL:** 10.3389/fpsyg.2022.1065196

Recognizing emotion from Electroencephalography (EEG) is a promising and valuable research issue in the field of affective brain-computer interfaces (aBCI). To improve the accuracy of emotion recognition, an emotional feature extraction method is proposed based on the temporal information in the EEG signal. This study adopts microstate analysis as a spatio-temporal analysis for EEG signals. Microstates are defined as a series of momentary quasi-stable scalp electric potential topographies. Brain electrical activity could be modeled as being composed of a time sequence of microstates. Microstate sequences provide an ideal macroscopic window for observing the temporal dynamics of spontaneous brain activity. To further analyze the fine structure of the microstate sequence, we propose a feature extraction method based on k-mer. K-mer is a k-length substring of a given sequence. It has been widely used in computational genomics and sequence analysis. We extract features that are based on the D 2 ∗ statistic of k-mer. In addition, we also extract four parameters (duration, occurrence, time coverage, GEV) of each microstate class as features at the coarse level. We conducted experiments on the DEAP dataset to evaluate the performance of the proposed features. The experimental results demonstrate that the fusion of features in fine and coarse levels can effectively improve classification accuracy.

## 99. Optimizing Bioimaging: Quantum Computing-Inspired Bald Eagle Search Optimization for Motor Imaging EEG Feature Selection

**Authors:** Chandan Choubey, M. Dhanalakshmi, S. Karunakaran, Gaurav Vishnu Londhe, Vrince Vimal, M. Kirubakaran (2025)
**DOI/URL:** 10.1177/15500594251325273

One of the most important objectives in brain–computer interfaces (BCI) is to identify a subset of characteristics that represents the electroencephalographic (EEG) signal while eliminating elements that are duplicate or irrelevant. Neuroscientific research is advanced by bioimaging, especially in the field of BCI. In this work, a novel quantum computing-inspired bald eagle search optimization (QC-IBESO) method is used to improve the effectiveness of motor imagery EEG feature selection. This method can prevent the dimensionality curse and improve the classification accuracy of the system by lowering the dimensionality of the dataset. The dataset that was used in the assessment is from BCI Competition-III IV-A. To normalize the EEG data, Z-score normalization is used in the preprocessing stage. Principal component analysis reduces dimensionality and preserves important information during feature extraction. In the context of motor imagery, the QC-IBESO approach is utilized to select certain EEG characteristics for bioimaging. This facilitates the exploration of intricate search spaces and improves the detection of critical EEG signals related to motor imagery. The study contrasts the suggested approach with conventional methods like neural networks, support vector machines and logistic regression. To evaluate the efficacy of the suggested strategy in contrast to current techniques, performance measures such as F1-score, precision, accuracy and recall are computed. This work advances the field of feature selection techniques in bioimaging and opens up a novel and intriguing direction for the investigation of quantum-inspired optimization in neuroimaging.

## 100. Transfer Learning for Brain–Computer Interfaces: A Euclidean Space Data Alignment Approach

**Authors:** He He, Dongrui Wu (2018)
**DOI/URL:** 10.1109/TBME.2019.2913914

Objective: This paper targets a major challenge in developing practical electroencephalogram (EEG)-based brain–computer interfaces (BCIs): how to cope with individual differences so that better learning performance can be obtained for a new subject, with minimum or even no subject-specific data? Methods: We propose a novel approach to align EEG trials from different subjects in the Euclidean space to make them more similar, and hence improve the learning performance for a new subject. Our approach has three desirable properties: first, it aligns the EEG trials directly in the Euclidean space, and any signal processing, feature extraction, and machine learning algorithms can then be applied to the aligned trials; second, its computational cost is very low; and third, it is unsupervised and does not need any label information from the new subject. Results: Both offline and simulated online experiments on motor imagery classification and event-related potential classification verified that our proposed approach outperformed a state-of-the-art Riemannian space data alignment approach, and several approaches without data alignment. Conclusion: The proposed Euclidean space EEG data alignment approach can greatly facilitate transfer learning in BCIs. Significance: Our proposed approach is effective, efficient, and easy to implement. It could be an essential pre-processing step for EEG-based BCIs.

## 101. Graph neural network based on brain inspired forward-forward mechanism for motor imagery classification in brain-computer interfaces

**Authors:** Qiwei Xue, Yu-jia Song, Huapeng Wu, Yong Cheng, Hongtao Pan (2024)
**DOI/URL:** 10.3389/fnins.2024.1309594

Introduction Within the development of brain-computer interface (BCI) systems, it is crucial to consider the impact of brain network dynamics and neural signal transmission mechanisms on electroencephalogram-based motor imagery (MI-EEG) tasks. However, conventional deep learning (DL) methods cannot reflect the topological relationship among electrodes, thereby hindering the effective decoding of brain activity. Methods Inspired by the concept of brain neuronal forward-forward (F-F) mechanism, a novel DL framework based on Graph Neural Network combined forward-forward mechanism (F-FGCN) is presented. F-FGCN framework aims to enhance EEG signal decoding performance by applying functional topological relationships and signal propagation mechanism. The fusion process involves converting the multi-channel EEG into a sequence of signals and constructing a network grounded on the Pearson correlation coeffcient, effectively representing the associations between channels. Our model initially pre-trains the Graph Convolutional Network (GCN), and fine-tunes the output layer to obtain the feature vector. Moreover, the F-F model is used for advanced feature extraction and classification. Results and discussion Achievement of F-FGCN is assessed on the PhysioNet dataset for a four-class categorization, compared with various classical and state-of-the-art models. The learned features of the F-FGCN substantially amplify the performance of downstream classifiers, achieving the highest accuracy of 96.11% and 82.37% at the subject and group levels, respectively. Experimental results affirm the potency of FFGCN in enhancing EEG decoding performance, thus paving the way for BCI applications.

## 102. Learning Robust Deep Visual Representations from EEG Brain Recordings

**Authors:** Prajwal Singh, Dwip Dalal, Gautam Vashishtha, KrishnaP Miyapuram, S. Raman (2023)
**DOI/URL:** 10.1109/WACV57701.2024.00738

Decoding the human brain has been a hallmark of neuroscientists and Artificial Intelligence researchers alike. Reconstruction of visual images from brain Electroencephalography (EEG) signals has garnered a lot of interest due to its applications in brain-computer interfacing. This study proposes a two-stage method where the first step is to obtain EEG-derived features for robust learning of deep representations and subsequently utilize the learned representation for image generation and classification. We demonstrate the generalizability of our feature extraction pipeline across three different datasets using deep-learning architectures with supervised and contrastive learning methods. We have performed the zero-shot EEG classification task to support the generalizability claim further. We observed that a subject invariant linearly separable visual representation was learned using EEG data alone in an unimodal setting that gives better k-means accuracy as compared to a joint representation learning between EEG and images. Finally, we propose a novel framework to transform unseen images into the EEG space and reconstruct them with approximation, showcasing the potential for image reconstruction from EEG signals. Our proposed image synthesis method from EEG shows 62.9% and 36.13% inception score improvement on the EEGCVPR40 and the Thoughtviz datasets, which is better than state-of-the-art performance in GAN 1.

## 103. Brain–Computer Interface Based on Steady-State Visual Evoked Potential Using Quick-Response Code Pattern for Wheelchair Control

**Authors:** Nannaphat Siribunyaphat, Yunyong Punsawad (2023)
**DOI/URL:** 10.3390/s23042069

Brain–computer interfaces (BCIs) are widely utilized in control applications for people with severe physical disabilities. Several researchers have aimed to develop practical brain-controlled wheelchairs. An existing electroencephalogram (EEG)-based BCI based on steady-state visually evoked potential (SSVEP) was developed for device control. This study utilized a quick-response (QR) code visual stimulus pattern for a robust existing system. Four commands were generated using the proposed visual stimulation pattern with four flickering frequencies. Moreover, we employed a relative power spectrum density (PSD) method for the SSVEP feature extraction and compared it with an absolute PSD method. We designed experiments to verify the efficiency of the proposed system. The results revealed that the proposed SSVEP method and algorithm yielded an average classification accuracy of approximately 92% in real-time processing. For the wheelchair simulated via independent-based control, the proposed BCI control required approximately five-fold more time than the keyboard control for real-time control. The proposed SSVEP method using a QR code pattern can be used for BCI-based wheelchair control. However, it suffers from visual fatigue owing to long-time continuous control. We will verify and enhance the proposed system for wheelchair control in people with severe physical disabilities.

## 104. Dual regularized feature extraction and adaptation for cross-subject motor imagery EEG classification

**Authors:** Tian-jian Luo (2022)
**DOI/URL:** 10.1109/BIBM55620.2022.9995282

Bioinformatics theoretical-based methods have attracted great attention in rehabilitation-assisted motor imagery (MI) brain-computer interface (BCI) using EEG, and gained promising results to deal with cross-subject MI-EEG classification. However, most of the existing methods are either suffered from outliers during feature learning across subjects or inefficient in computing discriminative features. Thus, they may not be able to obtain an optimal feature representation across subjects, resulting in classification performance deterioration. This paper proposes a dual regularization-based MI-EEG feature learning framework, in which feature weighted common spatial pattern, joint probability distribution alignment, and minimum Mahalanobis distance are taken into account, thus facilitating cross-subject classification. Specially, we adopt the multi-source to single target domain adaptation strategy, which is more suitable for real-world MI-BCI scenarios. Empirical studies on three benchmark MI-EEG datasets reveal the effectiveness and efficiency of the proposed method, which achieves a great performance improvement with less time consumption.

## 105. Design and Implementation of EEG-fNIRS Based Brain-Computer Interface Paradigm for Musical Imagery

**Authors:** Weiyue Zhu, Lin Fang, Xinmiao Cao, Wenhao Li, Kai Wu, Jing Zhou (2024)
**DOI/URL:** 10.1109/ICHCI63580.2024.10808007

In this experiment, EEG-fNIRS simultaneous acquisition technology was used to design and implement a brain-computer interface paradigm for musical imagery, and the self-designed experimental paradigm was utilized for sampling with a size of 40 college student subjects, data processing, time-frequency domain feature extraction, statistical analysis based on EEG, fNIRS in the resting, white noise, listening, and recall phases, and neurovascular coupling were carried out. Finally, music recognition based on six songs was performed by machine learning, resulting in the best recognized song as well as its features. In the future, the construction of a multimodal database based on simple elements of musical imagery is planned.

## 106. EEG-based Brain-Computer Interface System via Time-Locked Visual Attention for Assistive Device Control

**Authors:** Natjamee Tohkhwan, Charoenporn Bouyam, Theerat Saichoo, Nannaphat Siribunyaphat, Manorot Borirakarawin, Yunyong Punsawad (2024)
**DOI/URL:** 10.1109/ECTI-CON60892.2024.10594880

This work proposes a brain-computer interface system using visual attention paradigm. We used count-down numbers for different periods of attention to command creation from EEG signals. Electrode positions and feature extraction algorithm were verified. By using four number and the proposed simple classification method can produce four commands. The results showed that EEG from the occipital region using an alpha-beta ratio achieved an average classification accuracy of 80. 56% and 62.06% for two and four commands, respectively. The proposed system can be used for severely physically disabled people for control and communication in the future. However, the proposed needs to improve for higher efficiency by session training and using complex algorithms and classifiers.

## 107. Multi-Class Classification Methods for EEG Signals of Lower-Limb Rehabilitation Movements

**Authors:** Shuangling Ma, Zijie Situ, Xiaobo Peng, Zhangyang Li, Ying Huang (2025)
**DOI/URL:** 10.3390/biomimetics10070452

Brain–Computer Interfaces (BCIs) enable direct communication between the brain and external devices by decoding motor intentions from EEG signals. However, the existing multi-class classification methods for motor imagery EEG (MI-EEG) signals are hindered by low signal quality and limited accuracy, restricting their practical application. This study focuses on rehabilitation training scenarios, aiming to capture the motor intentions of patients with partial or complete motor impairments (such as stroke survivors) and provide feedforward control commands for exoskeletons. This study developed an EEG acquisition protocol specifically for use with lower-limb rehabilitation motor imagery (MI). It systematically explored preprocessing techniques, feature extraction strategies, and multi-classification algorithms for multi-task MI-EEG signals. A novel 3D EEG convolutional neural network (3D EEG-CNN) that integrates time/frequency features is proposed. Evaluations on a self-collected dataset demonstrated that the proposed model achieved a peak classification accuracy of 66.32%, substantially outperforming conventional approaches and demonstrating notable progress in the multi-class classification of lower-limb motor imagery tasks.

## 108. A non Invasive Brain-Computer-Interface for Service Robotics

**Authors:** F. Ahmed, Hashim Iqbal, Ahmed Nouman, H. F. Maqbool, Saqib Zafar, M. Saleem (2023)
**DOI/URL:** 10.1109/ICAI58407.2023.10136672

A Brain-Computer Interface (BCI) enables individuals to control a system solely through their brain activity, without relying on physical movement. These interfaces have numerous applications, particularly in assisting individuals with paralysis. Our research paper details a BCI interface that can classify and control seven wheelchair movements: forward, backward, left, right, stair climbing upwards, stair climbing downwards, and stop. We collected raw signal data using the electroencephalog-raphy (EEG) technique from healthy volunteers, which we then filter before feeding into the feature extraction and classification stages. We evaluated our approach using three classification algorithms: Convolution Neural Network (CNN), Support Vector Machines (SVM), and Random Forest Classifier, and compared their performance. Our experimental results demonstrate that our proposed approach is highly promising for implementing BCI, with a classification accuracy of 99% using a Random Forest Classifier.

## 109. Cross-Modal Transfer Learning From EEG to Functional Near-Infrared Spectroscopy for Classification Task in Brain-Computer Interface System

**Authors:** Yuqing Wang, Zhiqiang Yang, Hongfei Ji, Jie Li, Lingyu Liu, Zhuang Jie (2022)
**DOI/URL:** 10.3389/fpsyg.2022.833007

The brain-computer interface (BCI) based on functional near-infrared spectroscopy (fNIRS) has received more and more attention due to its vast application potential in emotion recognition. However, the relatively insufficient investigation of the feature extraction algorithms limits its use in practice. In this article, to improve the performance of fNIRS-based BCI, we proposed a method named R-CSP-E, which introduces EEG signals when computing fNIRS signals’ features based on transfer learning and ensemble learning theory. In detail, we used the Independent Component Analysis (ICA) algorithm for the correspondence between the sources of the two signals. We then introduced the EEG signals when computing the spatial filter based on a modified Common Spatial Pattern (CSP) algorithm. Experimental results on public datasets show that the proposed method in this paper outperforms traditional methods without transfer. In general, the mean classification accuracy can be increased by up to 5%. To our knowledge, it is an innovation that we tried to apply transfer learning between EEG and fNIRS. Our study’s findings not only prove the potential of the transfer learning algorithm in cross-model brain-computer interface, but also offer a new and innovative perspective to research the hybrid brain-computer interface.

## 110. Exploring high-density corticomuscular networks after stroke to enable a hybrid Brain-Computer Interface for hand motor rehabilitation

**Authors:** F. Pichiorri, J. Toppi, V. de Seta, E. Colamarino, M. Masciullo, F. Tamburella, M. Lorusso, F. Cincotti, D. Mattia (2023)
**DOI/URL:** 10.1186/s12984-023-01127-6

Background Brain-Computer Interfaces (BCI) promote upper limb recovery in stroke patients reinforcing motor related brain activity (from electroencephalogaphy, EEG). Hybrid BCIs which include peripheral signals (electromyography, EMG) as control features could be employed to monitor post-stroke motor abnormalities. To ground the use of corticomuscular coherence (CMC) as a hybrid feature for a rehabilitative BCI, we analyzed high-density CMC networks (derived from multiple EEG and EMG channels) and their relation with upper limb motor deficit by comparing data from stroke patients with healthy participants during simple hand tasks. Methods EEG (61 sensors) and EMG (8 muscles per arm) were simultaneously recorded from 12 stroke (EXP) and 12 healthy participants (CTRL) during simple hand movements performed with right/left (CTRL) and unaffected/affected hand (EXP, UH/AH). CMC networks were estimated for each movement and their properties were analyzed by means of indices derived ad-hoc from graph theory and compared among groups. Results Between-group analysis showed that CMC weight of the whole brain network was significantly reduced in patients during AH movements. The network density was increased especially for those connections entailing bilateral non-target muscles. Such reduced muscle-specificity observed in patients was confirmed by muscle degree index (connections per muscle) which indicated a connections’ distribution among non-target and contralateral muscles and revealed a higher involvement of proximal muscles in patients. CMC network properties correlated with upper-limb motor impairment as assessed by Fugl-Meyer Assessment and Manual Muscle Test in patients. Conclusions High-density CMC networks can capture motor abnormalities in stroke patients during simple hand movements. Correlations with upper limb motor impairment support their use in a BCI-based rehabilitative approach.

## 111. Detection of Movement Intention in EEG-Based Brain-Computer Interfaces Using Fourier-Based Synchrosqueezing Transform

**Authors:** Nedime Karakullukcu, Bülent Yilmaz (2021)
**DOI/URL:** 10.1142/S0129065721500593

Patients with motor impairments need caregivers' help to initiate the operation of brain-computer interfaces (BCI). This study aims to identify and characterize movement intention using multichannel electroencephalography (EEG) signals as a means to initiate BCI systems without extra accessories/methodologies. We propose to discriminate the resting and motor imagery (MI) states with high accuracy using Fourier-based synchrosqueezing transform (FSST) as a feature extractor. FSST has been investigated and compared with other popular approaches in 28 healthy subjects for a total of 6657 trials. The accuracy and f-measure values were obtained as 99.8% and 0.99, respectively, when FSST was used as the feature extractor and singular value decomposition (SVD) as the feature selection method and support vector machines as the classifier. Moreover, this study investigated the use of data that contain certain amount of noise without any preprocessing in addition to the clean counterparts. Furthermore, the statistical analysis of EEG channels with the best discrimination (of resting and MI states) characteristics demonstrated that F4-Fz-C3-Cz-C4-Pz channels and several statistical features had statistical significance levels, [Formula: see text], less than 0.05. This study showed that the preparation of the movement can be detected in real-time employing FSST-SVD combination and several channels with minimal pre-processing effort.

## 112. From Neural Networks to Emotional Networks: A Systematic Review of EEG-Based Emotion Recognition in Cognitive Neuroscience and Real-World Applications

**Authors:** E. Gkintoni, Anthimos Aroutzidis, H. Antonopoulou, C. Halkiopoulos (2025)
**DOI/URL:** 10.3390/brainsci15030220

Background/Objectives: This systematic review presents how neural and emotional networks are integrated into EEG-based emotion recognition, bridging the gap between cognitive neuroscience and practical applications. Methods: Following PRISMA, 64 studies were reviewed that outlined the latest feature extraction and classification developments using deep learning models such as CNNs and RNNs. Results: Indeed, the findings showed that the multimodal approaches were practical, especially the combinations involving EEG with physiological signals, thus improving the accuracy of classification, even surpassing 90% in some studies. Key signal processing techniques used during this process include spectral features, connectivity analysis, and frontal asymmetry detection, which helped enhance the performance of recognition. Despite these advances, challenges remain more significant in real-time EEG processing, where a trade-off between accuracy and computational efficiency limits practical implementation. High computational cost is prohibitive to the use of deep learning models in real-world applications, therefore indicating a need for the development and application of optimization techniques. Aside from this, the significant obstacles are inconsistency in labeling emotions, variation in experimental protocols, and the use of non-standardized datasets regarding the generalizability of EEG-based emotion recognition systems. Discussion: These challenges include developing adaptive, real-time processing algorithms, integrating EEG with other inputs like facial expressions and physiological sensors, and a need for standardized protocols for emotion elicitation and classification. Further, related ethical issues with respect to privacy, data security, and machine learning model biases need to be much more proclaimed to responsibly apply research on emotions to areas such as healthcare, human–computer interaction, and marketing. Conclusions: This review provides critical insight into and suggestions for further development in the field of EEG-based emotion recognition toward more robust, scalable, and ethical applications by consolidating current methodologies and identifying their key limitations.

## 113. Systematic Review of Single-Channel EEG-Based Drowsiness Detection Methods

**Authors:** Dr Venkata Phanikrishna B (Balam) (2024)
**DOI/URL:** 10.1109/TITS.2024.3442249

Drowsiness is characterized by reduced attentiveness, commonly experienced during the transition from wakefulness to sleepiness. It can decrease an individual’s alertness, thereby increasing the risk of accidents during activities such as driving, crane operation, working in mining areas, and industrial machinery operation. The detection of drowsiness plays an important role in preventing such accidents. Numerous methods exist for drowsiness detection, including Subjective, Vehicle, Behavioral, and Physiological approaches. Among these, Physiological methods, particularly those utilizing Electroencephalogram (EEG) data combined with artificial intelligence, have proven effective in detecting drowsiness. These methods excel in capturing physiological changes in the body during drowsiness and the potential for gathering information from the human brain during this state. EEG data-based Brain-Computer interface (BCI) systems have been popular for detecting drowsiness. Single-channel EEG signal analysis BCIs have been highly preferred for their ease and convenient usage in real-time applications. While some progress has been made in the single-channel EEG BCI, substantial progress is still needed. This paper provides a state-of-the-art analysis of recent developments in the single-channel EEG-based drowsiness detection methods. Ultimately, this review study explores potential avenues for the future development of single-channel EEG-based drowsiness detection.

## 114. Research on Feature Extraction Algorithm Commonly Used in Brain-computer Interface Technology

**Authors:** Yifan Zhang, Yao-Kun Wang (2021)
**DOI/URL:** 10.1088/1742-6596/1861/1/012027

Brain-computer interface (BCI) is an effective and direct channel of information exchange between human brain and external devices such as computer, which can provide auxiliary information acquisition and treatment means for the medical and other fields in the future. This paper focuses on four kinds of feature extraction algorithms such as power spectral density (PSD), wavelet transform, Hilbert-Huang transform (HHT) and common space pattern (CSP), which are commonly used to process abnormal electroencephalogram (EEG) signals in brain-computer interface technology. This paper also introduces their respective principles, characteristics and application fields, analyzes and compares the advantages and disadvantages of these algorithms, and obtains the development direction of feature extraction algorithms in the future. Finally, it also briefly discusses the ethical issues brought about by brain-computer interface technology.

## 115. Hybrid Brain–Computer Interface Spellers: A Walkthrough Recent Advances in Signal Processing Methods and Challenges

**Authors:** Nupur Chugh, Swati Aggarwal (2022)
**DOI/URL:** 10.1080/10447318.2022.2093445

Abstract Hybrid brain computer interfaces (hBCIs) have emerged as a possible path to integrated brain-computer interaction in current history. hBCI, is a device formed by the amalgamation of control signal and bio-signal combination of control signal with one or more bio-signals that enhances system performance and usability. Assistive technology, spelling, and gaming are some of the primary areas where hBCI can be used. Among these, hBCI spellers are the popular application that has opened up a slew of new possibilities of communication for paralyzed individuals. The goal of this review is to provide prospect on current state of hBCI spellers covering types of hBCI, signal processing methods and evaluation with emphasis on feature extraction techniques and classification methods used by these studies. The authors anticipate that this analysis will serve as a foundation for ongoing studies on hBCI spellers.

## 116. Classification of Motor Imagery Based on Multi-Scale Feature Extraction and the Channel-Temporal Attention Module

**Authors:** Runze Wu, Jing Jin, I. Daly, Xingyu Wang, A. Cichocki (2023)
**DOI/URL:** 10.1109/TNSRE.2023.3294815

Motor imagery (MI) is a popular paradigm for controlling electroencephalogram (EEG) based Brain-Computer Interface (BCI) systems. Many methods have been developed to attempt to accurately classify MI-related EEG activity. Recently, the development of deep learning has begun to draw increasing attention in the BCI research community because it does not need to use sophisticated signal preprocessing and can automatically extract features. In this paper, we propose a deep learning model for use in MI-based BCI systems. Our model makes use of a convolutional neural network based on a multi-scale and channel-temporal attention module (CTAM), which called MSCTANN. The multi-scale module is able to extract a large number of features, while the attention module includes both a channel attention module and a temporal attention module, which together allow the model to focus attention on the most important features extracted from the data. The multi-scale module and the attention module are connected by a residual module, which avoids the degradation of the network. Our network model is built from these three core modules, which combine to improve the recognition ability of the network for EEG signals. Our experimental results on three datasets (BCI competition IV 2a, III IIIa and IV 1) show that our proposed method has better performance than other state-of-the-art methods, with accuracy rates of 80.6%, 83.56% and 79.84%. Our model has stable performance in decoding EEG signals and achieves efficient classification performance while using fewer network parameters than other comparable state-of-the-art methods.

## 117. A Systematic Review of Virtual Reality and Robot Therapy as Recent Rehabilitation Technologies Using EEG-Brain–Computer Interface Based on Movement-Related Cortical Potentials

**Authors:** Ramadhan Rashid Said, Md Belal Bin Heyat, Keer Song, Chao Tian, Zhe Wu (2022)
**DOI/URL:** 10.3390/bios12121134

To enhance the treatment of motor function impairment, patients’ brain signals for self-control as an external tool may be an extraordinarily hopeful option. For the past 10 years, researchers and clinicians in the brain–computer interface (BCI) field have been using movement-related cortical potential (MRCP) as a control signal in neurorehabilitation applications to induce plasticity by monitoring the intention of action and feedback. Here, we reviewed the research on robot therapy (RT) and virtual reality (VR)-MRCP-based BCI rehabilitation technologies as recent advancements in human healthcare. A list of 18 full-text studies suitable for qualitative review out of 322 articles published between 2000 and 2022 was identified based on inclusion and exclusion criteria. We used PRISMA guidelines for the systematic review, while the PEDro scale was used for quality evaluation. Bibliometric analysis was conducted using the VOSviewer software to identify the relationship and trends of key items. In this review, 4 studies used VR-MRCP, while 14 used RT-MRCP-based BCI neurorehabilitation approaches. The total number of subjects in all identified studies was 107, whereby 4.375 ± 6.3627 were patient subjects and 6.5455 ± 3.0855 were healthy subjects. The type of electrodes, the epoch, classifiers, and the performance information that are being used in the RT- and VR-MRCP-based BCI rehabilitation application are provided in this review. Furthermore, this review also describes the challenges facing this field, solutions, and future directions of these smart human health rehabilitation technologies. By key items relationship and trends analysis, we found that motor control, rehabilitation, and upper limb are important key items in the MRCP-based BCI field. Despite the potential of these rehabilitation technologies, there is a great scarcity of literature related to RT and VR-MRCP-based BCI. However, the information on these rehabilitation methods can be beneficial in developing RT and VR-MRCP-based BCI rehabilitation devices to induce brain plasticity and restore motor impairment. Therefore, this review will provide the basis and references of the MRCP-based BCI used in rehabilitation applications for further clinical and research development.

## 118. Rhythmic temporal prediction enhances neural representations of movement intention for brain–computer interface

**Authors:** Jiayuan Meng, Yingru Zhao, Kun Wang, Jinsong Sun, Weibo Yi, Fangzhou Xu, Minpeng Xu, Dong Ming (2023)
**DOI/URL:** 10.1088/1741-2552/ad0650

Objective. Detecting movement intention is a typical use of brain–computer interfaces (BCI). However, as an endogenous electroencephalography (EEG) feature, the neural representation of movement is insufficient for improving motor-based BCI. This study aimed to develop a new movement augmentation BCI encoding paradigm by incorporating the cognitive function of rhythmic temporal prediction, and test the feasibility of this new paradigm in optimizing detections of movement intention. Methods. A visual-motion synchronization task was designed with two movement intentions (left vs. right) and three rhythmic temporal prediction conditions (1000 ms vs. 1500 ms vs. no temporal prediction). Behavioural and EEG data of 24 healthy participants were recorded. Event-related potentials (ERPs), event-related spectral perturbation induced by left- and right-finger movements, the common spatial pattern (CSP) and support vector machine, Riemann tangent space algorithm and logistic regression were used and compared across the three temporal prediction conditions, aiming to test the impact of temporal prediction on movement detection. Results. Behavioural results showed significantly smaller deviation time for 1000 ms and 1500 ms conditions. ERP analyses revealed 1000 ms and 1500 ms conditions led to rhythmic oscillations with a time lag in contralateral and ipsilateral areas of movement. Compared with no temporal prediction, 1000 ms condition exhibited greater beta event-related desynchronization (ERD) lateralization in motor area (P< 0.001) and larger beta ERD in frontal area (P< 0.001). 1000 ms condition achieved an averaged left–right decoding accuracy of 89.71% using CSP and 97.30% using Riemann tangent space, both significantly higher than no temporal prediction. Moreover, movement and temporal information can be decoded simultaneously, achieving 88.51% four-classification accuracy. Significance. The results not only confirm the effectiveness of rhythmic temporal prediction in enhancing detection ability of motor-based BCI, but also highlight the dual encodings of movement and temporal information within a single BCI paradigm, which is promising to expand the range of intentions that can be decoded by the BCI.

## 119. A2FWPO: Anti-aliasing filter based on whale parameter optimization method for feature extraction and recognition of dance motor imagery EEG

**Authors:** Tianliang Huang, Ziyue Luo, Yin Lyu (2023)
**DOI/URL:** 10.2298/csis221222033h

The classification accuracy of EEG signals based on traditional machine
 learning methods is low. Therefore, this paper proposes a new model for the
 feature extraction and recognition of dance motor imagery EEG, which makes
 full use of the advantage of anti-aliasing filter based on whale parameter
 optimization method. The anti-aliasing filter is used for preprocessing, and
 the filtered signal is extracted by two-dimensional empirical wavelet
 transform. The extracted feature is input to the robust support matrix
 machine to complete pattern recognition. In pattern recognition process, an
 improved whale algorithm is used to dynamically adjust the optimal
 parameters of individual subjects. Experiments are carried out on two public
 data sets to verify that anti-aliasing filter-based preprocessing can
 improve signal feature discrimination. The improved whale algorithm can find
 the optimal parameters of robust support matrix machine classification for
 individuals. This presented method can improve the recognition rate of dance
 motion image. Compared with other advanced methods, the proposed method
 requires less samples and computing resources, and it is suitable for the
 practical application of brain-computer interface.

## 120. Evaluation of an English language phoneme-based imagined speech brain computer interface with low-cost electroencephalography

**Authors:** John Larocco, Qudsia Tahmina, Sam Lecian, Jason Moore, Cole Helbig, Surya Gupta (2023)
**DOI/URL:** 10.3389/fninf.2023.1306277

Introduction Paralyzed and physically impaired patients face communication difficulties, even when they are mentally coherent and aware. Electroencephalographic (EEG) brain–computer interfaces (BCIs) offer a potential communication method for these people without invasive surgery or physical device controls. Methods Although virtual keyboard protocols are well documented in EEG BCI paradigms, these implementations are visually taxing and fatiguing. All English words combine 44 unique phonemes, each corresponding to a unique EEG pattern. In this study, a complete phoneme-based imagined speech EEG BCI was developed and tested on 16 subjects. Results Using open-source hardware and software, machine learning models, such as k-nearest neighbor (KNN), reliably achieved a mean accuracy of 97 ± 0.001%, a mean F1 of 0.55 ± 0.01, and a mean AUC-ROC of 0.68 ± 0.002 in a modified one-versus-rest configuration, resulting in an information transfer rate of 304.15 bits per minute. In line with prior literature, the distinguishing feature between phonemes was the gamma power on channels F3 and F7. Discussion However, adjustments to feature selection, trial window length, and classifier algorithms may improve performance. In summary, these are iterative changes to a viable method directly deployable in current, commercially available systems and software. The development of an intuitive phoneme-based EEG BCI with open-source hardware and software demonstrates the potential ease with which the technology could be deployed in real-world applications.

## 121. Enhancing P300-Based Brain-Computer Interfaces with Hybrid Transfer Learning: A Data Alignment and Fine-Tuning Approach

**Authors:** Sepideh Kilani, Seyedeh Nadia Aghili, M. Hulea (2023)
**DOI/URL:** 10.3390/app13106283

A new approach is introduced to address the subject dependency problem in P300-based brain-computer interfaces (BCI) by using transfer learning. The occurrence of P300, an event-related potential, is primarily associated with changes in natural neuron activity and elicited in response to infrequent stimuli, which can be monitored non-invasively through an electroencephalogram. However, implementing P300-based BCI in real-time requires many training samples and time-consuming calibration, making it challenging to use in practical applications. To tackle these challenges, the proposed approach harnesses the high-level feature extraction capability of a deep neural network, achieved through fine-tuning. To ensure similar distributions of feature extraction data, the approach of aligning data in Euclidean space is employed, which is then applied to a discriminatively restricted Boltzmann machine with a single layer for P300 detection. The performance of the proposed method on the BCI Competition III dataset II and the BCI competition II dataset II, the state-of-the-art dataset, was evaluated and compared with previous studies. The results showed that robust performance could be achieved using a small number of training samples, demonstrating the effectiveness of the transfer learning approach in P300-based BCI applications.

## 122. Fine-Grained Spatial-Frequency-Time Framework for Motor Imagery Brain–Computer Interface

**Authors:** Guoyang Liu, Rui Zhang, Lan Tian, Weidong Zhou (2025)
**DOI/URL:** 10.1109/JBHI.2025.3536212

The Motor Imagery Brain–Computer Interfaces (MI-BCIs) have shown considerable promise for applications in neural rehabilitation. However, improving the practicality and interpretability of MI-BCIs remains a critical challenge. Unlike previous methods that focus generally on either spatial, frequency, or temporal domains with coarse-grained segmentation schemes, this study proposes a novel fine-grained spatial-frequency-time (FGSFT) framework, aiming to enhance the efficiency and reliability of MI-BCIs. Multi-channel MI EEG recordings are firstly processed through multiscale time-frequency segmentation and spatial segmentation schemes, yielding fine-grained spatial-frequency-time segments (SFTSs). The key SFTSs are then selected with a tailored wrapper-based feature selection approach. Discriminative MI EEG features are extracted using a divergence-based common spatial pattern algorithm with intra-class regularization and classified using an efficient linear support vector machine (SVM). The proposed framework was evaluated on the BCI IV IIa and SDU-MI datasets, demonstrating state-of-the-art performance in terms of information transfer rate (ITR) Meanwhile, the proposed spatial segmentation strategy can significantly improve the performance of MI-BCIs when using a larger number of electrodes. Additionally, the fine-grained Motor Imagery Time-Frequency Reaction Map (MI-TFRM) and time-frequency topographical map can be obtained with the proposed framework enabling visualization of the subject-specific dynamic neural process during motor imagery tasks, facilitating the devising of personalized MI-BCIs. The FGSFT framework significantly advances the accuracy, ITR, and interoperability of MI-BCIs, paving the way for future neuroscientific research and clinical applications in neural rehabilitation and assistive technologies.

## 123. Depression Detection and Diagnosis Based on Electroencephalogram (EEG) Analysis: A Systematic Review

**Authors:** Kholoud Elnaggar, M. M. El-gayar, M. Elmogy (2025)
**DOI/URL:** 10.3390/diagnostics15020210

Background: Mental disorders are disturbances of brain functions that cause cognitive, affective, volitional, and behavioral functions to be disrupted to varying degrees. One of these disorders is depression, a significant factor contributing to the increase in suicide cases worldwide. Consequently, depression has become a significant public health issue globally. Electroencephalogram (EEG) data can be utilized to diagnose mild depression disorder (MDD), offering valuable insights into the pathophysiological mechanisms underlying mental disorders and enhancing the understanding of MDD. Methods: This survey emphasizes the critical role of EEG in advancing artificial intelligence (AI)-driven approaches for depression diagnosis. By focusing on studies that integrate EEG with machine learning (ML) and deep learning (DL) techniques, we systematically analyze methods utilizing EEG signals to identify depression biomarkers. The survey highlights advancements in EEG preprocessing, feature extraction, and model development, showcasing how these approaches enhance the diagnostic precision, scalability, and automation of depression detection. Results: This survey is distinguished from prior reviews by addressing their limitations and providing researchers with valuable insights for future studies. It offers a comprehensive comparison of ML and DL approaches utilizing EEG and an overview of the five key steps in depression detection. The survey also presents existing datasets for depression diagnosis and critically analyzes their limitations. Furthermore, it explores future directions and challenges, such as enhancing diagnostic robustness with data augmentation techniques and optimizing EEG channel selection for improved accuracy. The potential of transfer learning and encoder-decoder architectures to leverage pre-trained models and enhance diagnostic performance is also discussed. Advancements in feature extraction methods for automated depression diagnosis are highlighted as avenues for improving ML and DL model performance. Additionally, integrating Internet of Things (IoT) devices with EEG for continuous mental health monitoring and distinguishing between different types of depression are identified as critical research areas. Finally, the review emphasizes improving the reliability and predictability of computational intelligence-based models to advance depression diagnosis. Conclusions: This study will serve as a well-organized and helpful reference for researchers working on detecting depression using EEG signals and provide insights into the future directions outlined above, guiding further advancements in the field.

## 124. Brain–Computer Interface: The HOL–SSA Decomposition and Two-Phase Classification on the HGD EEG Data

**Authors:** Mary Judith Antony, Baghavathi Priya Sankaralingam, Shakir Khan, Abrar Almjally, N. Almujally, Rakesh Kumar Mahendran (2023)
**DOI/URL:** 10.3390/diagnostics13172852

An efficient processing approach is essential for increasing identification accuracy since the electroencephalogram (EEG) signals produced by the Brain–Computer Interface (BCI) apparatus are nonlinear, nonstationary, and time-varying. The interpretation of scalp EEG recordings can be hampered by nonbrain contributions to electroencephalographic (EEG) signals, referred to as artifacts. Common disturbances in the capture of EEG signals include electrooculogram (EOG), electrocardiogram (ECG), electromyogram (EMG) and other artifacts, which have a significant impact on the extraction of meaningful information. This study suggests integrating the Singular Spectrum Analysis (SSA) and Independent Component Analysis (ICA) methods to preprocess the EEG data. The key objective of our research was to employ Higher-Order Linear-Moment-based SSA (HOL–SSA) to decompose EEG signals into multivariate components, followed by extracting source signals using Online Recursive ICA (ORICA). This approach effectively improves artifact rejection. Experimental results using the motor imagery High-Gamma Dataset validate our method’s ability to identify and remove artifacts such as EOG, ECG, and EMG from EEG data, while preserving essential brain activity.

## 125. Multi-scale convolutional transformer network for motor imagery brain-computer interface

**Authors:** Wei Zhao, Baocan Zhang, Haifeng Zhou, Dezhi Wei, Chenxi Huang, Quan Lan (2025)
**DOI/URL:** 10.1038/s41598-025-96611-5

Brain-computer interface (BCI) systems allow users to communicate with external devices by translating neural signals into real-time commands. Convolutional neural networks (CNNs) have been effectively utilized for decoding motor imagery electroencephalography (MI-EEG) signals in BCIs. However, traditional CNN-based methods face challenges such as individual variability in EEG signals and the limited receptive fields of CNNs. This study presents the Multi-Scale Convolutional Transformer (MSCFormer) model that integrates multiple CNN branches for multi-scale feature extraction and a Transformer module to capture global dependencies, followed by a fully connected layer for classification. The multi-branch multi-scale CNN structure effectively addresses individual variability in EEG signals, enhancing the model’s generalization capabilities, while the Transformer encoder strengthens global feature integration and improves decoding performance. Extensive experiments on the BCI IV-2a and IV-2b datasets show that MSCFormer achieves average accuracies of 82.95% (BCI IV-2a) and 88.00% (BCI IV-2b), with kappa values of 0.7726 and 0.7599 in five-fold cross-validation, surpassing several state-of-the-art methods. These results highlight MSCFormer’s robustness and accuracy, underscoring its potential in EEG-based BCI applications. The code has been released in https://github.com/snailpt/MSCFormer.

## 126. A Combined Virtual Electrode-Based ESA and CNN Method for MI-EEG Signal Feature Extraction and Classification

**Authors:** Xiangmin Lun, Yifei Zhang, Mengyang Zhu, Yongheng Lian, Yimin Hou (2023)
**DOI/URL:** 10.3390/s23218893

A Brain–Computer Interface (BCI) is a medium for communication between the human brain and computers, which does not rely on other human neural tissues, but only decodes Electroencephalography (EEG) signals and converts them into commands to control external devices. Motor Imagery (MI) is an important BCI paradigm that generates a spontaneous EEG signal without external stimulation by imagining limb movements to strengthen the brain’s compensatory function, and it has a promising future in the field of computer-aided diagnosis and rehabilitation technology for brain diseases. However, there are a series of technical difficulties in the research of motor imagery-based brain–computer interface (MI-BCI) systems, such as: large individual differences in subjects and poor performance of the cross-subject classification model; a low signal-to-noise ratio of EEG signals and poor classification accuracy; and the poor online performance of the MI-BCI system. To address the above problems, this paper proposed a combined virtual electrode-based EEG Source Analysis (ESA) and Convolutional Neural Network (CNN) method for MI-EEG signal feature extraction and classification. The outcomes reveal that the online MI-BCI system developed based on this method can improve the decoding ability of multi-task MI-EEG after training, it can learn generalized features from multiple subjects in cross-subject experiments and has some adaptability to the individual differences of new subjects, and it can decode the EEG intent online and realize the brain control function of the intelligent cart, which provides a new idea for the research of an online MI-BCI system.

## 127. Cross subject emotion identification from multichannel EEG sub-bands using Tsallis entropy feature and KNN classifier

**Authors:** Pragati Patel, Sivarenjani Balasubramanian, Ramesh Naidu Annavarapu (2024)
**DOI/URL:** 10.1186/s40708-024-00220-3

Human emotion recognition remains a challenging and prominent issue, situated at the convergence of diverse fields, such as brain–computer interfaces, neuroscience, and psychology. This study utilizes an EEG data set for investigating human emotion, presenting novel findings and a refined approach for EEG-based emotion detection. Tsallis entropy features, computed for q values of 2, 3, and 4, are extracted from signal bands, including theta-θ (4–7 Hz), alpha-α (8–15 Hz), beta-β (16–31 Hz), gamma-γ (32–55 Hz), and the overall frequency range (0–75 Hz). These Tsallis entropy features are employed to train and test a KNN classifier, aiming for accurate identification of two emotional states: positive and negative. In this study, the best average accuracy of 79% and an F-score of 0.81 were achieved in the gamma frequency range for the Tsallis parameter q = 3. In addition, the highest accuracy and F-score of 84% and 0.87 were observed. Notably, superior performance was noted in the anterior and left hemispheres compared to the posterior and right hemispheres in the context of emotion studies. The findings show that the proposed method exhibits enhanced performance, making it a highly competitive alternative to existing techniques. Furthermore, we identify and discuss the shortcomings of the proposed approach, offering valuable insights into potential avenues for improvements. Subject independent human emotion identification is studied using SEED data set. Tsallis entropy is employed as feature and performance variation with Tsallis parameter (q = 2, 3, 4) is examined. Performance of kNN classifier is examined with Tsallis entropy feature. Emotion identification at various levels is studied, brain region, EEG rhythms, brain hemisphere. Prospects of TsEn-based real-time emotion recognition framework is canvassed. Subject independent human emotion identification is studied using SEED data set. Tsallis entropy is employed as feature and performance variation with Tsallis parameter (q = 2, 3, 4) is examined. Performance of kNN classifier is examined with Tsallis entropy feature. Emotion identification at various levels is studied, brain region, EEG rhythms, brain hemisphere. Prospects of TsEn-based real-time emotion recognition framework is canvassed.

## 128. Motor Imagery EEG Signals Decoding by Multivariate Empirical Wavelet Transform-Based Framework for Robust Brain–Computer Interfaces

**Authors:** M. Sadiq, Xiaojun Yu, Zhaohui Yuan, Fan Zeming, A. Rehman, Inam Ullah, Guoqi Li, Gaoxi Xiao (2019)
**DOI/URL:** 10.1109/ACCESS.2019.2956018

The robustness and computational load are the key challenges in motor imagery (MI) based on electroencephalography (EEG) signals to decode for the development of practical brain-computer interface (BCI) systems. In this study, we propose a robust and simple automated multivariate empirical wavelet transform (MEWT) algorithm for the decoding of different MI tasks. The main contributions of this study are four-fold. First, the multiscale principal component analysis method is utilized in the preprocessing module to obtain robustness against noise. Second, a novel automated channel selection strategy is proposed and then is further verified with comprehensive comparisons among three different strategies for decoding channel combination selection. Third, a sub-band alignment method by utilizing MEWT is adopted to obtain joint instantaneous amplitude and frequency components for the first time in MI applications. Four, a robust correlation-based feature selection strategy is applied to largely reduce the system complexity and computational load. Extensive experiments for subject-specific and subject independent cases are conducted with the three-benchmark datasets from BCI competition III to evaluate the performances of the proposed method by employing typical machine-learning classifiers. For subject-specific case, experimental results show that an average sensitivity, specificity and classification accuracy of 98% was achieved by employing multilayer perceptron neural networks, logistic model tree and least-square support vector machine (LS-SVM) classifiers, respectively for three datasets, resulting in an improvement of upto 23.50% in classification accuracy as compared with other existing method. While an average sensitivity, specificity and classification accuracy of 93%, 92.1% and 91.4% was achieved for subject independent case by employing LS-SVM classifier for all datasets with an increase of up to 18.14% relative to other existing methods. Results also show that our proposed algorithm provides a classification accuracy of 100% for subjects with small training size in subject-specific case, and for subject independent case by employing a single source subject. Such satisfactory results demonstrate the great potential of the proposed MEWT algorithm for practical MI EEG signals classification.

## 129. A WPSD-Based Feature Extraction Method of EEG Signal for Motor Imagination

**Authors:** Jing Shi, Qisong Wang, Dan Liu, C. Kim, Yan Zhang, Xin Liu (2023)
**DOI/URL:** 10.1109/CEI60616.2023.10527898

In order to improve the performance of the Brain-Computer Interface (BCI) system, it is important to extract the feature vector which reflects nonlinearity and non-stationary of Electroencephalogram (EEG) signals. This paper proposed an adaptive feature extraction method for BCI system based on multiclass motor imagery EEG signals. The proposed method extracts a feature vector related with time-frequency-spatial information of multiclass EEG signals from the continuous wavelet transform power spectral density (CWT-PSD) difference weighted by weight matrices which reflect the time-varying of EEG signals, in some channels which reflect well multiclass motor imagery. This method was evaluated on the EEG signals of BCI Competition IV Datasets $2\mathrm{a}$ using SVM as classifier, and the performance results were compared with the results obtained by the Common Spatial Pattern (CSP) and Filter Band CSP (FBCSP) feature extraction method used Naïve Bayesian Parzen Window (NBPW) classifier. The average classification accuracy of the proposed method is 90.22% for the 4-class motor imagery based BCI, and the kappa coefficient of the proposed method is higher 1.38 times and 1.21 times than one of the CSP and FBCSP method, respectively.

## 130. EEG-based human emotion recognition using entropy as a feature extraction measure

**Authors:** Pragati Patel, R. R, Ramesh Naidu Annavarapu (2021)
**DOI/URL:** 10.1186/s40708-021-00141-5

Many studies on brain–computer interface (BCI) have sought to understand the emotional state of the user to provide a reliable link between humans and machines. Advanced neuroimaging methods like electroencephalography (EEG) have enabled us to replicate and understand a wide range of human emotions more precisely. This physiological signal, i.e., EEG-based method is in stark comparison to traditional non-physiological signal-based methods and has been shown to perform better. EEG closely measures the electrical activities of the brain (a nonlinear system) and hence entropy proves to be an efficient feature in extracting meaningful information from raw brain waves. This review aims to give a brief summary of various entropy-based methods used for emotion classification hence providing insights into EEG-based emotion recognition. This study also reviews the current and future trends and discusses how emotion identification using entropy as a measure to extract features, can accomplish enhanced identification when using EEG signal.

## 131. Common Spatial Pattern Reformulated for Regularizations in Brain–Computer Interfaces

**Authors:** Boyu Wang, C. Wong, Zhao Kang, Feng Liu, Changjian Shui, Feng Wan, C. L. P. Chen (2020)
**DOI/URL:** 10.1109/tcyb.2020.2982901

Common spatial pattern (CSP) is one of the most successful feature extraction algorithms for brain–computer interfaces (BCIs). It aims to find spatial filters that maximize the projected variance ratio between the covariance matrices of the multichannel electroencephalography (EEG) signals corresponding to two mental tasks, which can be formulated as a generalized eigenvalue problem (GEP). However, it is challenging in principle to impose additional regularization onto the CSP to obtain structural solutions (e.g., sparse CSP) due to the intrinsic nonconvexity and invariance property of GEPs. This article reformulates the CSP as a constrained minimization problem and establishes the equivalence of the reformulated and the original CSPs. An efficient algorithm is proposed to solve this optimization problem by alternately performing singular value decomposition (SVD) and least squares. Under this new formulation, various regularization techniques for linear regression can then be easily implemented to regularize the CSPs for different learning paradigms, such as the sparse CSP, the transfer CSP, and the multisubject CSP. Evaluations on three BCI competition datasets show that the regularized CSP algorithms outperform other baselines, especially for the high-dimensional small training set. The extensive results validate the efficiency and effectiveness of the proposed CSP formulation in different learning contexts.

## 132. Domain-Generalized EEG Classification With Category-Oriented Feature Decorrelation and Cross-View Consistency Learning

**Authors:** Shuang Liang, Changsheng Xuan, Wenlong Hang, Baiying Lei, Jun Wang, Jing Qin, K. Choi (2023)
**DOI/URL:** 10.1109/TNSRE.2023.3300961

Generalizing the electroencephalogram (EEG) decoding methods to unseen subjects is an important research direction for realizing practical application of brain-computer interfaces (BCIs). Since distribution shifts across subjects, the performance of most current deep neural networks for decoding EEG signals degrades when dealing with unseen subjects. Domain generalization (DG) aims to tackle this issue by learning invariant representations across subjects. To this end, we propose a novel domain-generalized EEG classification framework, named FDCL, to generalize EEG decoding through category-relevant and -irrelevant Feature Decorrelation and Cross-view invariant feature Learning. Specifically, we first devise data augmented regularization through mixing the segments of same-category features from multiple subjects, which increases the diversity of EEG data by spanning the space of subjects. Furthermore, we introduce feature decorrelation regularization to learn the weights of the augmented EEG trials to remove the dependencies between their features, so that the true mapping relationship between relevant features and corresponding labels can be better established. To further distill subject-invariant EEG feature representations, cross-view consistency learning regularization is introduced to encourage consistent predictions of category-relevant features induced from different augmented EEG views. We seamlessly integrate three complementary regularizations into a unified DG framework to jointly improve the generalizability and robustness of the model on unseen subjects. Experimental results on motor imagery (MI) based EEG datasets validate that the proposed FDCL outperforms the available state-of-the-art methods.

## 133. Feature Extraction of Brain–Computer Interface Electroencephalogram Based on Motor Imagery

**Authors:** Tianwei Shi, Ling Ren, Wenhua Cui (2020)
**DOI/URL:** 10.1109/JSEN.2019.2939343

Brain-computer interface (BCI) is a system that allows people to communicate or control external devices simply by using information from the brain without relying on the peripheral nervous system and muscles; BCI technology has great potential application value in motor function assistance and motor function rehabilitation and has become a new research hotspot in the fields of machine learning, biomedical engineering and computer communication. The feature extraction of motor imagery electroencephalogram (EEG) is to find the most effective characteristics of complex EEG signal that can represent the consciousness task, to differentiate the feature vectors extracted from different consciousness tasks, and to maximize the correlation between the feature vector and the consciousness task. On the basis of summarizing and analyzing previous research works, this paper proposes a new EEG feature extraction algorithm based on common spatial pattern (CSP) and adaptive auto-regressive (AAR), and demonstrates feasibility of band energy, sample entropy and order accumulation to be the characteristics of motor imagery classification, and finally compares the classification effects of linear discrimination classifier, common space classifier and Bayesian classifier. The simulation results show that the proposed method and algorithm can effectively extract the features of EEG signals during motor imagery. The research results of this paper provide a reference for the further study of feature extraction of brain-computer interface EEG.

## 134. SFE-Net: EEG-based Emotion Recognition with Symmetrical Spatial Feature Extraction

**Authors:** Xiangwen Deng, Ju-xia Zhu, Shangming Yang (2021)
**DOI/URL:** 10.1145/3474085.3475403

Emotion recognition based on EEG (electroencephalography) has been widely used in human-computer interaction, distance education and health care. However, the conventional methods ignore the adjacent and symmetrical characteristics of EEG signals, which also contain salient information related to emotion. In this paper, a spatial folding ensemble network (SFE-Net) is presented for EEG feature extraction and emotion recognition. Firstly, for the undetected area between EEG electrodes, an improved Bicubic-EEG interpolation algorithm is developed for EEG channels information completion, which allows us to extract a wider range of adjacent space features. Then, motivated by the spatial symmetric mechanism of human brain, we fold the input EEG channels data with five different symmetrical strategies, which enable the proposed network to extract the information of space features of EEG signals more effectively. Finally, a 3DCNN-based spatial, temporal extraction, and a multi-voting strategy of ensemble learning are integrated to model a new neural network. With this network, the spatial features of different symmetric folding signals can be extracted simultaneously, which greatly improves the robustness and accuracy of emotion recognition. The experimental results on DEAP and SEED datasets show that the proposed algorithm has comparable performance in terms of recognition accuracy.

## 135. Fusion Analysis of EEG-fNIRS Multimodal Brain Signals: A Multitask Classification Algorithm Incorporating Spatial-Temporal Convolution and Dual Attention Mechanisms

**Authors:** Xingbin Shi, Haiyan Wang, Baojiang Li, Yuxin Qin, Cheng Peng, Yifan Lu (2025)
**DOI/URL:** 10.1109/TIM.2025.3538086

Brain–computer interface (BCI) is an important way of human-computer interaction, with the ability to monitor brain states, and it has become an increasingly significant research direction. Single-modal noninvasive brain signals have limitations, such as low spatial resolution or low temporal resolution, while multimodal brain signal acquisition and processing can overcome these limitations. Electroencephalogram and functional near-infrared spectroscopy (EEG-fNIRS) is a method with advantages in multimodal brain signal processing, but current fusion methods mostly use manual feature extraction or channel selection, which may lead to the loss of important information during the feature extraction or channel selection process in real-time BCI systems. In order to solve this issue, this article proposes an innovative fusion analysis method for EEG-fNIRS multimodal brain signals, using a hybrid algorithm that combines convolutional neural network (CNN) and Attention mechanisms for signal classification. The method first preprocesses the EEG and fNIRS signals separately, then extracts features using spatial-temporal convolutional layers, and finally merges them to obtain the classification results through dual attention calculation. Our method is validated on two publicly available mixed EEG-fNIRS BCI datasets, including three types of experimental tasks that do not involve actual movement: motor imagery (MI), mental arithmetic, and word generation (WG). The accuracy rates for each task reached 92.2% for MI, 98.6% for mental arithmetic, and 95.2% for WG, respectively. These rates have surpassed all the current methods. This indicates that our proposed method achieves better classification performance in non-actual movement classification tasks under the premise of lightweight. The method proposed in this study can be applied to the field of rapid and efficient identification of brain signals.

## 136. A Systematic Review of Using Deep Learning Technology in the Steady-State Visually Evoked Potential-Based Brain-Computer Interface Applications: Current Trends and Future Trust Methodology

**Authors:** A. Albahri, Z. Al-qaysi, Laith Alzubaidi, Alhamzah Alnoor, O. Albahri, A. Alamoodi, Anizah Abu Bakar (2023)
**DOI/URL:** 10.1155/2023/7741735

The significance of deep learning techniques in relation to steady-state visually evoked potential- (SSVEP-) based brain-computer interface (BCI) applications is assessed through a systematic review. Three reliable databases, PubMed, ScienceDirect, and IEEE, were considered to gather relevant scientific and theoretical articles. Initially, 125 papers were found between 2010 and 2021 related to this integrated research field. After the filtering process, only 30 articles were identified and classified into five categories based on their type of deep learning methods. The first category, convolutional neural network (CNN), accounts for 70% (n = 21/30). The second category, recurrent neural network (RNN), accounts for 10% (n = 3/30). The third and fourth categories, deep neural network (DNN) and long short-term memory (LSTM), account for 6% (n = 30). The fifth category, restricted Boltzmann machine (RBM), accounts for 3% (n = 1/30). The literature's findings in terms of the main aspects identified in existing applications of deep learning pattern recognition techniques in SSVEP-based BCI, such as feature extraction, classification, activation functions, validation methods, and achieved classification accuracies, are examined. A comprehensive mapping analysis was also conducted, which identified six categories. Current challenges of ensuring trustworthy deep learning in SSVEP-based BCI applications were discussed, and recommendations were provided to researchers and developers. The study critically reviews the current unsolved issues of SSVEP-based BCI applications in terms of development challenges based on deep learning techniques and selection challenges based on multicriteria decision-making (MCDM). A trust proposal solution is presented with three methodology phases for evaluating and benchmarking SSVEP-based BCI applications using fuzzy decision-making techniques. Valuable insights and recommendations for researchers and developers in the SSVEP-based BCI and deep learning are provided.

## 137. Intra- and Inter-subject Variability in EEG-Based Sensorimotor Brain Computer Interface: A Review

**Authors:** S. Saha, M. Baumert (2020)
**DOI/URL:** 10.3389/fncom.2019.00087

Brain computer interfaces (BCI) for the rehabilitation of motor impairments exploit sensorimotor rhythms (SMR) in the electroencephalogram (EEG). However, the neurophysiological processes underpinning the SMR often vary over time and across subjects. Inherent intra- and inter-subject variability causes covariate shift in data distributions that impede the transferability of model parameters amongst sessions/subjects. Transfer learning includes machine learning-based methods to compensate for inter-subject and inter-session (intra-subject) variability manifested in EEG-derived feature distributions as a covariate shift for BCI. Besides transfer learning approaches, recent studies have explored psychological and neurophysiological predictors as well as inter-subject associativity assessment, which may augment transfer learning in EEG-based BCI. Here, we highlight the importance of measuring inter-session/subject performance predictors for generalized BCI frameworks for both normal and motor-impaired people, reducing the necessity for tedious and annoying calibration sessions and BCI training.

## 138. Multiclass Classification of Brain-Computer Interface Motor Imagery System: A Systematic Literature Review

**Authors:** Ade Widyatama Dian Boernama, N. A. Setiawan, O. Wahyunggoro (2021)
**DOI/URL:** 10.1109/AIMS52415.2021.9466056

The Brain-Computer Interface (BCI) is a great concept that enables people to interact with external devices solely through their brain signals. Motor imagery (MI), in which the acquired signals are captured from limb movements' imagination, is one of the most popular BCI research topics. For people with disabilities, this concept could be beneficial. The most common research for BCI MI classification has so far focused on a binary classification problem. In a real-world situation, however, the machine will need to train and differentiate more than two classes or solve a multiclass classification problem. Therefore, to summarize the research on multiclass BCI MI classification, this paper will conduct a systematic literature review for 30 articles that have gone through the selection process. This review found that the most used dataset in Multiclass BCI MI-EEG System is BCI Competition IV dataset 2a. As for the feature extraction method and classification method, most researchers used computationally inexpensive and stable methods. However, some of the researchers use more complex methods such as Fourier Transform as a feature extraction method and a Deep Learning-based classifier as a classification method.

## 139. Statistical Feature Extraction and Classification using Machine Learning Techniques in Brain-Computer Interface

**Authors:** Ph.D M.Kanimozhi, Dr.R.Roselin (2020)
**DOI/URL:** 10.35940/ijitee.k2343.019320

Brain Computer Interface is a paralyzed system. This system is used for direct communication between brain nerves and computer devices. BCI is an imagery movement of the patients who are all unable to communicate with the people. In EEG signals feature extraction plays an important role. Statistical based features are essential feature being used in machine learning applications. Researchers mainly focus on the filters and feature extraction techniques. In this paper data are collected from the BCI Competition III dataset 1a. Statistical features like minimum, maximum, standard deviation, variance, skewnesss, kurtosis, root mean square, average, energy, contrast, correlation and Homogeneity are extracted. Classification is done using machine learning techniques such as Support Vector Machine, Artificial Neural Network and K-Nearest Neighbor. In the proposed system 90.6% accuracy is achieved

## 140. A Biologically Inspired Approach to Frequency Domain Feature Extraction for EEG Classification

**Authors:** Nurhan Gürsel Özmen, Levent Gümüsel, Yuan Yang (2018)
**DOI/URL:** 10.1155/2018/9890132

Classification of electroencephalogram (EEG) signal is important in mental decoding for brain-computer interfaces (BCI). We introduced a feature extraction approach based on frequency domain analysis to improve the classification performance on different mental tasks using single-channel EEG. This biologically inspired method extracts the most discriminative spectral features from power spectral densities (PSDs) of the EEG signals. We applied our method on a dataset of six subjects who performed five different imagination tasks: (i) resting state, (ii) mental arithmetic, (iii) imagination of left hand movement, (iv) imagination of right hand movement, and (v) imagination of letter “A.” Pairwise and multiclass classifications were performed in single EEG channel using Linear Discriminant Analysis and Support Vector Machines. Our method produced results (mean classification accuracy of 83.06% for binary classification and 91.85% for multiclassification) that are on par with the state-of-the-art methods, using single-channel EEG with low computational cost. Among all task pairs, mental arithmetic versus letter imagination yielded the best result (mean classification accuracy of 90.29%), indicating that this task pair could be the most suitable pair for a binary class BCI. This study contributes to the development of single-channel BCI, as well as finding the best task pair for user defined applications.

## 141. An Attention-Based Multi-Domain Bi-Hemisphere Discrepancy Feature Fusion Model for EEG Emotion Recognition

**Authors:** Linlin Gong, Wanzhong Chen, Dingguo Zhang (2024)
**DOI/URL:** 10.1109/JBHI.2024.3418010

Electroencephalogram (EEG)-based emotion recognition has become a research hotspot in the field of brain-computer interface. Previous emotion recognition methods have overlooked the fusion of multi-domain emotion-specific information to improve performance, and faced the challenge of insufficient interpretability. In this paper, we proposed a novel EEG emotion recognition model that combined the asymmetry of the brain hemisphere, and the spatial, spectral, and temporal multi-domain properties of EEG signals, aiming to improve emotion recognition performance. Based on the 10–20 standard system, a global spatial projection matrix (GSPM) and a bi-hemisphere discrepancy projection matrix (BDPM) are constructed. A dual-stream spatial-spectral-temporal convolution neural network is designed to extract depth features from the two matrix paradigms. Finally, the transformer-based fusion module is used to learn the dependence of fused features, and to retain the discriminative information. We conducted extensive experiments on the SEED, SEED-IV, and DEAP public datasets, achieving excellent average results of 98.33/2.46<inline-formula><tex-math notation="LaTeX">$\%$</tex-math></inline-formula>, 92.15/5.13<inline-formula><tex-math notation="LaTeX">$\%$</tex-math></inline-formula>, 97.60/1.68<inline-formula><tex-math notation="LaTeX">$\%$</tex-math></inline-formula>(valence), and 97.48/1.42<inline-formula><tex-math notation="LaTeX">$\%$</tex-math></inline-formula>(arousal) respectively. Visualization analysis supports the interpretability of the model, and ablation experiments validate the effectiveness of multi-domain and bi-hemisphere discrepancy information fusion.

## 142. Comparing Steady-State Visually Evoked Potentials Frequency Estimation Methods in Brain-Computer Interface With the Minimum Number of EEG Channels

**Authors:** Mehrnoosh Neghabi, H. Marateb, A. Mahnam (2018)
**DOI/URL:** 10.32598/bcn.9.10.200

Introduction: Brain-Computer Interface (BCI) systems provide a communication pathway between users and systems. BCI systems based on Steady-State Visually Evoked Potentials (SSVEP) are widely used in recent decades. Different feature extraction methods have been introduced in the literature to estimate SSVEP responses to BCI applications. Methods: In this study, the new algorithms, including Canonical Correlation Analysis (CCA), Least Absolute Shrinkage and Selection Operator (LASSO), L1-regularized Multi-way CCA (L1-MCCA), Multi-set CCA (MsetCCA), Common Feature Analysis (CFA), and Multiple Logistic Regression (MLR) are compared using proper statistical methods to determine which one has better performance with the least number of EEG electrodes. Results: It was found that MLR, MsetCCA, and CFA algorithms provided the highest performances and significantly outperformed CCA, LASSO, and L1-MCCA algorithms when using 8 EEG channels. However, when using only 1 or 2 EEG channels d, CFA method provided the highest F-scores. This algorithm not only outperformed MLR and MsetCCA when applied on different electrode montages but also provided the fastest computation time on the test set. Conclusion: Although MLR method has already demonstrated to have higher performance in comparison with other frequency recognition algorithms, this study showed that in a practical SSVEP-based BCI system with 1 or 2 EEG channels and short-time windows, CFA method outperforms other algorithms. Therefore, it is proposed that CFA algorithm is a promising choice for the expansion of practical SSVEP-based BCI systems.

## 143. An innovative EEG-based emotion recognition using a single channel-specific feature from the brain rhythm code method

**Authors:** Jia Wen Li, Di Lin, Yan Che, J. Lv, Rong Jun Chen, Lei Wang, Xiangyu Zeng, Jin-Chang Ren, Huiming Zhao, X. Lu (2023)
**DOI/URL:** 10.3389/fnins.2023.1221512

Introduction Efficiently recognizing emotions is a critical pursuit in brain–computer interface (BCI), as it has many applications for intelligent healthcare services. In this work, an innovative approach inspired by the genetic code in bioinformatics, which utilizes brain rhythm code features consisting of δ, θ, α, β, or γ, is proposed for electroencephalography (EEG)-based emotion recognition. Methods These features are first extracted from the sequencing technique. After evaluating them using four conventional machine learning classifiers, an optimal channel-specific feature that produces the highest accuracy in each emotional case is identified, so emotion recognition through minimal data is realized. By doing so, the complexity of emotion recognition can be significantly reduced, making it more achievable for practical hardware setups. Results The best classification accuracies achieved for the DEAP and MAHNOB datasets range from 83–92%, and for the SEED dataset, it is 78%. The experimental results are impressive, considering the minimal data employed. Further investigation of the optimal features shows that their representative channels are primarily on the frontal region, and associated rhythmic characteristics are typical of multiple kinds. Additionally, individual differences are found, as the optimal feature varies with subjects. Discussion Compared to previous studies, this work provides insights into designing portable devices, as only one electrode is appropriate to generate satisfactory performances. Consequently, it would advance the understanding of brain rhythms, which offers an innovative solution for classifying EEG signals in diverse BCI applications, including emotion recognition.

## 144. Effects of EMD and Feature Extraction on EEG Analysis

**Authors:** P. Huynh, Gregory Warner, Hong Lin (2020)
**DOI/URL:** 10.12720/jait.11.1.26-34

s—Brain-computer interfaces have been investigated for more than 20 years and have great potential to develop applications for physicians to diagnose diseases or patients with severe neurologic disabilities to return to interact with society. To gain those purposes requires technics to analyze the EEG data as well as an algorithm to train the model for identifying the patterns or controlling the devices. TensorFlow is a machine learning developed by Google team for internal use and was released for public use in 2015. Since it can train and test on deep learning neural network, it can be used for EEG data. This project used TFKeras and TensorFlow-DNN to train the models for classifying brain states using EEG data. Neurosky Mindwave Mobile headset and a new device developed from Micro:bit were the recorders for EEG signals in the project. Several technics such as min-max normalization, Ensemble Empirical Mode Decomposition (EEMD), extraction were applied to analyze the recorded EEG data. The results show that the accuracies of TensorFlow-Keras and TensorFlow DNN models are 97% while the results from XGBoost is 98% when classifying the EEG data from Micro:bit device. The result confirms the ability of application of TensorFlow in identifying EEG data. The technics for processing data contributed to the above results are min-max normalization and data extraction. Moreover, we also verify that the lowfrequency drifts in the recorded data is essential to identify the brain states using EEG data. The results also show the application of IMFs generated from EEMD technic as features to build the models for classifying brain states using the EEG data.

## 145. Adaptive feature extraction in EEG-based motor imagery BCI: tracking mental fatigue

**Authors:** Upasana Talukdar, S. Hazarika, J. Q. Gan (2020)
**DOI/URL:** 10.1088/1741-2552/ab53f1

Objective. Electroencephalogram (EEG) signals are non-stationary. This could be due to internal fluctuation of brain states such as fatigue, frustration, etc. This necessitates the development of adaptive brain-computer interfaces (BCI) whose performance does not deteriorate significantly with the adversary change in the cognitive state. In this paper, we put forward an unsupervised adaptive scheme to adapt the feature extractor of motor imagery (MI) BCIs by tracking the fatigue level of the user. Approach. Eleven subjects participated in the study during which they accomplished MI tasks while self-reporting their perceived levels of mental fatigue. Out of the 11 subjects, only six completed the whole experiment, while the others quit in the middle because of experiencing high fatigue. The adaptive feature extractor is attained through the adaptation of the common spatial patterns (CSP), one of the most popular feature extraction algorithms in EEG-based BCIs. The proposed method was analyzed in two ways: offline and in near real-time. The separability of the MI EEG features extracted by the proposed adaptive CSP (ADCSP) has been compared with that by the conventional CSP (C-CSP) and another CSP based adaptive method (ACSP) in terms of: Davies Bouldin index (DBI), Fisher score (FS) and Dunn’s index (DI). Main results. Experimental results show significant improvement in the separability of MI EEG features extracted by ADCSP as compared to that by C-CSP and ACSP. Significance. Collectively, the results of the experiments in this study suggest that adapting CSP based on mental fatigue can improve the class separability of MI EEG features.

## 146. Riemannian distance based channel selection and feature extraction combining discriminative time-frequency bands and Riemannian tangent space for MI-BCIs

**Authors:** Tingnan Qu, Jing Jin, Ren Xu, Xingyu Wang, A. Cichocki (2022)
**DOI/URL:** 10.1088/1741-2552/ac9338

Objective. Motor imagery-based brain computer interfaces (MI-BCIs) have been widely researched because they do not demand external stimuli and have a high degree of maneuverability. In most scenarios, superabundant selected channels, fixed time windows, and frequency bands would certainly affect the performance of MI-BCIs due to the neurophysiological diversities among different individuals. In this study, we attempt to effectively use the Riemannian geometry of spatial covariance matrix to extract more robust features and thus enhance the decoding efficiency. Approach. First, we utilize a Riemannian distance-based electroencephalography (EEG) channel selection method, which preliminarily reduces the information redundancy in the first stage. Second, we extract discriminative Riemannian tangent space features of EEG signals of selected channels from the most discriminant time-frequency bands to further enhance decoding accuracy for MI-BCIs. Finally, we train a support vector machine model with a linear kernel to classify our extracted discriminative Riemannian features, and evaluate our proposed method using publicly available BCI Competition IV dataset Ⅰ (DS1) and Competition Ⅲ dataset Ⅲa (DS2). Main results. The experimental results show that the average classification accuracy with the selected 16-channel EEG signals of our method is 90.0% and 89.4% in DS1 and DS2 respectively. The average improvements are 20.0% and 21.2% on DS1, 9.4% and 7.2% on DS2 for 8 and 16 selected channels, respectively. Significance. These results show that our proposed method is a promising candidate for the performance improvement of MI-BCIs.

## 147. An effective classification framework for brain-computer interface system design based on combining of fNIRS and EEG signals

**Authors:** Adi Alhudhaif (2021)
**DOI/URL:** 10.7717/peerj-cs.537

Background The brain-computer interface (BCI) is a relatively new but highly promising special field that is actively used in basic neuroscience. BCI includes interfaces for human-computer communication based directly on neural activity concerning mental processes. Fundamental BCI components consist of different units. In the first stage, the EEG and NIRS signals obtained from the individuals are preprocessed, and the signals are brought to a certain standard. Methods In order to realize proposed framework, a dataset containing Motor Imaginary and Mental Activity tasks are prepared with Electroencephalography (EEG) and Near-Infrared Spectroscopy (NIRS) signal. First of all, HbO and HbR curves are obtained from NIRS signals. Hbo, HbR, HbO+HbR, EEG, EEG+HbO and EEG+HbR features tables are created with the features obtained by using HbO, HbR, and EEG signals, and feature weighted is carried out with the k-Means clustering centers based attribute weighting method (KMCC-based) and the k-Means clustering centers difference based attribute weighting method (KMCCD-based). Linear Discriminant Analysis (LDA), Support Vector Machine (SVM), and k-Nearest Neighbors algorithm (kNN) classifiers are used to see the classifier differences in the study. Results As a result of this study, an accuracy rate of 99.7% (with kNN classifier and KMCCD-based weighting) is obtained in the data set of Motor Imaginary. Similarly, an accuracy rate of 99.9% (with SVM and kNN classifier and KMCCD-based weighting) is obtained in the Mental Activity dataset. The weighting method is used to increase the classification accuracy, and it has been shown that it will contribute to the classification of EEG and NIRS BCI systems. The results show that the proposed method increases classifiers’ performance, offering less processing power and ease of application. In the future, studies could be carried out by combining the k-Means clustering center-based weighted hybrid BCI method with deep learning architectures. Further improved classifier performances can be achieved by combining both systems.

## 148. Advances on Real Time M/EEG Neural Feature Extraction

**Authors:** P. S. Shabestari, Delphine Ribes, Lara Défayes, Danpeng Cai, Emily Groves, Harry H. Behjat, D. Van de Ville, Tobias Kleinjung, Adrian Naas, Nicolas Henchoz, A. Sonderegger, Patrick Neff (2025)
**DOI/URL:** 10.1109/CBMS65348.2025.00074

This paper introduces MNE-RT, a Python package designed for real-time neural feature extraction from magne-toencephalography (MEG) and electroencephalography (EEG) signals in Brain-Computer Interface (BCI) systems. The package incorporates efficient algorithms spanning traditional univariate metrics, such as frequency band power and entropy, to advanced bivariate connectivity measures. It is compatible with various recording systems, enabling the extraction of neural targets from brain signals in real time, with potential applications in enhancing neurofeedback efficacy.

## 149. Objective Emotion Assessment Using a Triple Attention Network for an EEG-Based Brain–Computer Interface

**Authors:** Lihua Zhang, Xin Zhang, Xiu Zhang, Changyi Yu, Xuguang Liu (2025)
**DOI/URL:** 10.3390/brainsci15111167

Background: The assessment of emotion recognition holds growing significance in research on the brain–computer interface and human–computer interaction. Among diverse physiological signals, electroencephalography (EEG) occupies a pivotal position in affective computing due to its exceptional temporal resolution and non-invasive acquisition. However, EEG signals are inherently complex, characterized by substantial noise contamination and high variability, posing considerable challenges to accurate assessment. Methods: To tackle these challenges, we propose a Triple Attention Network (TANet), a triple-attention EEG emotion recognition framework that integrates Conformer, Convolutional Block Attention Module (CBAM), and Mutual Cross-Modal Attention (MCA). The Conformer component captures temporal feature dependencies, CBAM refines spatial channel representations, and MCA performs cross-modal fusion of differential entropy and power spectral density features. Results: We evaluated TANet on two benchmark EEG emotion datasets, DEAP and SEED. On SEED, using a subject-specific cross-validation protocol, the model reached an average accuracy of 98.51 ± 1.40%. On DEAP, we deliberately adopted a segment-level splitting paradigm—in line with influential state-of-the-art methods—to ensure a direct and fair comparison of model architecture under an identical evaluation protocol. This approach, designed specifically to assess fine-grained within-trial pattern discrimination rather than cross-subject generalization, yielded accuracies of 99.69 ± 0.15% and 99.67 ± 0.13% for the valence and arousal dimensions, respectively. Compared with existing benchmark approaches under similar evaluation protocols, TANet delivers substantially better results, underscoring the strong complementary effects of its attention mechanisms in improving EEG-based emotion recognition performance. Conclusions: This work provides both theoretical insights into multi-dimensional attention for physiological signal processing and practical guidance for developing high-performance, robust EEG emotion assessment systems.

## 150. Swarm Intelligence-Based Feature Selection Algorithm of EEG Classification for Brain Emotion Detection: A Review

**Authors:** Gaganjot Kaur, Meenu Gupta, Rakesh Kumar (2023)
**DOI/URL:** 10.1109/I2CT57861.2023.10126425

In recent technology, Brain Computer Interfacing (BCI) plays a prominent role through which a human can interact with the outside world using brain signals. Brain signals are the current reactions in the brain when neurological activity occurs and are closely associated with critical thinking, logical decision-making, recognition, human interaction, and to some extent, Human Intelligence. Brain waves influence most real human body reactions; compared to other types of emotion analysis, brain wave emotion analysis comes out on top. Emotion Detection has a broad perspective in interdisciplinary research for neurologists, psychologists, engineers, etc. This paper aims to represent the latest comprehensive review of emotion detection techniques using Electroencephalography (EEG) Signals, feature extraction, feature selection, and classification, along with pointing out existing problems in the field and potential growth areas.

## 151. A Cross-Session Dataset for Collaborative Brain-Computer Interfaces Based on Rapid Serial Visual Presentation

**Authors:** Li Zheng, Sen Sun, Hongze Zhao, Weihua Pei, Hongda Chen, Xiaorong Gao, Lijian Zhang, Yijun Wang (2020)
**DOI/URL:** 10.3389/fnins.2020.579469

Brain-computer interfaces (BCIs) based on rapid serial visual presentation (RSVP) have been widely used to categorize target and non-target images. However, it is still a challenge to detect single-trial event related potentials (ERPs) from electroencephalography (EEG) signals. Besides, the variability of EEG signal over time may cause difficulties of calibration in long-term system use. Recently, collaborative BCIs have been proposed to improve the overall BCI performance by fusing brain activities acquired from multiple subjects. For both individual and collaborative BCIs, feature extraction and classification algorithms that can be transferred across sessions can significantly facilitate system calibration. Although open datasets are highly efficient for developing algorithms, currently there is still a lack of datasets for a collaborative RSVP-based BCI. This paper presents a cross-session EEG dataset of a collaborative RSVP-based BCI system from 14 subjects, who were divided into seven groups. In collaborative BCI experiments, two subjects did the same target image detection tasks synchronously. All subjects participated in the same experiment twice with an average interval of ∼23 days. The results in data evaluation indicate that adequate signal processing algorithms can greatly enhance the cross-session BCI performance in both individual and collaborative conditions. Besides, compared with individual BCIs, the collaborative methods that fuse information from multiple subjects obtain significantly improved BCI performance. This dataset can be used for developing more efficient algorithms to enhance performance and practicality of a collaborative RSVP-based BCI system.

## 152. Enhancing EEG-based BCI Performances by Reducing Covariate Shift via Adaptive Multi-Domain Feature Extraction

**Authors:** Moein Radman, Reza Arghand, Nader Nariman-Zadeh, Ali Chaibakhsh (2025)
**DOI/URL:** 10.1109/ICCKE68588.2025.11273863

The main objective of this article is to enhance the functional accuracy of brain-computer interface systems by addressing the challenges created by non-stationary characteristics of EEG signals in certain subjects. To deal with this problem, the brain signals are decomposed into several frequency sub-bands using a bank of Constant-Q filters, as the best features from the temporal, spectral, and spatial domains are extracted. These features are used to train the probabilistic classification vector machines, where covariate shift minimization is used to adapt the features. The assessment phase is based on the BCI 2008-2b dataset, which results in achieving a Kappa score of 0.78 and performance enhancement of about 8.7 and 12.2 percent for subject one and subject two, respectively.

## 153. Domain Adaptive Algorithm Based on Multi-Manifold Embedded Distributed Alignment for Brain-Computer Interfaces

**Authors:** Yunyuan Gao, Yici Liu, Qingshan She, Jianhai Zhang (2022)
**DOI/URL:** 10.1109/JBHI.2022.3218453

The use of transfer learning in brain-computer interfaces (BCIs) has potential applications. As electroencephalogram (EEG) signals vary among different paradigms and subjects, existing EEG transfer learning algorithms mainly focus on the alignment of the original space. They may not discover hidden details owing to the low-dimensional structure of EEG. To effectively transfer data from a source to target domain, a multi-manifold embedding domain adaptive algorithm is proposed for BCI. First, we aligned the EEG covariance matrix in the Riemannian manifold and extracted the characteristics of each source domain in the tangent space to reflect the differences between different source domains. Subsequently, we mapped the extracted characteristics to the Grassmann manifold to obtain a common feature representation. In domain adaptation, the geometric and statistical attributes of EEG data were considered simultaneously, and the target domain divergence matrix was updated with pseudo-labels to maximize the inter-class distance and minimize the intra-class distance. Datasets generated via BCIs were used to verify the effectiveness of the algorithm. Under two experimental paradigms, namely single-source to single-target and multi-source to single-target, the average accuracy of the algorithm on three datasets was 73.31% and 81.02%, respectively, which is more than that of several state-of-the-art EEG cross-domain classification approaches. Our multi-manifold embedded domain adaptive method achieved satisfactory results on EEG transfer learning. The method can achieve effective EEG classification without a same subject's training set.

## 154. To train or not to train? A survey on training of feature extraction methods for SSVEP-based BCIs

**Authors:** Rosanne Zerafa, Tracey A. Camilleri, O. Falzon, Kenneth P. Camilleri (2018)
**DOI/URL:** 10.1088/1741-2552/aaca6e

Objective. Despite the vast research aimed at improving the performance of steady-state visually evoked potential (SSVEP)-based brain–computer interfaces (BCIs), several limitations exist that restrict the use of such applications for long-term users in the real-world. One of the main challenges has been to reduce training time while maintaining good BCI performance. In view of this challenge, this survey identifies and compares the different training requirements of feature extraction methods for SSVEP-based BCIs. Approach. This paper reviews the various state-of-the-art SSVEP feature extraction methods that have been developed and are most widely used in the literature. Main results. The main contributions compared to existing reviews are the following: (i) a detailed summary, including a brief mathematical description of each feature extraction algorithm, providing a guide to the basic concepts of the state-of-the-art techniques for SSVEP-based BCIs found in literature; (ii) a categorisation of the training requirements of SSVEP-based methods into three categories, defined as training-free methods, subject-specific and subject-independent training methods; (iii) a comparative review of the training requirements of SSVEP feature extraction methods, providing a reference for future work on SSVEP-based BCIs. Significance. This review highlights the strengths and weaknesses of the three categories of SSVEP training methods. Training-free systems are more practical but their performance is limited due to inter-subject variability resulting from the complex EEG activity. Feature extraction methods that incorporate some training data address this issue and in fact have outperformed training-free methods: subject-specific BCIs are tuned to the individual yielding the best performance at the cost of long, tiring training sessions making these methods unsuitable for everyday use; subject-independent BCIs that make use of training data from various subjects offer a good trade-off between training effort and performance, making these BCIs better suited for practical use.

## 155. Data Augmentation of SSVEPs Using Source Aliasing Matrix Estimation for Brain–Computer Interfaces

**Authors:** Ruixin Luo, Minpeng Xu, Xiaoyu Zhou, Xiaolin Xiao, T. Jung, Dong Ming (2022)
**DOI/URL:** 10.1109/TBME.2022.3227036

Objective: Currently, ensemble task-related component analysis (eTRCA) and task discriminative component analysis (TDCA) are the state-of-the-art algorithms for steady-state visual evoked potential (SSVEP)-based brain-computer interfaces (BCIs). However, training the BCIs requires multiple calibration trials. With insufficient calibration data, the accuracy of the BCI will degrade, or even become invalid with only one calibration trial. However, collecting a large amount of electroencephalography (EEG) data for calibration is a time-consuming and laborious process, which hinders the practical use of eTRCA and TDCA. Methods: This study proposed a novel method, namely Source Aliasing Matrix Estimation (SAME), to augment the calibration data for SSVEP-BCIs. SAME could generate artificial EEG trials with the featured SSVEPs. Its effectiveness was evaluated using two public datasets (i.e., Benchmark, BETA). Results: When combined with SAME, both eTRCA and TDCA had significantly improved performance with a limited number of calibration data. Specifically, SAME increased the average accuracy of eTRCA and TDCA by about 12% and 3%, respectively, with as few as two calibration trials. Notably, SAME enabled eTRCA and TDCA to work well with a single calibration trial, achieving an average accuracy >90% for the Benchmark dataset and >70% for the BETA dataset with 1-second EEG. Conclusion: SAME is an effective method for SSVEP-BCIs to augment the calibration data, thereby significantly enhancing the performance of eTRCA and TDCA. Significance: We propose a new data-augmentation method that is compatible with the state-of-the-art algorithms of SSVEP-based BCIs. It can significantly reduce the efforts required to calibrate SSVEP-BCIs, which is promising for the development of practical BCIs.

## 156. Distinguishable spatial-spectral feature learning neural network framework for motor imagery-based brain–computer interface

**Authors:** Chang Liu, Jing Jin, Ren Xu, Shurui Li, Cili Zuo, Hao Sun, Xingyu Wang, A. Cichocki (2021)
**DOI/URL:** 10.1088/1741-2552/ac1d36

Objective. Spatial and spectral features extracted from electroencephalogram (EEG) are critical for the classification of motor imagery (MI) tasks. As prevalently used methods, the common spatial pattern (CSP) and filter bank CSP (FBCSP) can effectively extract spatial-spectral features from MI-related EEG. To further improve the separability of the CSP features, we proposed a distinguishable spatial-spectral feature learning neural network (DSSFLNN) framework for MI-based brain–computer interfaces (BCIs) in this study. Approach. The first step of the DSSFLNN framework was to extract FBCSP features from raw EEG signals. Then two squeeze-and-excitation modules were used to re-calibrate CSP features along the band-wise axis and the class-wise axis, respectively. Next, we used a parallel convolutional neural network module to learn distinguishable spatial-spectral features. Finally, the distinguishable spatial-spectral features were fed to a fully connected layer for classification. To verify the effectiveness of the proposed framework, we compared it with the state-of-the-art methods on BCI competition IV datasets 2a and 2b. Main results. The results showed that the DSSFLNN framework can achieve a mean Cohen’s kappa value of 0.7 on two datasets, which outperformed the state-of-the-art methods. Moreover, two additional experiments were conducted and they proved that the combination of band-wise feature learning and class-wise feature learning can achieve significantly better performance than only using either one of them. Significance. The proposed DSSFLNN can effectively improve the decoding performance of MI-based BCIs.

## 157. How Visual Stimuli Evoked P300 is Transforming the Brain–Computer Interface Landscape: A PRISMA Compliant Systematic Review

**Authors:** Jai Kalra, Prashasti Mittal, Nirmiti Mittal, Abhishek Arora, Utkarsh Tewari, Aviral Chharia, Rahul Upadhyay, Vinay Kumar, Longo Luca (2023)
**DOI/URL:** 10.1109/TNSRE.2023.3246588

Non-invasive Visual Stimuli evoked-EEG-based P300 BCIs have gained immense attention in recent years due to their ability to help patients with disability using BCI-controlled assistive devices and applications. In addition to the medical field, P300 BCI has applications in entertainment, robotics, and education. The current article systematically reviews 147 articles that were published between 2006-2021*. Articles that pass the pre-defined criteria are included in the study. Further, classification based on their primary focus, including article orientation, participants’ age groups, tasks given, databases, the EEG devices used in the studies, classification models, and application domain, is performed. The application-based classification considers a vast horizon, including medical assessment, assistance, diagnosis, applications, robotics, entertainment, etc. The analysis highlights an increasing potential for P300 detection using visual stimuli as a prominent and legitimate research area and demonstrates a significant growth in the research interest in the field of BCI spellers utilizing P300. This expansion was largely driven by the spread of wireless EEG devices, advances in computational intelligence methods, machine learning, neural networks and deep learning.

## 158. A comprehensive review on motion trajectory reconstruction for EEG-based brain-computer interface

**Authors:** Pengpai Wang, Xuhao Cao, Yueying Zhou, Peiliang Gong, Muhammad Yousefnezhad, Wei Shao, Daoqiang Zhang (2023)
**DOI/URL:** 10.3389/fnins.2023.1086472

The advance in neuroscience and computer technology over the past decades have made brain-computer interface (BCI) a most promising area of neurorehabilitation and neurophysiology research. Limb motion decoding has gradually become a hot topic in the field of BCI. Decoding neural activity related to limb movement trajectory is considered to be of great help to the development of assistive and rehabilitation strategies for motor-impaired users. Although a variety of decoding methods have been proposed for limb trajectory reconstruction, there does not yet exist a review that covers the performance evaluation of these decoding methods. To alleviate this vacancy, in this paper, we evaluate EEG-based limb trajectory decoding methods regarding their advantages and disadvantages from a variety of perspectives. Specifically, we first introduce the differences in motor execution and motor imagery in limb trajectory reconstruction with different spaces (2D and 3D). Then, we discuss the limb motion trajectory reconstruction methods including experiment paradigm, EEG pre-processing, feature extraction and selection, decoding methods, and result evaluation. Finally, we expound on the open problem and future outlooks.

## 159. EEGPT: Pretrained Transformer for Universal and Reliable Representation of EEG Signals

**Authors:** Guangyu Wang, Wenchao Liu, Yuhong He, Cong Xu, Lin Ma, Haifeng Li (2024)
**DOI/URL:** 10.52202/079017-1239

Electroencephalography (EEG) is crucial for recording brain activity, with applications in medicine, neuroscience, and brain-computer interfaces (BCI). However, challenges such as low signal-to-noise ratio (SNR), high inter-subject variability, and channel mismatch complicate the extraction of robust, universal EEG representations. We propose EEGPT, a novel 10-million-parameter pretrained transformer model designed for universal EEG feature extraction. In EEGPT, a mask-based dual self-supervised learning method for efficient feature extraction is designed. Compared to other mask-based self-supervised learning methods, EEGPT introduces spatio-temporal representation alignment. This involves constructing a self-supervised task based on EEG representations that possess high SNR and rich semantic information, rather than on raw signals. Consequently, this approach mitigates the issue of poor feature quality typically extracted from low SNR signals. Additionally, EEGPT’s hierarchical structure processes spatial and temporal information separately, reducing computational complexity while increasing flexibility and adaptability for BCI applications. By training on a large mixed multi-task EEG dataset, we fully exploit EEGPT’s capabilities. The experiment validates the efficacy and scalability of EEGPT, achieving state-of-the-art performance on a range of downstream tasks with linear-probing. Our research advances EEG representation learning

## 160. Driver Drowsiness Detection: An Approach Based on Intelligent Brain–Computer Interfaces

**Authors:** Tharun Kumar Reddy, L. Behera (2022)
**DOI/URL:** 10.1109/MSMC.2021.3069145

Estimating reaction times (RTs) and drowsiness states from brain signals is a notable step in creating passive brain–computer interfaces (BCIs). Prior to the deep learning era, estimating RTs and drowsiness from electroencephalogram (EEG) signals was feasible only with moderate accuracy, which led to unreliability for neuro-engineering applications. However, recent developments in machine learning algorithms, notably stationarity-based approaches and deep convolutional neural networks (CNNs), have demonstrated promising results for a class of BCI systems, e.g., motor imagery BCIs, and affective state classification. These methods have not been systematically analyzed for EEG-based driver drowsiness detection and RT prediction.

## 161. Feature Extraction Method Based on Filter Banks and Riemannian Tangent Space in Motor-Imagery BCI

**Authors:** Hua Fang, Jing Jin, I. Daly, Xingyu Wang (2022)
**DOI/URL:** 10.1109/JBHI.2022.3146274

Optimal feature extraction for multi-category motor imagery brain-computer interfaces (MI-BCIs) is a research hotspot. The common spatial pattern (CSP) algorithm is one of the most widely used methods in MI-BCIs. However, its performance is adversely affected by variance in the operational frequency band and noise interference. Furthermore, the performance of CSP is not satisfactory when addressing multi-category classification problems. In this work, we propose a fusion method combining Filter Banks and Riemannian Tangent Space (FBRTS) in multiple time windows. FBRTS uses multiple filter banks to overcome the problem of variance in the operational frequency band. It also applies the Riemannian method to the covariance matrix extracted by the spatial filter to obtain more robust features in order to overcome the problem of noise interference. In addition, we use a One-Versus-Rest support vector machine (OVR-SVM) model to classify multi-category features. We evaluate our FBRTS method using BCI competition IV dataset 2a and 2b. The experimental results show that the average classification accuracy of our FBRTS method is 77.7% and 86.9% in datasets 2a and 2b respectively. By analyzing the influence of the different numbers of filter banks and time windows on the performance of our FBRTS method, we can identify the optimal number of filter banks and time windows. Additionally, our FBRTS method can obtain more distinctive features than the filter banks common spatial pattern (FBCSP) method in two-dimensional embedding space. These results show that our proposed method can improve the performance of MI-BCIs.

## 162. OptEF-BCI: An Optimization-Based Hybrid EEG and fNIRS–Brain Computer Interface

**Authors:** M. U. Ali, Kwang-su Kim, K. D. Kallu, A. Zafar, Seung Won Lee (2023)
**DOI/URL:** 10.3390/bioengineering10050608

Multimodal data fusion (electroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS)) has been developed as an important neuroimaging research field in order to circumvent the inherent limitations of individual modalities by combining complementary information from other modalities. This study employed an optimization-based feature selection algorithm to systematically investigate the complementary nature of multimodal fused features. After preprocessing the acquired data of both modalities (i.e., EEG and fNIRS), the temporal statistical features were computed separately with a 10 s interval for each modality. The computed features were fused to create a training vector. A wrapper-based binary enhanced whale optimization algorithm (E-WOA) was used to select the optimal/efficient fused feature subset using the support-vector-machine-based cost function. An online dataset of 29 healthy individuals was used to evaluate the performance of the proposed methodology. The findings suggest that the proposed approach enhances the classification performance by evaluating the degree of complementarity between characteristics and selecting the most efficient fused subset. The binary E-WOA feature selection approach showed a high classification rate (94.22 ± 5.39%). The classification performance exhibited a 3.85% increase compared with the conventional whale optimization algorithm. The proposed hybrid classification framework outperformed both the individual modalities and traditional feature selection classification (p < 0.01). These findings indicate the potential efficacy of the proposed framework for several neuroclinical applications.

## 163. Analysis of Minimal Channel Electroencephalography for Wearable Brain–Computer Interface

**Authors:** Arpa Suwannarat, S. Pan-ngum, P. Israsena (2024)
**DOI/URL:** 10.3390/electronics13030565

Electroencephalography (EEG)-based brain—computer interface (BCI) is a non-invasive technology with potential in various healthcare applications, including stroke rehabilitation and neuro-feedback training. These applications typically require multi-channel EEG. However, setting up a multi-channel EEG headset is time-consuming, potentially resulting in patient reluctance to use the system despite its potential benefits. Therefore, we investigated the appropriate number of electrodes required for a successful BCI application in wearable devices using various numbers of EEG channels. EEG multi-frequency features were extracted using the “filter bank” feature extraction technique. A support vector machine (SVM) was used to classify a left/right-hand opening/closing motor imagery (MI) task. Nine electrodes around the center of the scalp (F3, Fz, F4, C3, Cz, C4, P3, Pz, and P4) provided high classification accuracy with a moderate setup time; hence, this system was selected as the minimal number of required channels. Spherical spline interpolation (SSI) was also applied to investigate the feasibility of generating EEG signals from limited channels on an EEG headset. We found classification accuracies of interpolated groups only, and combined interpolated and collected groups were significantly lower than the measured groups. The results indicate that SSI may not provide additional EEG data to improve classification accuracy of the collected minimal channels. The conclusion is that other techniques could be explored or a sufficient number of EEG channels must be collected without relying on generated data. Our proposed method, which uses a filter bank feature, session-dependent training, and the exploration of many groups of EEG channels, offers the possibility of developing a successful BCI application using minimal channels on an EEG device.

## 164. ADFCNN: Attention-Based Dual-Scale Fusion Convolutional Neural Network for Motor Imagery Brain–Computer Interface

**Authors:** Wei Tao, Z. Wang, C. Wong, Ziyu Jia, Senior Member Ieee Xun Chen, F. I. C. L. Philip Chen, Feng Wan, ChangLiiswith (2023)
**DOI/URL:** 10.1109/TNSRE.2023.3342331

Convolutional neural networks (CNNs) have been successfully applied to motor imagery (MI)-based brain–computer interface (BCI). Nevertheless, single-scale CNN fail to extract abundant information over a wide spectrum from EEG signals, while typical multi-scale CNNs cannot effectively fuse information from different scales with concatenation-based methods. To overcome these challenges, we propose a new scheme equipped with attention-based dual-scale fusion convolutional neural network (ADFCNN), which jointly extracts and fuses EEG spectral and spatial information at different scales. This scheme also provides novel insight through self-attention for effective information fusion from different scales. Specifically, temporal convolutions with two different kernel sizes identify EEG $\boldsymbol{\mu }$ and $\boldsymbol{\beta }$ rhythms, while spatial convolutions at two different scales generate global and detailed spatial information, respectively, and the self-attention mechanism performs feature fusion based on the internal similarity of the concatenated features extracted by the dual-scale CNN. The proposed scheme achieves the superior performance compared with state-of-the-art methods in subject-specific motor imagery recognition on BCI Competition IV dataset 2a, 2b and OpenBMI dataset, with the cross-session average classification accuracies of 79.39% and significant improvements of 9.14% on BCI-IV2a, 87.81% and 7.66% on BCI-IV2b, 65.26% and 7.2% on OpenBMI dataset, and the within-session average classification accuracies of 86.87% and significant improvements of 10.89% on BCI-IV2a, 87.26% and 8.07% on BCI-IV2b, 84.29% and 5.17% on OpenBMI dataset, respectively. What is more, ablation experiments are conducted to investigate the mechanism and demonstrate the effectiveness of the dual-scale joint temporal-spatial CNN and self-attention modules. Visualization is also used to reveal the learning process and feature distribution of the model.

## 165. A Fusion Algorithm for EEG Signal Processing Based on Motor Imagery Brain-Computer Interface

**Authors:** Xiaozhong Geng, Song Xue, Ping Yu, Dezhi Li, Mengzhe Yue, Xi Zhang, Linen Wang (2022)
**DOI/URL:** 10.1155/2022/8935543

Electroencephalogram (EEG) signal processing is a very important module in the brain-computer interface system. As an important physiological feature of the human body, EEG signals are closely related to the functional state of the cerebral nervous system. However, the EEG signals collected on the scalp are generally weak and inevitably subject to various noise interferences. In order to remove artifacts from the EEG in brain computer interfaces (BCIs), a fusion algorithm for EEG signal preprocessing is proposed. The fusion method includes the following steps: firstly, the raw EEG signals are separated into a set of statistics independent components (ICs) by the improved FastICA algorithm. Then, each independent component is decomposed into a series of intrinsic mode functions (IMFs) by using the improved empirical mode decomposition method (EMD). Many IMFs with high-frequency noise are deleted. The rest of the IMFs are reconstructed. Furthermore, artifacts are further eliminated by iterative process of the improved FastICA algorithm, and then, the EEG signals are reconstructed again by inverse ICA. Finally, the cleaned EEG signal was obtained. The comparative experiment shows that the EMD-ICA fusion algorithm not only accurately eliminates the artifact components but also better retains the local characteristics of the raw EEG. Continuous wavelet transform was used to extract energy features of 
 
 μ
 
 rhythm and 
 
 β
 
 rhythmic to represent the characteristics of EEG signals under different motor imageries. These two features are normalized and used as the input data of the convolutional neural network (CNN) designed by the paper, and the two kinds of features are learned by CNN, and then, the two-classification problem of motor imagery EEG signals is completed. The experimental results show that the average classification accuracy and kappa value of the proposed method are higher than those of SVM and SAE for most subjects.

## 166. Spectral feature extraction from EEG based motor imagery using common spatial patterns

**Authors:** Mustapha Moufassih, Oussama Tarahi, Soukaina Hamou, Said Agounad, Hafida Idrissi Azami (2022)
**DOI/URL:** 10.1109/IRASET52964.2022.9738394

Noninvasive MI-BCI (Motor imagery Brain computer interface) allows people to communicate and control external devices through EEG signals. Feature extraction is an important bloc to obtain a reliable classification accuracy of motor imagery tasks. Common spatial patterns (CSP) is a frequently used algorithm for EEG feature extraction, but its performance relies on the subject-specific frequency band. This paper shows the powerful effect of CSP in discrimination between two classes of motor imagery (left and right hand). Using projected training data on CSP this study demonstrates that subject-specific frequency bands can easily be determined. The experimental results obtained using two public EEG datasets (BCI competition IV dataset 2a and 2b) demonstrate that the subject-specific frequency bands extracted in offline analysis phase using CSP help improve the classification performance of MI-BCI.

## 167. Cognitive Computing for Brain–Computer Interface-Based Computational Social Digital Twins Systems

**Authors:** Zhihan Lv, Liang Qiao, Haibin Lv (2022)
**DOI/URL:** 10.1109/TCSS.2022.3202872

To accurately and effectively analyze electroencephalogram (EEG) with high complexity, large amount of data, and strong uncertainty, brain–computer interface (BCI) cognitive computing and its signal analysis algorithms are studied based on the digital twins (DTs) cognitive computing platform. To avoid the influence of noise on EEG analysis results, it is necessary to use filtering and defalsification methods to process EEG. Four methods, including Butterworth filter, finite impulse response (FIR) filter, elliptic filter, and wavelet decomposition, are summarized. Based on the Riemann manifold theory, a feature extraction algorithm under transfer learning based on tangent space selection (TL-TSS) is proposed. In the process of decoding EEG, an EEG decoding method combining entropy measure and singular spectrum analysis (SSA) is proposed. An algorithm performance is tested on the motor imagery dataset of the two International BCI Competitions. It is found that when the training sample size accounts for 5%, the TL-TSS algorithm proposed in this work is superior to other algorithms in classification accuracy. In particular, compared with common spatial pattern (CSP) algorithm, it has great advantages. The classification accuracy of A2, A4, A8, and A9 users is the best, and especially for A8 users, the classification accuracy reaches 97.88%. In summary, in the EEG interface technology of DT cognitive computing platform, the combination of cognitive computing and deep learning can improve the recognition and analysis effect of EEG, which is of great value for further optimization of DT cognitive computing system.

## 168. LMDA-Net: A lightweight multi-dimensional attention network for general EEG-based brain-computer interface paradigms and interpretability

**Authors:** Zhengqing Miao, Xin Zhang, Mei-rong Zhao, Dong Ming (2023)
**DOI/URL:** 10.48550/arXiv.2303.16407

EEG-based recognition of activities and states involves the use of prior neuroscience knowledge to generate quantitative EEG features, which may limit BCI performance. Although neural network-based methods can effectively extract features, they often encounter issues such as poor generalization across datasets, high predicting volatility, and low model interpretability. Hence, we propose a novel lightweight multi-dimensional attention network, called LMDA-Net. By incorporating two novel attention modules designed specifically for EEG signals, the channel attention module and the depth attention module, LMDA-Net can effectively integrate features from multiple dimensions, resulting in improved classification performance across various BCI tasks. LMDA-Net was evaluated on four high-impact public datasets, including motor imagery (MI) and P300-Speller paradigms, and was compared with other representative models. The experimental results demonstrate that LMDA-Net outperforms other representative methods in terms of classification accuracy and predicting volatility, achieving the highest accuracy in all datasets within 300 training epochs. Ablation experiments further confirm the effectiveness of the channel attention module and the depth attention module. To facilitate an in-depth understanding of the features extracted by LMDA-Net, we propose class-specific neural network feature interpretability algorithms that are suitable for event-related potentials (ERPs) and event-related desynchronization/synchronization (ERD/ERS). By mapping the output of the specific layer of LMDA-Net to the time or spatial domain through class activation maps, the resulting feature visualizations can provide interpretable analysis and establish connections with EEG time-spatial analysis in neuroscience. In summary, LMDA-Net shows great potential as a general online decoding model for various EEG tasks.

## 169. SCSP-3: A Spectrally Augmented Common Spatial Pattern Approach for Robust Motor Imagery-Based Brain–Computer Interface

**Authors:** Sunreet Khanna, Anirban Chowdhury, Ashish Dutta, Venkatesh K. Subramanian (2024)
**DOI/URL:** 10.1109/JSEN.2024.3351880

Common spatial pattern (CSP) is a widely used method for feature extraction in motor imagery (MI)-based brain–computer interface (BCI) development. However, the performance of traditional CSP features often lacks robustness against intersession and intersubject variabilities present in MI-related electroencephalogram (EEG) signals. To address this limitation, we propose a novel approach to CSP-based feature extraction, combining spectral information obtained from Welch power-spectrum (PS) estimation with temporal variations which we named here as SCSP-3. Our SCSP-3 method employs independent learning paths for the temporal and spectral features extracted through CSP. We introduce a postprocessing step that crosses the classification probabilities from these pathways using element-wise products, deriving linearly separable features. The performance of SCSP-3 is evaluated and compared to the traditional CSP approach utilizing a support vector machine (SVM) for classification following a within-subject evaluation scheme. The results demonstrate a significant improvement in average accuracy for SCSP-3 with more generalizability, as it performs equally well with datasets from healthy subjects and stroke patients. This enhanced robustness and generalizability highlight the potential of SCSP-3 as a superior alternative to traditional CSP-based feature extraction methods for achieving consistent performance across different subject categories.

## 170. Human emotion recognition from EEG-based brain–computer interface using machine learning: a comprehensive review

**Authors:** Essam H. Houssein, A. Hammad, Abdelmgeid A. Ali (2022)
**DOI/URL:** 10.1007/s00521-022-07292-4

Affective computing, a subcategory of artificial intelligence, detects, processes, interprets, and mimics human emotions. Thanks to the continued advancement of portable non-invasive human sensor technologies, like brain–computer interfaces (BCI), emotion recognition has piqued the interest of academics from a variety of domains. Facial expressions, speech, behavior (gesture/posture), and physiological signals can all be used to identify human emotions. However, the first three may be ineffectual because people may hide their true emotions consciously or unconsciously (so-called social masking). Physiological signals can provide more accurate and objective emotion recognition. Electroencephalogram (EEG) signals respond in real time and are more sensitive to changes in affective states than peripheral neurophysiological signals. Thus, EEG signals can reveal important features of emotional states. Recently, several EEG-based BCI emotion recognition techniques have been developed. In addition, rapid advances in machine and deep learning have enabled machines or computers to understand, recognize, and analyze emotions. This study reviews emotion recognition methods that rely on multi-channel EEG signal-based BCIs and provides an overview of what has been accomplished in this area. It also provides an overview of the datasets and methods used to elicit emotional states. According to the usual emotional recognition pathway, we review various EEG feature extraction, feature selection/reduction, machine learning methods (e.g., k-nearest neighbor), support vector machine, decision tree, artificial neural network, random forest, and naive Bayes) and deep learning methods (e.g., convolutional and recurrent neural networks with long short term memory). In addition, EEG rhythms that are strongly linked to emotions as well as the relationship between distinct brain areas and emotions are discussed. We also discuss several human emotion recognition studies, published between 2015 and 2021, that use EEG data and compare different machine and deep learning algorithms. Finally, this review suggests several challenges and future research directions in the recognition and classification of human emotional states using EEG.

## 171. An Optimized SWCSP Technique for Feature Extraction in EEG-based BCI System

**Authors:** Navtej S. Ghumman, B. Jindal (2022)
**DOI/URL:** 10.14500/aro.10926

Brain-computer interface (BCI) is an evolving technology having huge potential for rehabilitation of patients suffering from disorders of the nervous system, besides  many other nonmedical applications. Multichannel electroencephalography (EEG) is widely used to provide input signals to a BCI system. Significant research in methodology employed to implement different stages of BCI system, has led to discovery of new issues and challenges. The raw EEG data includes artifacts from environmental and physiological sources, which is eliminated in preprocessing phase of BCI system. It is then followed by a feature extraction stage to isolate a few relevant features for further classification to a particular motor imagery (MI) activity. A feature extraction approach based on spectrally weighted common spatial pattern (SWCSP) is proposed in this paper to improve overall accuracy of a BCI system. The reported literature uses SWCSP for feature extraction, as it has outperformed other techniques. The proposed approach enhances its performance by optimizing its parameters. The independent component analysis (ICA) method is used for detection and removal of irrelevant data, while linear discriminant analysis (LDA) is used as a classifier. The proposed approach is executed on benchmark data-set 2a of BCI competition IV. It yielded classification accuracy of 70.6% across nine subjects, which is higher than all the reported approaches. 

## 172. Recognizing Tonal and Nontonal Mandarin Sentences for EEG-Based Brain–Computer Interface

**Authors:** Shiau-Ru Yang, T. Jung, Chin-Teng Lin, Kuan-Chih Huang, Chun-Shu Wei, H. Chiueh, Y. Hsin, Guan-Ting Liou, Li-Chun Wang (2022)
**DOI/URL:** 10.1109/TCDS.2021.3137251

Most current research has focused on nontonal languages such as English. However, more than 60% of the world’s population speaks tonal languages. Mandarin is the most spoken tonal languages in the world. Interestingly, the use of tone in tonal languages may represent different meanings of words and reflect feelings, which is very different from nontonal languages. The objective of this study is to determine whether a spoken Mandarin sentence with or without tone can be distinguished by analyzing electroencephalographic (EEG) signals. We first constructed a new Brain Research Center Speech (BRCSpeech) database to recognize Mandarin. The EEG data of 14 participants were recorded, while they articulated preselected sentences. To the best of our knowledge, this is the first study to apply the method of asymmetric feature extraction method for speech recognition using EEG signals. This study shows that the feature extraction method of rational asymmetry (RASM) can achieve the best accuracy in the classification of cross-subjects. In addition, our proposed binomial variable algorithm methodology can achieve 98.82% accuracy in cross-subject classification. Furthermore, we demonstrate that the use of eight channels [(F7, F8), (C5, C6), (P5, P6), and (O1, O2)] can achieve an accurate of 94.44%. This study explores the neurophysiological correlation of Mandarin pronunciation, which can help develop a tonal language synthesis system based on BCI in the future.

## 173. Band power feature part-based convolutional neural network with African vulture optimization fostered channel selection for EEG classification

**Authors:** Vairaprakash Selvaraj, Manjunathan Alagarsamy, Kavitha Datchanamoorthy, Geethalakshmi Manickam (2024)
**DOI/URL:** 10.1080/10255842.2024.2356633

Abstract The electroencephalogram-based motor imagery (MI-EEG) classification task is significant for brain–computer interface (BCI). EEG signals need a lot of channels to be acquired, which makes it difficult to use in real-world applications. Choosing the optimal channel subset without severely impacting the classification performance is a problem in the field of BCI. To overwhelm this problem, a band power feature part-based convolutional neural network with African vulture optimization fostered channel selection for EEG classification (PCNNC-AVOACS-EEG) is proposed in this article. Initially, the input EEG signals are taken from BCI competition IV, dataset 1. Then the input EEG signals are pre-processed by contrast-limited adaptive histogram equalization filtering. These pre-processed EEG signals are extracted by hexadecimal local adaptive binary pattern (HLABP) method. This HLABP method extracts the features of alpha and beta bands from the EEG segments. Each EEG channel’s band power data are utilized as features for a PCNNC to exactly classify the EEG into 3 classes: two MI states and idle state. The AVOA is applied within the band power feature PCNNC for channel selection, wherein channel selection aids to enhance the categorization accuracy on test set that is a vital indicator for real-time BCI applications. The proposed method is activated in python. From the experiment, the proposed technique attains 17.91%, 20.46% and 18.146% higher accuracy; 14.105%, 15.295% and 5.291% higher area under the curve and 70%, 60% and 65.714% lower computation time compared with the existing approaches.

## 174. A Dual-Branch Spatio-Temporal-Spectral Transformer Feature Fusion Network for EEG-Based Visual Recognition

**Authors:** Jiebo Luo, Weigang Cui, Song Xu, Lina Wang, Xiao Li, Xiaofeng Liao, Yang Li (2024)
**DOI/URL:** 10.1109/TII.2023.3280560

Recognizing visual objects from single-trial electroencephalograph (EEG) signals is a promising brain-computer interface technology. However, due to the redundant features from noisy multichannel EEG signals, it is still a challenging task to achieve high precision recognition. Recent deep learning approaches commonly extract spatio-temporal features of EEG signals, which neglect important spectral-temporal features and may degrade the EEG recognition performance. To address the deficiency, we propose a novel channel attention weighting and multilevel adaptive spectral aggregation based dual-branch spatio-temporal-spectral transformer feature fusion network (CAW-MASA-STST) for EEG-based visual recognition. Specially, we first develop a channel attention weighting (CAW) to automatically learn the channel weights of EEG signals. Then, a graph convolution-based MASA is employed to aggregate spectral-temporal features of different sub-bands. Finally, an STST is designed to fuse spatio-temporal and spectral-temporal features, which enhances the comprehensive learning ability by modeling the temporal dependencies of the fused features. Competitive experimental results on two public datasets demonstrate that the proposed method is able to achieve superior recognition performance compared with the state-of-the-art methods, indicating a feasible solution for visual recognition-based BCI technology. The code of our proposed method will be available at https://github.com/ljbuaa/VisualDecoding.

## 175. Motion Control Using Brain Computer Interface Utilizing GCNs-Net with BILstms

**Authors:** S. Gokulnath, A. Ponraj, Bhargav Krishna, Shivaganesh, Sandeep (2024)
**DOI/URL:** 10.1109/ICDECS59733.2023.10503435

This study focuses on harnessing EEG (electroencephalogram) brain signals for motion control through a Brain-Computer Interface (BCI). The research integrates advanced deep learning techniques, such as transfer learning with ResNet, for predicting and interpreting these brain signals. Additionally, the study utilizes LSTM (Long Short-Term Memory) and RNN (Recurrent Neural Network) for processing time-series EEG data, enhancing the system’s ability to decode the user’s intended movements.A key element of the research is the application of an attention-based BiLSTM-GCN (Bidirectional Long Short-Term Memory-Graph Convolutional Network) model. This model enables deep feature extraction and mining in the context of human motor imagery recognition. It empowers the system to effectively understand and respond to the user’s intentions based on their EEG patterns.The ultimate goal of this research is to create a more efficient and accurate BCI system that can recognize and interpret the user’s brain signals, allowing for precise and intuitive motion control. This has the potential to revolutionize various fields, including assistive technology, neurorehabilitation, and human-computer interaction. The combination of EEG-based control and deep learning methods holds promise for enhancing the quality of life for individuals with disabilities and expanding the horizons of human-machine communication.

## 176. Electroencephalogram-Based Motor Imagery Brain–Computer Interface Using Multivariate Iterative Filtering and Spatial Filtering

**Authors:** Kritiprasanna Das, R. B. Pachori (2023)
**DOI/URL:** 10.1109/TCDS.2022.3214081

In motor imagery (MI)-based brain–computer interface (BCI), common spatial pattern (CSP) is most popularly used for discriminant feature extraction. However, the performance of CSP depends on the operational frequency bands, which are selected manually or set to a broad frequency range in most of the previously developed applications. Due to subject to subject or even trial to trial variability of frequency band affected by MI task, these methods suffer from the poor performance. We have proposed a novel approach, using combination of multivariate iterative filtering (MIF) and CSP (MIFCSP), to automatically select optimal frequency bands based on MIF which can be further used for discriminant feature extraction. MIF decomposes the signal into several multivariate intrinsic mode functions, from which features are extracted using CSP. We select the minimum number of most significant features for which highest classification accuracy is achieved. Subsequently, linear discriminant analysis (LDA) classifier is used to classify different MI tasks. Experimental results for BCI competition IV data set 2a and BCI competition III-IIIa are presented. For left-hand versus right-hand MI classification, proposed MIFCSP method provides 83.18% and 84.44% average accuracy, respectively. Superior classification performance confirms that MIFCSP is a promising candidate for MI BCI application.

## 177. Relevant Frequency Band Selection using Sequential Forward Feature Selection for Motor Imagery Brain Computer Interfaces

**Authors:** J. Kirar, R. Agrawal (2018)
**DOI/URL:** 10.1109/SSCI.2018.8628719

In order to provide basic communication abilities to people with motor disability, motor imagery brain computer interface is one of most widely used technique. In this paper, we present a novel algorithm (Composite Filter bank based stationary CSP) for determining subject as well as task specific discriminative frequency bands for classification of motor imagery tasks. It is noted in the literature that while performing any motor imagery tasks, two major frequency band of EEG spectrum i.e mu (7-12 Hz) as well as beta (12-30 Hz) bands are actively involved. Hence, in most of the literature work EEG signals were filtered using a frequency band of 7-30 Hz usually before using CSP transformation. However, it is possible that some of the frequencies may not provide useful features to distinguish motor imagery tasks. In this paper, we propose a novel approach to select a subset of relevant frequency bands using sequential forward feature selection method from a composite filter bank which consists of Prior-known EEG frequency bands and a set of variable size overlapping frequency bands to improve the performance of motor imagery tasks classification. Experimental results of the proposed work on publicly available datasets validate the effectiveness of the proposed method. Friedman statistical test conducted further shows that the proposed approach significantly outperforms the existing methods.

## 178. Optimal Fuzzy Logic Enabled EEG Motor Imagery Classification for Brain Computer Interface

**Authors:** Eunmok Yang, K. Shankar, Eswaran Perumal, Changho Seo (2024)
**DOI/URL:** 10.1109/ACCESS.2023.3346674

Brain-computer interface BCI) is a technology that assists in straight link among the human brain as well as external devices like computers or robotic systems, without including muscles and peripheral nerves. BCI allows individuals with motor disabilities to manage external devices with the aid of brain signals such as motor imagery detected from electroencephalography (EEG) signals. An EEG Motor Imagery Classification for BCI is a specific application of EEG in which brain signals directly related to motor imagery tasks are analyzed and classified to control external devices or applications, namely robotic systems or computers. In this regard, the study introduces a Jellyfish Optimization with Fuzzy Logic Enabled EEG Motor Imagery Classification for Brain Computer Interface (JFOFL-MICBCI) technique. The JFOFL-MICBCI technique aims to exploit the fuzzy logic system with metaheuristics for classifying EEC motor imagery signals. It initially executes Continuous Wavelet Transform (CWT) for transforming 1D-EEG signals into 2D time-frequency amplitude ones. For feature extraction, the JFOFL-MICBCI technique uses the SqueezeNet method, and its hyperparameters can be adjusted by the employ of the JFO system. The JFOFL-MICBCI method exploits the adaptive neuro-fuzzy inference system (ANFIS) approach for performing the classification process. A comprehensive range of experiments has been accompanied to demonstrate the higher efficiency of the JFOFL-MICBCI technique. The obtained results inferred the better of the JFOFL-MICBCI technique with other recent systems.

## 179. Motor Imagery EEG Decoding Based on Multi-Scale Hybrid Networks and Feature Enhancement

**Authors:** Xianlun Tang, Caiquan Yang, Xia Sun, Mi Zou, Huiming Wang (2023)
**DOI/URL:** 10.1109/TNSRE.2023.3242280

Motor Imagery (MI) based on Electroencephalography (EEG), a typical Brain-Computer Interface (BCI) paradigm, can communicate with external devices according to the brain’s intentions. Convolutional Neural Networks (CNN) are gradually used for EEG classification tasks and have achieved satisfactory performance. However, most CNN-based methods employ a single convolution mode and a convolution kernel size, which cannot extract multi-scale advanced temporal and spatial features efficiently. What’s more, they hinder the further improvement of the classification accuracy of MI-EEG signals. This paper proposes a novel Multi-Scale Hybrid Convolutional Neural Network (MSHCNN) for MI-EEG signal decoding to improve classification performance. The two-dimensional convolution is used to extract temporal and spatial features of EEG signals and the one-dimensional convolution is used to extract advanced temporal features of EEG signals. In addition, a channel coding method is proposed to improve the expression capacity of the spatiotemporal characteristics of EEG signals. We evaluate the performance of the proposed method on the dataset collected in the laboratory and BCI competition IV 2b, 2a, and the average accuracy is at 96.87%, 85.25%, and 84.86%, respectively. Compared with other advanced methods, our proposed method achieves higher classification accuracy. Then we use the proposed method for an online experiment and design an intelligent artificial limb control system. The proposed method effectively extracts EEG signals’ advanced temporal and spatial features. Additionally, we design an online recognition system, which contributes to the further development of the BCI system.

## 180. Enhancing Four-Class Motor Imagery Detection Through Advanced Feature Extraction Techniques

**Authors:** Jihen Souissi, Sourour Karmani, Kais Belwafi, R. Djemal (2024)
**DOI/URL:** 10.1109/AICCSA63423.2024.10912553

Brain-computer interface (BCI) technology has great potential in control, communication, and neurological diagnostics by interpreting EEG signals. This paper introduces a novel method for extracting distinguishing features from EEG signals using a Common Spatial Patterns (CSP) model, enhanced with a Phase Space Reconstruction model and followed by an autoregressive (AR) model. Initially, EEG signals are denoised using an IIR Butterworth filter before feature extraction. Two classifiers, Linear Discriminant Analysis (LDA) and Multi-Layer Perceptron (MLP), are employed to differentiate features across four motor imagery (MI) tasks. For a four-class MI task, combining spatial and temporal-frequency domain features, LDA achieves an accuracy of 67.40%, while MLP reaches 64.78%. LDA yields precision and recall scores of 67.40% and 67.20%, respectively, for the F1-score, whereas MLP records precision, recall, and F1-scores of 65.36%, 64.78%, and 64.28%, respectively. The proposed architecture is evaluated using the BCI Competition IV set 2a dataset, proving its effectiveness in EEG signal classification for BCI applications.

## 181. A review of recent trends in EEG based Brain-Computer Interface

**Authors:** P. Lahane, Jay Jagtap, Aditya Inamdar, Nihal Karne, Ritwik Dev (2019)
**DOI/URL:** 10.1109/ICCIDS.2019.8862054

In recent times, the advancements in Brain-Computer Interface has not only been instrumental in achieving its fundamental purpose of aiding disabled people, but also in creating novel applications like playing games without physical controls or operating home appliances merely by the power of your brain. The electrical activity generated in the brain is measured by an EEG device after which the collected raw data undergoes through various steps, namely: Signal acquisition, Data Preprocessing, Feature Extraction, and Classification. This paper helps the reader in understanding the different algorithms and methods used in each of these processes. A detailed survey of various applications of BCI using different feature extraction and classification techniques is done. Finally, we have compiled all the current issues which hinder the efficiency of BCI systems.

## 182. A CNN model with feature integration for MI EEG subject classification in BMI

**Authors:** Anisha Roy (2022)
**DOI/URL:** 10.1101/2022.01.05.475058

Objective Electroencephalogram (EEG) based motor imagery (MI) classification is an important aspect in brain-machine interfaces (BMIs) which bridges between neural system and computer devices decoding brain signals into recognizable machine commands. However, the MI classification task is challenging due to inherent complex properties, inter-subject variability, and low signal-to-noise ratio (SNR) of EEG signals. To overcome the above-mentioned issues, the current work proposes an efficient multi-scale convolutional neural network (MS-CNN). Approach In the framework, discriminant user-specific features have been extracted and integrated to improve the accuracy and performance of the CNN classifier. Additionally, different data augmentation methods have been implemented to further improve the accuracy and robustness of the model. Main results The model achieves an average classification accuracy of 93.74% and Cohen’s kappa-coefficient of 0.92 on the BCI competition IV2b dataset outperforming several baseline and current state-of-the-art EEG-based MI classification models. Significance The proposed algorithm effectively addresses the shortcoming of existing CNN-based EEG-MI classification models and significantly improves the classification accuracy.

## 183. Improving EEG based brain computer interface emotion detection with EKO ALSTM model

**Authors:** R. K. Kanna, Preety Shoran, Meenakshi Yadav, Mohammad Nadeem Ahmed, S. Burje, Garima Shukla, Anurag Sinha, Mohammad Rashid Hussain, Saifullah Khalid (2025)
**DOI/URL:** 10.1038/s41598-025-07438-z

Decoding signals from the CNS brain activity is done by a computer-based communication device called a BCI. In contrast, the system is considered compelling communication equipment enabling command, communication, and action without using neuromuscular or muscle channels. Various techniques for automatic emotion identification based on body language, speech, or facial expressions are nowadays in use. However, the monitoring of exterior emotions, which are easily manipulated, limits the applicability of these procedures. EEG-based emotion detection research might yield significant benefits for enhancing BCI application performance and user experience. To overcome these issues, this study proposed a novel EKO-ALSTM for emotion detection in EEG-based brain–computer interfaces. The proposed study comprises EEG-based signals that record the electrical activity of the brain connected to various emotional states, which are gathered as real-time acquired EEG signals for emotion detection. The data was pre-processed using a bandpass filter to remove unwanted frequency noise for the obtained data. Then, feature extraction is performed using DWT from pre-processed data. Specifically, the proposed approach is implemented using Python software. The proposed system and existing algorithms are compared using a variety of evaluation criteria, including specificity, F1 score, accuracy, recall or sensitivity, and positive predictive values or precision. The results demonstrated that the proposed method achieved better performance in EEG-based BCI emotion detection with an accuracy of 97.93%, a positive predictive value of 96.24%, a sensitivity of 97.81%, and a specificity of 97.75%. This study emphasizes that innovative approaches have significantly increased the accuracy of emotion identification when applied to EEG-based emotion recognition systems. Additionally, the findings suggest that integrating advanced machine learning techniques can further enhance the effectiveness and reliability of these systems in real-world applications, paving the way for more responsive and intuitive BCI technologies.

## 184. Performance Analysis of Machine Learning Algorithms for Classifying Hand Motion-Based EEG Brain Signals

**Authors:** Ayman Altameem, Jaideep Singh Sachdev, Vijander Singh, Ramesh Chandra Poonia, Sandeep Kumar, Abdul Khader Jilani Saudagar (2022)
**DOI/URL:** 10.32604/csse.2022.023256

Brain-computer interfaces (BCIs) records brain activity using electroencephalogram (EEG) headsets in the form of EEG signals; these signals can be recorded, processed and classified into different hand movements, which can be used to control other IoT devices. Classification of hand movements will be one step closer to applying these algorithms in real-life situations using EEG headsets. This paper uses different feature extraction techniques and sophisticated machine learning algorithms to classify hand movements from EEG brain signals to control prosthetic hands for amputated persons. To achieve good classification accuracy, denoising and feature extraction of EEG signals is a significant step. We saw a considerable increase in all the machine learning models when the moving average filter was applied to the raw EEG data. Feature extraction techniques like a fast fourier transform (FFT) and continuous wave transform (CWT) were used in this study; three types of features were extracted, i.e., FFT Features, CWT Coefficients and CWT scalogram images. We trained and compared different machine learning (ML) models like logistic regression, random forest, k-nearest neighbors (KNN), light gradient boosting machine (GBM) and XG boost on FFT and CWT features and deep learning (DL) models like VGG-16, DenseNet201 and ResNet50 trained on CWT scalogram images. XG Boost with FFT features gave the maximum accuracy of 88%.

## 185. Effective Emotion Recognition by Learning Discriminative Graph Topologies in EEG Brain Networks

**Authors:** Cunbo Li, Peiyang Li, Yangsong Zhang, Ning Li, Yajing Si, Fali Li, Zehong Cao, Huafu Chen, Badong Chen, Dezhong Yao, Peng Xu (2023)
**DOI/URL:** 10.1109/TNNLS.2023.3238519

Multichannel electroencephalogram (EEG) is an array signal that represents brain neural networks and can be applied to characterize information propagation patterns for different emotional states. To reveal these inherent spatial graph features and increase the stability of emotion recognition, we propose an effective emotion recognition model that performs multicategory emotion recognition with multiple emotion-related spatial network topology patterns (MESNPs) by learning discriminative graph topologies in EEG brain networks. To evaluate the performance of our proposed MESNP model, we conducted single-subject and multisubject four-class classification experiments on two public datasets, MAHNOB-HCI and DEAP. Compared with existing feature extraction methods, the MESNP model significantly enhances the multiclass emotional classification performance in the single-subject and multisubject conditions. To evaluate the online version of the proposed MESNP model, we designed an online emotion monitoring system. We recruited 14 participants to conduct the online emotion decoding experiments. The average online experimental accuracy of the 14 participants was 84.56%, indicating that our model can be applied in affective brain–computer interface (aBCI) systems. The offline and online experimental results demonstrate that the proposed MESNP model effectively captures discriminative graph topology patterns and significantly improves emotion classification performance. Moreover, the proposed MESNP model provides a new scheme for extracting features from strongly coupled array signals.

## 186. A Stepwise Discriminant Analysis and FBCSP Feature Selection Strategy for EEG MI Recognition

**Authors:** Yinghui Meng, YaRu Su, Duan Li, Jiaofen Nan, Yongquan Xia (2024)
**DOI/URL:** 10.14569/ijacsa.2024.0150597

—Accurate decoding of brain intentions is a pivotal technology within Brain-Computer Interface (BCI) systems that rely on Motor Imagery (MI). The effective extraction of information features plays a critical role in the precise decoding of these brain intentions. However, there exists significant individual and environmental variability in signals, and the sensitivity of EEG signals from different subjects also varies, imposing higher demands on both feature exploration and accurate decoding. To address these challenges, we employ adaptive sliding time windows and a stepwise discriminant analysis strategy to selectively extract features obtained through the Filter Bank Common Spatial Pattern (FBCSP). This entails the identification of an optimal feature combination tailored to specific patients, thereby mitigating individual differences and environmental variations. Initially, adaptive sliding time windows are applied to segment electroencephalogram (EEG) data for different subjects, followed by FBCSP for feature extraction. Subsequently, a stepwise discriminant analysis (SDA) incorporating prior knowledge is employed for optimal feature selection, effectively and adaptively identifying the best feature combination for specific subjects. The proposed method is evaluated using two publicly available datasets, the EEG recognition accuracy for Dataset A is 98.47%, and for Dataset B, it is 95.2%. In comparison to current publicly reported research results (utilizing Power Spectral Density (PSD) + Support Vector Machine (SVM) methods) for Dataset A, the proposed method improves MI recognition accuracy by 25.37%. For Dataset B, compared to current publicly reported results (FBCNet method), the proposed method improves MI recognition accuracy by 26.4%. The experimental results underscore the method's broad applicability, scalability, and substantial value for promotion and

## 187. Feature extraction of four-class motor imagery EEG signals based on functional brain network

**Authors:** Qingsong Ai, Anqi Chen, Kun Chen, QUAN LIU, Tichao Zhou, Sijin Xin, Ze Ji (2019)
**DOI/URL:** 10.1088/1741-2552/ab0328

Objective. A motor-imagery-based brain–computer interface (MI-BCI) provides an alternative way for people to interface with the outside world. However, the classification accuracy of MI signals remains challenging, especially with an increased number of classes and the presence of high variations with data from multiple individual people. This work investigates electroencephalogram (EEG) signal processing techniques, aiming to enhance the classification performance of multiple MI tasks in terms of tackling the challenges caused by the vast variety of subjects. Approach. This work introduces a novel method to extract discriminative features by combining the features of functional brain networks with two other feature extraction algorithms: common spatial pattern (CSP) and local characteristic-scale decomposition (LCD). After functional brain networks are established from the MI EEG signals of the subjects, the measures of degree in the binary networks are extracted as additional features and fused with features in the frequency and spatial domains extracted by the CSP and LCD algorithms. A real-time BCI robot control system is designed and implemented with the proposed method. Subjects can control the movement of the robot through four classes of MI tasks. Both the BCI competition IV dataset 2a and real-time data acquired in our designed system are used to validate the performance of the proposed method. Main results. As for the offline data experiment results, the average classification accuracy of the proposed method reaches 79.7%, outperforming the majority of popular algorithms. Experimental results with real-time data also prove the proposed method to be highly promising in its real-time performance. Significance. The experimental results show that our proposed method is robust in extracting discriminative brain activity features when performing different MI tasks, hence improving the classification accuracy in four-class MI tasks. The high classification accuracy and low computational demand show a considerable practicality for real-time rehabilitation systems.

## 188. SCDAN: Learning Common Feature Representation of Brain Activation for Intersubject Motor Imagery EEG Decoding

**Authors:** Boxun Fu, Fu Li, Youshuo Ji, Yang Li, Xuemei Xie, Guangming Shi (2023)
**DOI/URL:** 10.1109/TIM.2023.3284926

An electroencephalogram (EEG)-based motor imagery (MI) brain–computer interface (BCI) builds a direct communication channel between humans and computers by decoding EEG signals. The intersubject decoding ability is crucial for the application of MI-BCI, which implies that the subject can use MI-BCI equipment without recording additional data for training. Physiologically, because of the distinction in the imagery method, brain structure, and brain state, the intersubject data distribution of MI EEG data is different. This often leads to a partial or even complete failure of the MI decoding algorithm between subjects. To solve these issues, we propose a novel deep learning method called the spatial and conditional domain adaption network (SCDAN), which aims to adapt the intersubject MI EEG data. In SCDAN, three innovative structures are employed: a parallel temporal–spatial convolution feature extractor, a spatial discriminator, and a conditional discriminator. The feature extractor adopts an improved temporal–spatial convolutional network that has a more reasonable structure and fewer parameters to reduce the risk of intersubject overfitting. The spatial discriminator and conditional discriminator calibrate the training processing to help the feature extractor learn the intersubject common feature representation. We evaluate the performance of SCDAN on the GigaScience dataset and the 2a BCI Competition IV dataset using both one-to-one and leave-one-out transfer protocols. For the one-to-one transfer protocol, the classification accuracies of SCDAN improve by 5.70% and 12.43% compared with the baseline method. And for the leave-one-out transfer protocol, the improvements are 8.60% and 15.84%, respectively. The results show a significant improvement compared with the baseline and comparison methods.

## 189. A correntropy-based classifier for motor imagery brain-computer interfaces

**Authors:** L. F. S. Uribe, C. A. S. Filho, Vinicius Alves de Oliveira, T. B. da Silva Costa, P. G. Rodrigues, D. Soriano, Levy Boccato, G. Castellano, R. Attux (2019)
**DOI/URL:** 10.1088/2057-1976/ab5145

Objective. This work aims to present a deeper investigation of the classification performance achieved by a motor imagery (MI) EEG-based brain-computer interface (BCI) using functional connectivity (FC) measures as features. The analysis is performed for two different datasets and analytical setups, including an information-theoretic based FC estimator (correntropy). Approach. In the first setup, using data acquired by our group, correntropy was compared to Pearson and Spearman correlations for FC estimation followed by graph-based feature extraction and two different classification strategies—linear discriminant analysis (LDA) and extreme learning machines (ELMs) - coupled with a wrapper for feature selection in the mu (7-13 Hz) and beta (13-30 Hz) frequency bands. In the second setup, the BCI competition IV dataset 2a was considered for a broader comparison. Main results. For our own database the correntropy / degree centrality / ELM approach resulted in the most solid framework, with overall classification error as low as 5%. When using the BCI competition dataset, our best result provided a performance comparable to those of the top three competitors. Significance. Correntropy was shown to be the best FC estimator in all analyzed situations in the first experimental setup, capturing the signal temporal behavior and being less sensitive to outliers. The second experimental setup showed that the inclusion of different frequency bands can bring more information and improve the classification performance. Finally, our results pointed towards the importance of the joint use of different graph measures for the classification.

## 190. Motor Task Learning in Brain Computer Interfaces using Time-Dependent Regularized Common Spatial Patterns and Residual Networks

**Authors:** H. Sadreazami, G. Mitsis (2020)
**DOI/URL:** 10.1109/newcas49341.2020.9159807

This work proposes a method for motor task recognition in brain computer interfaces (BCI). The proposed method is realized by EEG signals classification using time-dependent regularized common spatial patterns and deep residual networks. Unlike other existing methods, the proposed method relies on both the spectral and temporal features by preserving the temporal resolution of the spatially-filtered EEG signals. These features are projected onto an image representation and fed into a residual network for a hierarchical feature learning and classification. Experiments are carried out on benchmark datasets taken from BCI competitions to evaluate the performance of the proposed method and to compare it with other existing methods. The binary classification results of the proposed method demonstrate a superior performance in classification accuracy compared to other existing methods.

## 191. A Review of EEG-Based Brain-Computer Interface Systems Design

**Authors:** Wenchang Zhang, Chuanqi Tan, F. Sun, Hang Wu, Bo Zhang (2018)
**DOI/URL:** 10.26599/BSA.2018.9050010

A brain-computer interface (BCI) system can recognize the mental activities pattern by computer algorithms to control the external devices. Electroencephalogram (EEG) is one of the most common used approach for BCI due to the convenience and non-invasive implement. Therefore, more and more BCIs have been designed for the disabled people that suffer from stroke or spinal cord injury to help them for rehabilitation and life. We introduce the common BCI paradigms, the signal processing, and feature extraction methods. Then, we survey the different combined modes of hybrids BCIs and review the design of the synchronous/asynchronous BCIs. Finally, the shared control methods are discussed.

## 192. Optimum Feature Selection Using Hybrid Grey Wolf Differential Evolution for Motor Imagery Brain Computer Interface

**Authors:** Marzieh Hajizamani, M. Helfroush, K. Kazemi (2020)
**DOI/URL:** 10.1109/ICCKE50421.2020.9303629

One of the challenges in improving the performance of brain computer interface systems is to overcome the large number of extracted features from EEG signals. Feature selection can reduce noisy data, overtraining effects, necessary storage, computational complexity, and can improve the performance of the classifier. Different feature selection methods have been used to achieve these goals. In this study, a new hybrid feature selection method is proposed. It employs a filter bank common spatial pattern for feature extraction and a grey wolf optimization algorithm to search and generate optimal feature subset with performance evaluated by support vector machine classifier. Also, In order to increase the search performance of the proposed feature selection algorithm, a new parallel combined grey wolf and differential evolution optimization algorithm is proposed. Experimental results show that the proposed methods improve the performance of motor imagery brain computer interface system in comparison to the state-of-the-art methods, even with small training data.

## 193. EEG Band Separation Using Multilayer Perceptron for Efficient Feature Extraction and Perfect BCI Paradigm

**Authors:** Md Samiul Haque Sunny, Nashrah Afroze, Eklas Hossain (2020)
**DOI/URL:** 10.1109/ETCCE51779.2020.9350883

For treatment of mental and brain diseases and diagnosis of abnormalities electroencephalogram (EEG) is an important measurement of brain activity. Feature extraction is vital in brain-computer interface (BCI) in the zone of biomedical and bioinformatics research alongside developing and adopting advanced signal processing techniques. Nonstationary and the nonlinear behavior of the EEG signal is the main challenge in feature extraction process. For the betterment of healthcare services, effective and affordable interpretation methods are the emerging keys. In this paper, the main focus is to separate different frequency band from EEG signal to extract features more efficiently using Multilayer Perceptron (MLP). B-Alert X10 is used for EEG acquisition and for analyzing the signal data, a virtual platform MATLAB has been used. For the classification of EEG bands Multilayer Perceptron Neural Network has been implemented which has been proved to be a more effective method with 95.47% accuracy for the classification.

## 194. SSVEP-Based Brain-Computer Interface System for Managing Disabilities

**Authors:** K. R. Swetha, R. G K, S. S V (2022)
**DOI/URL:** 10.1109/ICERECT56837.2022.10060273

Brain-Computer Interface will recognize patterns in mental activity using the computer's algorithm in controlling a third-party device. Ideally, BDI will measure the activity of the brain to command and control messages. Electroencephalogram (EEG) is a commonly used approach in BCI based on its non-invasive and convenient use. As a result, more and more BCIs have been designed for persons with disabilities who suffer from spinal cord injury helping to rehabilitate and live. BCI includes feature extraction methods, the signal processing. Later, the different hybrid BCI combined methods and review the synchronous/asynchronous BCI designs.

## 195. Artificial Intelligence in Brain Computer Interface

**Authors:** A. Subasi (2022)
**DOI/URL:** 10.1109/hora55278.2022.9800002

A brain-computer interface (BCI) is a connection path among brain and an external device. Motor imagery (MI) is proven to be a useful cognitive technique for enhancing motor skills as well as for movement disorder rehabilitation therapy. It is known that the efficiency of MI training can be enhanced by using BCI approach, which provides real-time feedback on the mental attempts of the subject. Artificial intelligence (AI) methods play a key role in detecting changes in brain signals and converting them into appropriate control signals. In this paper, we focus on brain signals that have been obtained from the scalp to control assistive devices. In addition, signal denoising, feature extraction, dimension reduction, and AI techniques utilized for EEG-based BCI are evaluated. Moreover, Bagging and Adaboost are utilized to classify MI task for BCI using EEG signals. Different classifiers are used to enhance the performance of detecting the signals from the brain and make it on the real time and controlling any lateness. MI related brain activities can be categorized efficiently via AI techniques. This paper utilizes wavelet packet decomposition feature extraction approach to improve MI recognition accuracy. The proposed approach classifies MI-related brain signals using ensemble techniques. The results show that the proposed framework surpasses the traditional machine learning approaches. Furthermore, the proposed Adaboost with k-NN ensemble approach also yields a greater performance for MI classification with 94.57% classification accuracy for subject independent case.

## 196. Iterative Outlier Removal Clustering Based Time-Frequency-Spatial Feature Selection for Binary EEG Motor Imagery Decoding

**Authors:** Yue Ma, Xin Wu, Liangsheng Zheng, Pengchen Lian, Yang Xiao, Zhengkun Yi (2022)
**DOI/URL:** 10.1109/tim.2022.3193407

Electroencephalography (EEG)-based motor imagery (MI) brain-computer interface (BCI) is a bridge in the instruments of rehabilitation and motor assistance field to control external assist devices without external stimulation. Feature extraction (FE) is a key to improving the performance of EEG MI decoding. Existing FE methods usually extract single-domain features such as spatial, frequency features, or dual-domain features such as time–frequency features. However, the multidomains features which describe the intent more comprehensively are not simultaneously extracted. Therefore, inspired by short-time Fourier transform (STFT) and common spatial pattern (CSP) FE methods, a frequency-spatial-temporal multidomain (FSTMD) FE method is proposed. To solve the problem of the high dimensions of the FSTMD features, a feature selection (FS) method is designed. In the proposed FSTMD FE process, the STFT is employed to extract the time–frequency domain features first. Then, the time–frequency features of each channel are cascaded. After that, the cascaded features are divided according to time segments. At last, the covariance transform is performed for each time segment. Since the proposed features have a one-to-one correspondence with frequency, channel, and time, the extracted features have good interpretability. The proposed FS method selects the features in the frequency-spatial domain of each time segment based on mutual information and correlation metrics first and then selects the key time segment based on clustering with outlier removal. The performance of the proposed feature is verified in BCI Competition IV Dataset IIa and IIb. Compared to the CSP feature in the only spatial domain, the proposed feature has significantly lower deviation and slightly higher accuracy. The average recognition accuracy of the proposed MI decoding framework is 85.1% on the dataset IIb session 3, which is competitive compared with the state-of-the-art methods.

## 197. Two is better? combining EEG and fMRI for BCI and neurofeedback: a systematic review

**Authors:** Mathis Fleury, Patrícia Figueiredo, A. Vourvopoulos, A. Lécuyer (2023)
**DOI/URL:** 10.1088/1741-2552/ad06e1

Electroencephalography (EEG) and functional magnetic resonance imaging (fMRI) are two commonly used non-invasive techniques for measuring brain activity in neuroscience and brain–computer interfaces (BCI). Objective. In this review, we focus on the use of EEG and fMRI in neurofeedback (NF) and discuss the challenges of combining the two modalities to improve understanding of brain activity and achieve more effective clinical outcomes. Advanced technologies have been developed to simultaneously record EEG and fMRI signals to provide a better understanding of the relationship between the two modalities. However, the complexity of brain processes and the heterogeneous nature of EEG and fMRI present challenges in extracting useful information from the combined data. Approach. We will survey existing EEG–fMRI combinations and recent studies that exploit EEG–fMRI in NF, highlighting the experimental and technical challenges. Main results. We made a classification of the different combination of EEG-fMRI for NF, we provide a review of multimodal analysis methods for EEG–fMRI features. We also survey the current state of research on EEG-fMRI in the different existing NF paradigms. Finally, we also identify some of the remaining challenges in this field. Significance. By exploring EEG-fMRI combinations in NF, we are advancing our knowledge of brain function and its applications in clinical settings. As such, this review serves as a valuable resource for researchers, clinicians, and engineers working in the field of neural engineering and rehabilitation, highlighting the promising future of EEG-fMRI-based NF.

## 198. Identification of Lower-Limb Motor Tasks via Brain–Computer Interfaces: A Topical Overview

**Authors:** Víctor Asanza, Enrique Peláez, Francis R. Loayza, L. L. Lorente-Leyva, D. Peluffo-Ordóñez (2022)
**DOI/URL:** 10.3390/s22052028

Recent engineering and neuroscience applications have led to the development of brain–computer interface (BCI) systems that improve the quality of life of people with motor disabilities. In the same area, a significant number of studies have been conducted in identifying or classifying upper-limb movement intentions. On the contrary, few works have been concerned with movement intention identification for lower limbs. Notwithstanding, lower-limb neurorehabilitation is a major topic in medical settings, as some people suffer from mobility problems in their lower limbs, such as those diagnosed with neurodegenerative disorders, such as multiple sclerosis, and people with hemiplegia or quadriplegia. Particularly, the conventional pattern recognition (PR) systems are one of the most suitable computational tools for electroencephalography (EEG) signal analysis as the explicit knowledge of the features involved in the PR process itself is crucial for both improving signal classification performance and providing more interpretability. In this regard, there is a real need for outline and comparative studies gathering benchmark and state-of-art PR techniques that allow for a deeper understanding thereof and a proper selection of a specific technique. This study conducted a topical overview of specialized papers covering lower-limb motor task identification through PR-based BCI/EEG signal analysis systems. To do so, we first established search terms and inclusion and exclusion criteria to find the most relevant papers on the subject. As a result, we identified the 22 most relevant papers. Next, we reviewed their experimental methodologies for recording EEG signals during the execution of lower limb tasks. In addition, we review the algorithms used in the preprocessing, feature extraction, and classification stages. Finally, we compared all the algorithms and determined which of them are the most suitable in terms of accuracy.

## 199. Neural Decoding of EEG Signals with Machine Learning: A Systematic Review

**Authors:** Maham Saeidi, W. Karwowski, F. Farahani, K. Fiok, R. Taiar, P. Hancock, Awad M. Aljuaid (2021)
**DOI/URL:** 10.3390/brainsci11111525

Electroencephalography (EEG) is a non-invasive technique used to record the brain’s evoked and induced electrical activity from the scalp. Artificial intelligence, particularly machine learning (ML) and deep learning (DL) algorithms, are increasingly being applied to EEG data for pattern analysis, group membership classification, and brain-computer interface purposes. This study aimed to systematically review recent advances in ML and DL supervised models for decoding and classifying EEG signals. Moreover, this article provides a comprehensive review of the state-of-the-art techniques used for EEG signal preprocessing and feature extraction. To this end, several academic databases were searched to explore relevant studies from the year 2000 to the present. Our results showed that the application of ML and DL in both mental workload and motor imagery tasks has received substantial attention in recent years. A total of 75% of DL studies applied convolutional neural networks with various learning algorithms, and 36% of ML studies achieved competitive accuracy by using a support vector machine algorithm. Wavelet transform was found to be the most common feature extraction method used for all types of tasks. We further examined the specific feature extraction methods and end classifier recommendations discovered in this systematic review.

## 200. Online Brain Computer Interface Based Five Classes EEG To Control Humanoid Robotic Hand

**Authors:** M. Z. A. Faiz, Ammar A. Al-hamadani (2019)
**DOI/URL:** 10.1109/TSP.2019.8769072

The proposed system had three stages in general, first stage was feature extraction, second stage was training a machine learning algorithm and third stage was online feature extraction and classification of ME/MI to control HRH. Variation for two kinds of feature extraction methods were proposed, Autoregressive (AR) coefficients and Common Spatial Pattern (CSP). Principal Component analysis (PCA) was used to reduce the dimensionality of AR feature. The output of the two methods were concatenated and normalized to train Support Vector Machine (SVM) algorithm. During online stage, EEG signal was acquired using EMOTIV EPOC EEG headset and same processing steps were applied as in training phase. The trained SVM module was used to predict the class of motion from the acquired EEG signal with 97.5% of online accuracy with the aid of majority voting. The predicted class was used as online signal to move the HRH to its corresponding hand gesture.

## 201. A Novel Quick-Response Eigenface Analysis Scheme for Brain–Computer Interfaces

**Authors:** Hojong Choi, Junghun Park, Yeon-Mo Yang (2022)
**DOI/URL:** 10.3390/s22155860

The brain–computer interface (BCI) is used to understand brain activities and external bodies with the help of the motor imagery (MI). As of today, the classification results for EEG 4 class BCI competition dataset have been improved to provide better classification accuracy of the brain computer interface systems (BCIs). Based on this observation, a novel quick-response eigenface analysis (QR-EFA) scheme for motor imagery is proposed to improve the classification accuracy for BCIs. Thus, we considered BCI signals in standardized and sharable quick response (QR) image domain; then, we systematically combined EFA and a convolution neural network (CNN) to classify the neuro images. To overcome a non-stationary BCI dataset available and non-ergodic characteristics, we utilized an effective neuro data augmentation in the training phase. For the ultimate improvements in classification performance, QR-EFA maximizes the similarities existing in the domain-, trial-, and subject-wise directions. To validate and verify the proposed scheme, we performed an experiment on the BCI dataset. Specifically, the scheme is intended to provide a higher classification output in classification accuracy performance for the BCI competition 4 dataset 2a (C4D2a_4C) and BCI competition 3 dataset 3a (C3D3a_4C). The experimental results confirm that the newly proposed QR-EFA method outperforms the previous the published results, specifically from 85.4% to 97.87% ± 0.75 for C4D2a_4C and 88.21% ± 6.02 for C3D3a_4C. Therefore, the proposed QR-EFA could be a highly reliable and constructive framework for one of the MI classification solutions for BCI applications.

## 202. Comparison of Deep Learning and Traditional Machine Learning Classification Performance in a Steady State Visual Evoked Potential Based Brain Computer Interface

**Authors:** Z. Iscan (2022)
**DOI/URL:** 10.17694/bajece.1088353

Brain-computer interfaces (BCIs) offer a very high potential to help those who cannot use their organs properly. In the literature, many electroencephalogram based BCIs exist. Steady state visual evoked potential (SSVEP) based BCIs provide relatively higher accuracy values which make them very popular in BCI research. Recently, deep learning (DL) based methods have been used in electroencephalogram classification problems and they had superior performance over traditional machine learning (ML) methods, which require feature extraction step. This study aimed at comparing the performance of DL and traditional ML based classification performance in terms of stimuli duration, number of channels, and number of trials in an SSVEP based BCI experiment. In the traditional approach canonical correlation analysis method was used for the feature extraction and then three well-known classifiers were used for classification. In DL-based classification, spatio-spectral decomposition (SSD) method was integrated as a preprocessing step to extract oscillatory signals in the frequency band of interest with a convolutional neural network structure. Obtained offline classification results show that proposed DL approach could generate better accuracy values than traditional ML-based methods for short time segments (< 1 s). Besides, use of SSD as a preprocessing step increased the accuracy of DL classification. Superior performance of proposed SSD based DL approach over the traditional ML methods in short trials shows the feasibility of this approach in future BCI designs. Similar approach can be used in other fields where there are oscillatory activity in the recorded signals.

## 203. Features Domains and Classification Algorithms in Motor Imagery Brain Computer Interface

**Authors:** Weizheng Yuan (2022)
**DOI/URL:** 10.1109/EIECT58010.2022.00081

Motor imagery brain-computer interface (MI-BCI) is well approved to help people with movement impairments due to neural disorders. The procedure for MI-BCI to translate MI brain signals to understandable instructions for external devices involves extracting features from recorded signals and predicting desired movements. This paper summarizes and compares feature extraction methods and classification algorithms and their modifications that are commonly used for MI EEG signals. Feature extraction techniques are discussed based on their feature domains: time, frequency, and spatial. Classification algorithms are divided into classical machine learning and deep learning. This paper aims to provide a straightforward view of common ways to extract features and classifying movements in MI-BCI and show difficulties in MI-BCI signal processing. The nature of MI EEG signals and MI-BCI applications points to several promising field such as transfer learning and deep learning neural networks.

## 204. Novel electrotactile brain-computer interface with somatosensory event-related potential based control

**Authors:** A. Savić, Marija Novičić, Olivera Ðorđević, L. Konstantinović, Vera Miler-Jerković (2023)
**DOI/URL:** 10.3389/fnhum.2023.1096814

Objective A brain computer interface (BCI) allows users to control external devices using non-invasive brain recordings, such as electroencephalography (EEG). We developed and tested a novel electrotactile BCI prototype based on somatosensory event-related potentials (sERP) as control signals, paired with a tactile attention task as a control paradigm. Approach A novel electrotactile BCI comprises commercial EEG device, an electrical stimulator and custom software for EEG recordings, electrical stimulation control, synchronization between devices, signal processing, feature extraction, selection, and classification. We tested a novel BCI control paradigm based on tactile attention on a sensation at a target stimulation location on the forearm. Tactile stimuli were electrical pulses delivered at two proximal locations on the user’s forearm for stimulating branches of radial and median nerves, with equal probability of the target and distractor stimuli occurrence, unlike in any other ERP-based BCI design. We proposed a compact electrical stimulation electrodes configuration for delivering electrotactile stimuli (target and distractor) using 2 stimulation channels and 3 stimulation electrodes. We tested the feasibility of a single EEG channel BCI control, to determine pseudo-online BCI performance, in ten healthy subjects. For optimizing the BCI performance we compared the results for two classifiers, sERP averaging approaches, and novel dedicated feature extraction/selection methods via cross-validation procedures. Main results We achieved a single EEG channel BCI classification accuracy in the range of 75.1 to 88.1% for all subjects. We have established an optimal combination of: single trial averaging to obtain sERP, feature extraction/selection methods and classification approach. Significance The obtained results demonstrate that a novel electrotactile BCI paradigm with equal probability of attended (target) and unattended (distractor) stimuli and proximal stimulation sites is feasible. This method may be used to drive restorative BCIs for sensory retraining in stroke or brain injury, or assistive BCIs for communication in severely disabled users.

## 205. Adaptive multi-degree of freedom Brain Computer Interface using online feedback: Towards novel methods and metrics of mutual adaptation between humans and machines for BCI

**Authors:** Chuong H. Nguyen, George K. Karavas, P. Artemiadis (2019)
**DOI/URL:** 10.1371/journal.pone.0212620

This paper proposes a novel adaptive online-feedback methodology for Brain Computer Interfaces (BCI). The method uses ElectroEncephaloGraphic (EEG) signals and combines motor with speech imagery to allow for tasks that involve multiple degrees of freedom (DoF). The main approach utilizes the covariance matrix descriptor as feature, and the Relevance Vector Machines (RVM) classifier. The novel contributions include, (1) a new method to select representative data to update the RVM model, and (2) an online classifier which is an adaptively-weighted mixture of RVM models to account for the users’ exploration and exploitation processes during the learning phase. Instead of evaluating the subjects’ performance solely based on the conventional metric of accuracy, we analyze their skill’s improvement based on 3 other criteria, namely the confusion matrix’s quality, the separability of the data, and their instability. After collecting calibration data for 8 minutes in the first run, 8 participants were able to control the system while receiving visual feedback in the subsequent runs. We observed significant improvement in all subjects, including two of them who fell into the BCI illiteracy category. Our proposed BCI system complements the existing approaches in several aspects. First, the co-adaptation paradigm not only adapts the classifiers, but also allows the users to actively discover their own way to use the BCI through their exploration and exploitation processes. Furthermore, the auto-calibrating system can be used immediately with a minimal calibration time. Finally, this is the first work to combine motor and speech imagery in an online feedback experiment to provide multiple DoF for BCI control applications.

## 206. EEG changes during passive movements improve the motor imagery feature extraction in BCIs-based sensory feedback calibration

**Authors:** D. Delisle-Rodríguez, Leticia Silva, T. Bastos-Filho (2023)
**DOI/URL:** 10.1088/1741-2552/acb73b

Objective. This work proposes a method for two calibration schemes based on sensory feedback to extract reliable motor imagery (MI) features, and provide classification outputs more correlated to the user’s intention. Method. After filtering the raw electroencephalogram (EEG), a two-step method for spatial feature extraction by using the Riemannian covariance matrices (RCM) method and common spatial patterns is proposed here. It uses EEG data from trials providing feedback, in an intermediate step composed of both kth nearest neighbors and probability analyses, to find periods of time in which the user probably performed well the MI task without feedback. These periods are then used to extract features with better separability, and train a classifier for MI recognition. For evaluation, an in-house dataset with eight healthy volunteers and two post-stroke patients that performed lower-limb MI, and consequently received passive movements as feedback was used. Other popular public EEG datasets (such as BCI Competition IV dataset IIb, among others) from healthy subjects that executed upper-and lower-limbs MI tasks under continuous visual sensory feedback were further used. Results. The proposed system based on the Riemannian geometry method in two-steps (RCM–RCM) outperformed significantly baseline methods, reaching average accuracy up to 82.29%. These findings show that EEG data on periods providing passive movement can be used to contribute greatly during MI feature extraction. Significance. Unconscious brain responses elicited over the sensorimotor areas may be avoided or greatly reduced by applying our approach in MI-based brain–computer interfaces (BCIs). Therefore, BCI’s outputs more correlated to the user’s intention can be obtained.

## 207. Assessment of CSP-based two-stage channel selection approach and local transformation-based feature extraction for classification of motor imagery/movement EEG data

**Authors:** Funda Kutlu Onay, C. Köse (2019)
**DOI/URL:** 10.1515/bmt-2018-0201

Abstract The main idea of brain-computer interfaces (BCIs) is to facilitate the lives of patients having difficulties to move their muscles due to a disorder of their motor nervous systems but healthy cognitive functions. BCIs are usually electroencephalography (EEG)-based, and the success of the BCIs relies on the precision of signal preprocessing, detection of distinctive features, usage of suitable classifiers and selection of effective channels. In this study, a two-stage channel selection and local transformation-based feature extraction are proposed for the classification of motor imagery/movement tasks. In the first stage of the channel selection, the channels were combined according to the neurophysiological information about brain functions acquired from the literature, then averaged and a single channel was formed. In the second stage, selective channels were specified with the common spatial pattern-linear discriminant analysis (CSP-LDA)-based sequential channel removal. After the channel selection phase, the feature extraction was carried out with local transformation-based methods (LTBM): local centroid pattern (LCP), one-dimensional-local gradient pattern (1D-LGP), local neighborhood descriptive pattern (LNDP) and one-dimensional-local ternary pattern (1D-LTP). The distinctions and deficiencies of these methods were compared with other methods in the literature and the classification performances of the k-nearest neighbor (k-NN) and the support vector machines (SVM) were evaluated. As a result, the proposed methods yielded the highest average classification accuracies as 99.34%, 95.95%, 98.66% and 99.90% with the LCP, 1D-LGP, LNDP and 1D-LTP when using k-NN, respectively. The two-stage channel selection and 1D-LTP method showed promising results for recognition of motor tasks. The LTBM will contribute to the development of EEG-based BCIs with the advantages of high classification accuracy, easy implementation and low computational complexity.

## 208. A 1D CNN for high accuracy classification and transfer learning in motor imagery EEG-based brain-computer interface

**Authors:** Francesco Mattioli, C. Porcaro, Gianluca Baldassarre (2021)
**DOI/URL:** 10.1088/1741-2552/ac4430

Objective. Brain-computer interface (BCI) aims to establish communication paths between the brain processes and external devices. Different methods have been used to extract human intentions from electroencephalography (EEG) recordings. Those based on motor imagery (MI) seem to have a great potential for future applications. These approaches rely on the extraction of EEG distinctive patterns during imagined movements. Techniques able to extract patterns from raw signals represent an important target for BCI as they do not need labor-intensive data pre-processing. Approach. We propose a new approach based on a 10-layer one-dimensional convolution neural network (1D-CNN) to classify five brain states (four MI classes plus a ‘baseline’ class) using a data augmentation algorithm and a limited number of EEG channels. In addition, we present a transfer learning method used to extract critical features from the EEG group dataset and then to customize the model to the single individual by training its late layers with only 12-min individual-related data. Main results. The model tested with the ‘EEG Motor Movement/Imagery Dataset’ outperforms the current state-of-the-art models by achieving a 99.38% accuracy at the group level. In addition, the transfer learning approach we present achieves an average accuracy of 99.46% . Significance. The proposed methods could foster the development of future BCI applications relying on few-channel portable recording devices and individual-based training.

## 209. An Empirical Evaluation of Brain Computer Interface Models from a Pragmatic Perspective

**Authors:** A. Tayade, R. Khobragade (2022)
**DOI/URL:** 10.1109/ICERECT56837.2022.10060641

Designing Brain Computer Interfaces (BCIs) is a multi-domain task that involves selection of sensing elements to capture brain signals, pre-processing these signals, their segmentation to obtain Regions of Interest (RoI), feature extraction & selection from these RoIs, classification into computer actions, and post-processing tasks. A wide variety of Machine Learning based methods are proposed by researchers, and each of them have their own internal & external configuration & dependency characteristics. For instance, methods like Convolutional Neural Networks (CNN) are highly generic but provide moderate BCI accuracy, while ensemble methods are existing BCI Models, and evaluates them in terms of their contextual nuances, functionality specific advantages, deployment specific limitations, internal & external reconfiguration requirements, and application specific future scopes. Based on this discussion, readers will be able to identify function models for their context-specific use cases. This text also compares these models in terms of qualitative metrics including accuracy levels, precision levels, computational complexity, cost of deployment, and scalability capabilities. Referring this comparison, readers will be able to identify optimum models for their performance-specific use cases. To further simplify the process of BCI Model selection, this text proposes evaluation of a novel BCI Rank Metric (BRM), which combines these parameters in order to identify models that can be used for multiple performance-specific use cases.

## 210. Single-Trial NIRS Data Classification for Brain–Computer Interfaces Using Graph Signal Processing

**Authors:** P. Petrantonakis, I. Kompatsiaris (2018)
**DOI/URL:** 10.1109/TNSRE.2018.2860629

Near-infrared spectroscopy (NIRS)-based brain–computer interface (BCI) systems use feature extraction methods relying mainly on the slope characteristics and mean changes of the hemodynamic responses in respect to certain mental tasks. Nevertheless, spatial patterns across the measurement channels have been detected and should be considered during the feature vector extraction stage of the BCI realization. In this paper, a graph signal processing (GSP) approach for feature extraction is adopted in order to capture the aforementioned spatial information of the NIRS signals. The proposed GSP-based methodology for feature extraction in NIRS-based BCI systems, namely graph NIRS (GNIRS), is applied on a publicly available dataset of NIRS recordings during a mental arithmetic task. GNIRS exhibits higher classification rates (CRs), up to 92.52%, as compared to the CRs of two state-of-the-art feature extraction methodologies related to slope and mean values of hemodynamic response, i.e., 90.35% and 82.60%, respectively. In addition, GNIRS leads to the formation of feature vectors with reduced dimensionality in comparison with the baseline approaches. Moreover, it is shown to facilitate high CRs even from the first second after the onset of the mental task, paving the way for faster NIRS-based BCI systems.

## 211. Motor-Imagery EEG-Based BCIs in Wheelchair Movement and Control: A Systematic Literature Review

**Authors:** A. Palumbo, V. Gramigna, B. Calabrese, N. Ielpo (2021)
**DOI/URL:** 10.3390/s21186285

The pandemic emergency of the coronavirus disease 2019 (COVID-19) shed light on the need for innovative aids, devices, and assistive technologies to enable people with severe disabilities to live their daily lives. EEG-based Brain-Computer Interfaces (BCIs) can lead individuals with significant health challenges to improve their independence, facilitate participation in activities, thus enhancing overall well-being and preventing impairments. This systematic review provides state-of-the-art applications of EEG-based BCIs, particularly those using motor-imagery (MI) data, to wheelchair control and movement. It presents a thorough examination of the different studies conducted since 2010, focusing on the algorithm analysis, features extraction, features selection, and classification techniques used as well as on wheelchair components and performance evaluation. The results provided in this paper could highlight the limitations of current biomedical instrumentations applied to people with severe disabilities and bring focus to innovative research topics.

## 212. Subject-Independent Wearable P300 Brain–Computer Interface Based on Convolutional Neural Network and Metric Learning

**Authors:** Li Hu, Wei Gao, Zilin Lu, Chun Shan, Haiwei Ma, Wenyu Zhang, Yuanqing Li (2024)
**DOI/URL:** 10.1109/TNSRE.2024.3457502

The calibration procedure for a wearable P300 brain-computer interface (BCI) greatly impact the user experience of the system. Each user needs to spend additional time establishing a decoder adapted to their own brainwaves. Therefore, achieving subject independent is an urgent issue for wearable P300 BCI needs to be addressed. A dataset of electroencephalogram (EEG) signals was constructed from 100 individuals by conducting a P300 speller task with a wearable EEG amplifier. A framework is proposed that initially improves cross- subject consistency of EEG features through a common feature extractor. Subsequently, a simple and compact convolutional neural network (CNN) architecture is employed to learn an embedding sub-space, where the mapped EEG features are maximally separated, while pursuing the minimum distance within the same class and the maximum distance between different classes. Finally, the model’s generalization capability was further optimized through fine-tuning. Results: The proposed method significantly boosts the average accuracy of wearable P300 BCI to $73.23\pm 7.62$ % without calibration and $78.75\pm 6.37$ % with fine-tuning. The results demonstrate the feasibility and excellent performance of our dataset and framework. A calibration-free wearable P300 BCI system is feasible, suggesting significant potential for practical applications of the wearable P300 BCI system.

## 213. Current Status, Challenges, and Possible Solutions of EEG-Based Brain-Computer Interface: A Comprehensive Review

**Authors:** M. Rashid, N. Sulaiman, A. P. Majeed, R. Musa, A. Nasir, Bifta Sama Bari, S. Khatun (2020)
**DOI/URL:** 10.3389/fnbot.2020.00025

Brain-Computer Interface (BCI), in essence, aims at controlling different assistive devices through the utilization of brain waves. It is worth noting that the application of BCI is not limited to medical applications, and hence, the research in this field has gained due attention. Moreover, the significant number of related publications over the past two decades further indicates the consistent improvements and breakthroughs that have been made in this particular field. Nonetheless, it is also worth mentioning that with these improvements, new challenges are constantly discovered. This article provides a comprehensive review of the state-of-the-art of a complete BCI system. First, a brief overview of electroencephalogram (EEG)-based BCI systems is given. Secondly, a considerable number of popular BCI applications are reviewed in terms of electrophysiological control signals, feature extraction, classification algorithms, and performance evaluation metrics. Finally, the challenges to the recent BCI systems are discussed, and possible solutions to mitigate the issues are recommended.

## 214. Statistical Evaluation of Factors Influencing Inter-Session and Inter-Subject Variability in EEG-Based Brain Computer Interface

**Authors:** Rito Clifford Maswanganyi, Chunling Tu, P. Owolawi, Shengzhi Du (2022)
**DOI/URL:** 10.1109/ACCESS.2022.3205734

A cognitive alteration in the form of diverse mental states has a significant impact on the performance of electroencephalography (EEG) based brain computer interface (BCI). Such alterations include a change in concentration levels commonly recognized as being indicated by the alpha rhythm, drowsiness or mental fatigue which occurs during EEG signal acquisition. Change in mental state give rise to a challenge of variability in EEG characteristics across sessions and subjects. Consequently, this variability constitutes to low intention detection rate (IDR) that renders BCI performance unreliable. This study investigates the impact of multiple factors that lead to the poor performance of the EEG-BCI. Five factors 1) concentration level; 2) selection of independent components(IC); 3) inter-session variability; 4) inter-subject variability; and 5) classification methods on the IDR in EEG based BCI. The alpha rhythm, as the indicator of concentration level, is validated, and the relationship between the alpha rhythm and the IDR is studied among sessions. In addition, ICs are examined to determine their effects on the IDR across sessions. The possibility of two sessions to contain similar EEG characteristics is also examined, where both sessions are acquired from the same subject in different days. Moreover, the possibility of two different subjects to containing similar EEG characteristics is examined. Furthermore, to conquer the challenge of variability in EEG dynamics a feature transfer learning (TL) approach is proposed in this study. Furthermore, three classification methods (TL, K-NN and NB) are examined and compared to determine whether multi-source neural information can improve the classification accuracy of individual sessions or subjects. Three EEG datasets acquired using different paradigms are used for experiments. The datasets include steady state motion visual evoked potential (SSMVEP), motor imagery (MI) and BCI competition IV-a dataset. Experimental results have shown that selection of independent components has an effect on the IDR. In this case IC-2 and IC-11 achieved a lowest and highest accuracies of 51% and 100% for SSMVEP datasets, while IC-9 and the double-component (IC-2 and IC-13) achieved a lowest and highest accuracies of 40% and 69% for MI datasets respectively. The second experiment demonstrated that higher alpha rhythm, depicted by a lower IDR corresponds to a lower concentration level. While a lower alpha rhythm depicted by a higher IDR corresponds to a higher concentration level. Moreover, variability within sessions can significantly deteriorate intention detection rate across sessions. As such a decline in accuracy from 82% to 61%, and from 56% to 44% was observed across both SSMVEP and MI sessions during inter-session experiment respectively. Integration of samples from different sessions but same subject resulted in a highest accuracy of 65%, 59% and 40% for SSMVEP, MI and BCI competition dataset. Integration of samples from different subjects resulted in a highest accuracy of 65%, 44% and 48% for SSMVEP, BCI competition and MI datasets. When three classifiers are evaluated and compared to determine whether multi-source neural information can improve the classification accuracy of individual sessions and subjects or domains, both K-NN and NB achieved highest accuracies of 59% and 52% respectively, while TL showed a significant increase with an accuracy of 98% achieved using SSMVEP sessions. In a similarly manner both K-NN and NB achieved highest accuracies of 49%and 42%respectively using SSMVEP subjects,while TL showed a significant increasewith an accuracy of 64% achieved. Furthermore, when 9 MI subjects acquired from BCI competition dataset were used, both K-NN and NB achieved highest accuracies of 68% and 65% respectively, while a significant increase in accuracy was observed when TL is used with accuracy of 99% achieved. In conclusion, the change of alpha rhythm magnitude among sessions significantly affect the IDR across sessions. While component selection across sessions has significant effects due to non-linear and non-stationary nature of EEGsignals.Moreover,merging of ICs fromdifferent sessions, and inter-subject factor introduce challenges of overfitting resulting in low IDR. The classification methods are also found critical, because some advanced classification methods can improve the classification accuracy.

## 215. Motor Imagery EEG Decoding Based on New Spatial-Frequency Feature and Hybrid Feature Selection Method

**Authors:** Yuan Tang, Zining Zhao, Shaorong Zhang, Zhi Li, Yun Mo, Yan Guo (2022)
**DOI/URL:** 10.1155/2022/2856818

Feature extraction and selection are important parts of motor imagery electroencephalogram (EEG) decoding and have always been the focus and difficulty of brain-computer interface (BCI) system research. In order to improve the accuracy of EEG decoding and reduce model training time, new feature extraction and selection methods are proposed in this paper. First, a new spatial-frequency feature extraction method is proposed. The original EEG signal is preprocessed, and then the common spatial pattern (CSP) is used for spatial filtering and dimensionality reduction. Finally, the filter bank method is used to decompose the spatially filtered signals into multiple frequency subbands, and the logarithmic band power feature of each frequency subband is extracted. Second, to select the subject-specific spatial-frequency features, a hybrid feature selection method based on the Fisher score and support vector machine (SVM) is proposed. The Fisher score of each feature is calculated, then a series of threshold parameters are set to generate different feature subsets, and finally, SVM and cross-validation are used to select the optimal feature subset. The effectiveness of the proposed method is validated using two sets of publicly available BCI competition data and a set of self-collected data. The total average accuracy of the three data sets achieved by the proposed method is 82.39%, which is 2.99% higher than the CSP method. The experimental results show that the proposed method has a better classification effect than the existing methods, and at the same time, feature extraction and feature selection time also have greater advantages.

## 216. A Review of Processing Methods and Classification Algorithm for EEG Signal

**Authors:** Yu Xie, S. Oniga (2020)
**DOI/URL:** 10.2478/cjece-2020-0004

Abstract The analysis technique of EEG signals is developing promptly with the evolution of Brain Computer- Interfaces science. The processing and classification algorithm of EEG signals includes three states: pre-processing, feature extraction and classification. The article discusses both conventional and recent processing techniques of EEG signals at the phases of preprocessing, feature extraction and classification. Finally, analyze popular research directions in the future.

## 217. Brain Computer Interface Based on Motor Imagery for Mechanical Arm Grasp Control

**Authors:** Tianwei Shi, Ke Chen, Ling Ren, Wenhua Cui (2023)
**DOI/URL:** 10.5755/j01.itc.52.2.32873

This paper puts forward a brain computer interface (BCI) system to realize the hand and wrist control using the ABB Mechanical Arm. This BCI system gathers four kinds of motor imaginary (MI) tasks (hand grasp, hand spread, wrist flexion and wrist extension) electroencephalogram (EEG) signals from 30 electrodes. It utilizes two fifth-order Butterworth Band-Pass Filter (BPF) with different bandwidths and normalization method to achieve the raw MI tasks EEG signals preprocessing. The main challenge of feature extraction is to extract enough representative features from MI tasks to classify them. This proposed BCI system extracts eleven kinds of features in time domain and time-frequency domain and uses mutual information method to reduce the large dimension of the extracted features. In addition, the BCI system applies a single convolutional layer Convolutional neural networks (CNN) with 30 filters to implement the quaternary classification of MI tasks. Compared with early researches, the classification accuracy of this BCI system is increased by about 35%. The actual mechanical arm grasping control experiments verifies that this BCI system has good adaptability.

## 218. Brain–Computer-Interface-Based Smart-Home Interface by Leveraging Motor Imagery Signals

**Authors:** Simona Cariello, D. Sanalitro, Alessandro Micali, A. Buscarino, M. Bucolo (2023)
**DOI/URL:** 10.3390/inventions8040091

In this work, we propose a brain–computer-interface (BCI)-based smart-home interface which leverages motor imagery (MI) signals to operate home devices in real-time. The idea behind MI-BCI is that different types of MI activities will activate various brain regions. Therefore, after recording the user’s electroencephalogram (EEG) data, two approaches, i.e., Regularized Common Spatial Pattern (RCSP) and Linear Discriminant Analysis (LDA), analyze these data to classify users’ imagined tasks. In such a way, the user can perform the intended action. In the proposed framework, EEG signals were recorded by using the EMOTIV helmet and OpenVibe, a free and open-source platform that has been utilized for EEG signal feature extraction and classification. After being classified, such signals are then converted into control commands, and the open communication protocol for building automation KNX (“Konnex”) is proposed for the tasks’ execution, i.e., the regulation of two switching devices. The experimental results from the training and testing stages provide evidence of the effectiveness of the users’ intentions classification, which has subsequently been used to operate the proposed home automation system, allowing users to operate two light bulbs.

## 219. Towards Asynchronous Motor Imagery-Based Brain-Computer Interfaces: a joint training scheme using deep learning

**Authors:** Patcharin Cheng, Phairot Autthasan, Boriwat Pijarana, Ekapol Chuangsuwanich, Theerawit Wilaiprasitporn (2018)
**DOI/URL:** 10.1109/TENCON.2018.8650546

In this paper, the deep learning (DL) approach is applied to a joint training scheme for asynchronous motor imagery-based Brain-Computer Interface (BCI). The proposed DL approach is a cascade of one-dimensional convolutional neural networks and fully-connected neural networks (CNN-FC). The focus is mainly on three types of brain responses: non-imagery EEG (background EEG), (pure imagery) EEG, and EEG during the transitional period between background EEG and pure imagery (transitional imagery). The study of transitional imagery signals should provide greater insight into real-world scenarios. It may be inferred that pure imagery and transitional EEG are high and low power EEG imagery, respectively. Moreover, the results from the CNN-FC are compared to the conventional approach for motor imagery-BCI, namely the common spatial pattern (CSP) for feature extraction and support vector machine (SVM) for classification (CSP-SVM). Under a joint training scheme, pure and transitional imagery are treated as the same class, while background EEG is another class. Ten-fold cross-validation is used to evaluate whether the joint training scheme significantly improves the performance task of classifying pure and transitional imagery signals from background EEG. Using sparse of just a few electrode channels (Cz, C3 and C4), mean accuracy reaches 71.52% and 70.27% for CNN-FC and CSP-SVM, respectively. On the other hand, mean accuracy without the joint training scheme achieve only 62.68% and 52.41% for CNN-FC and CSP-SVM, respectively.

## 220. A zero-shot learning approach to the development of brain-computer interfaces for image retrieval

**Authors:** Benjamin McCartney, Jesus Martinez-del-Rincon, Barry Devereux, B. Murphy (2019)
**DOI/URL:** 10.1371/journal.pone.0214342

Brain decoding—the process of inferring a person’s momentary cognitive state from their brain activity—has enormous potential in the field of human-computer interaction. In this study we propose a zero-shot EEG-to-image brain decoding approach which makes use of state-of-the-art EEG preprocessing and feature selection methods, and which maps EEG activity to biologically inspired computer vision and linguistic models. We apply this approach to solve the problem of identifying viewed images from recorded brain activity in a reliable and scalable way. We demonstrate competitive decoding accuracies across two EEG datasets, using a zero-shot learning framework more applicable to real-world image retrieval than traditional classification techniques.

## 221. Transfer Learning: Rotation Alignment With Riemannian Mean for Brain–Computer Interfaces and Wheelchair Control

**Authors:** Xianlun Tang, Xingchen Li, Wei Li, Bohui Hao, Yingke Xie, Xiaoyuan Dang (2021)
**DOI/URL:** 10.1109/TCDS.2021.3082648

The cross-session and cross-subject classification of motor imagery (MI) electroencephalogram (EEG) signals is challenging. This article presents a transfer learning (TL) method to address the cross-session and cross-subject classification of MI EEG signals, a tricky procedure in brain–computer interface (BCI). Method: We propose a rotation alignment domain adaptation method with Riemannian mean (RMRA). The method uses covariance matrix to represent data feature, and achieves data alignment by rotating the symmetric positive-definite (SPD) matrix in Riemannian space. In this process, our proposed matrix-TCA extends the traditional transfer component analysis (TCA) to a matrix form in order to function in the Riemannian framework. Data labels are not required, so the proposed method is unsupervised. In addition, we simplify the calculation process through Riemannian mean. Results: We have performed both offline and online experiments on multiple MI EEG data sets. Our results show that RMRA improves the cross-session and cross-subject classification accuracy. Conclusion and Significance: This article presents a new approach to cross-domain learning, which achieves desirable results and shows great promise in real-life application of the service robot (intelligent wheelchair).

## 222. A data driven Information theoretic feature extraction in EEG-based Motor Imagery BCI

**Authors:** Ji-Hack Lee, Young-Seok Choi (2019)
**DOI/URL:** 10.1109/ictc46691.2019.8939945

Motor Imagery (MI) is the most popular Brain-Computer Interface (BCI) model which aimed at analyzing and classifying the electroencephalogram (EEG) measured without direct human’s motor movements. The EEG recording is measured on the scalp noninvasively, which has nonstationarity and nonlinearity. To tackle the obstacle for analyzing the EEG obtained during MI tasks, we propose a novel feature extraction method by combining the Hilbert-Huang Transform (HHT) and the dispersion entropy (DisEn). Here, we develop the multivariate HHT using intrinsic mode functions (IMFs) obtained through multivariate empirical mode decomposition (MEMD) instead of HHT using existing EMD. By comparing the classification performance with other traditional methods, we validate the improved capacity of the proposed method, which shows its usefulness in MI BCI model.

## 223. A Review of the Role of Machine Learning Techniques towards Brain-Computer Interface Applications

**Authors:** Saim Rasheed (2021)
**DOI/URL:** 10.3390/make3040042

This review article provides a deep insight into the Brain–Computer Interface (BCI) and the application of Machine Learning (ML) technology in BCIs. It investigates the various types of research undertaken in this realm and discusses the role played by ML in performing different BCI tasks. It also reviews the ML methods used for mental state detection, mental task categorization, emotion classification, electroencephalogram (EEG) signal classification, event-related potential (ERP) signal classification, motor imagery categorization, and limb movement classification. This work explores the various methods employed in BCI mechanisms for feature extraction, selection, and classification and provides a comparative study of reviewed methods. This paper assists the readers to gain information regarding the developments made in BCI and ML domains and future improvements needed for improving and designing better BCI applications.

## 224. Feature Extraction of EEG Signal by Power Spectral Density for Motor Imagery Based BCI

**Authors:** Mohammad Nur Alam, M. Ibrahimy, S. Motakabber (2021)
**DOI/URL:** 10.1109/ICCCE50029.2021.9467141

Signals produced from the brain are widely known as Electroencephalogram (EEG) signal interfacing with any communication device creates a unidirectional communicating channel in the absence of neuro-muscular pathways. An effective Brain-Computer Interface (BCI) system basically consists of three operations which are signal recording, feature extraction and classification. Efficient and reliable classification of EEG signal for motor imagery (MI) based BCI system depends on the accuracy of denoising and extracted features of the signal. Extracted features are intended to be lossless key information obtained from a signal that describes a dataset accurately. It is important to minimize the classification complexity and maximize the accuracy. Traditional strategies can be used to process the signal, but the diverseness of the EEG signal conceivably could not be depicted utilizing a linear analytical approach. Hence, this paper adopted the power spectral density (PSD) feature extraction technique to extract the features based on various frequency transformations that enhance the classification performance. Graz BCI competition IV, dataset 2b has been utilized in this paper that consisting of two different classes of motor imagery left-hand and right-hand movement. Overall, 0.61 of Cohen’s Kappa accuracy obtained using the LDA classifier.

## 225. Motor-Imagery-Based Brain–Computer Interface Using Signal Derivation and Aggregation Functions

**Authors:** J. Fumanal-Idocin, Yu-kai Wang, Chin-Teng Lin, Javier Fern'andez, J. Sanz, H. Bustince (2021)
**DOI/URL:** 10.1109/TCYB.2021.3073210

Brain–computer interface (BCI) technologies are popular methods of communication between the human brain and external devices. One of the most popular approaches to BCI is motor imagery (MI). In BCI applications, the electroencephalography (EEG) is a very popular measurement for brain dynamics because of its noninvasive nature. Although there is a high interest in the BCI topic, the performance of existing systems is still far from ideal, due to the difficulty of performing pattern recognition tasks in EEG signals. This difficulty lies in the selection of the correct EEG channels, the signal-to-noise ratio of these signals, and how to discern the redundant information among them. BCI systems are composed of a wide range of components that perform signal preprocessing, feature extraction, and decision making. In this article, we define a new BCI framework, called enhanced fusion framework, where we propose three different ideas to improve the existing MI-based BCI frameworks. First, we include an additional preprocessing step of the signal: a differentiation of the EEG signal that makes it time invariant. Second, we add an additional frequency band as a feature for the system: the sensorimotor rhythm band, and we show its effect on the performance of the system. Finally, we make a profound study of how to make the final decision in the system. We propose the usage of both up to six types of different classifiers and a wide range of aggregation functions (including classical aggregations, Choquet and Sugeno integrals, and their extensions and overlap functions) to fuse the information given by the considered classifiers. We have tested this new system on a dataset of 20 volunteers performing MI-based brain–computer interface experiments. On this dataset, the new system achieved 88.80% accuracy. We also propose an optimized version of our system that is able to obtain up to 90.76%. Furthermore, we find that the pair Choquet/Sugeno integrals and overlap functions are the ones providing the best results.

## 226. The effects of layer-wise relevance propagation-based feature selection for EEG classification: a comparative study on multiple datasets

**Authors:** Hye-Young Nam, Jun-Mo Kim, Woohyeok Choi, Soyeon Bak, Tae-Eui Kam (2023)
**DOI/URL:** 10.3389/fnhum.2023.1205881

Introduction The brain-computer interface (BCI) allows individuals to control external devices using their neural signals. One popular BCI paradigm is motor imagery (MI), which involves imagining movements to induce neural signals that can be decoded to control devices according to the user's intention. Electroencephalography (EEG) is frequently used for acquiring neural signals from the brain in the fields of MI-BCI due to its non-invasiveness and high temporal resolution. However, EEG signals can be affected by noise and artifacts, and patterns of EEG signals vary across different subjects. Therefore, selecting the most informative features is one of the essential processes to enhance classification performance in MI-BCI. Methods In this study, we design a layer-wise relevance propagation (LRP)-based feature selection method which can be easily integrated into deep learning (DL)-based models. We assess its effectiveness for reliable class-discriminative EEG feature selection on two different publicly available EEG datasets with various DL-based backbone models in the subject-dependent scenario. Results and discussion The results show that LRP-based feature selection enhances the performance for MI classification on both datasets for all DL-based backbone models. Based on our analysis, we believe that it can broad its capability to different research domains.

## 227. DTP-Net: Learning to Reconstruct EEG Signals in Time-Frequency Domain by Multi-Scale Feature Reuse

**Authors:** Yan Pei, Jiahui Xu, Qianhao Chen, Chenhao Wang, Feng Yu, Lisan Zhang, Wei Luo (2023)
**DOI/URL:** 10.1109/JBHI.2024.3358917

Electroencephalography (EEG) signals are prone to contamination by noise, such as ocular and muscle artifacts. Minimizing these artifacts is crucial for EEG-based downstream applications like disease diagnosis and brain-computer interface (BCI). This paper presents a new EEG denoising model, DTP-Net. It is a fully convolutional neural network comprising Densely-connected Temporal Pyramids (DTPs) placed between two learnable time-frequency transformations. In the time-frequency domain, DTPs facilitate efficient propagation of multi-scale features extracted from EEG signals of any length, leading to effective noise reduction. Comprehensive experiments on two public semi-simulated datasets demonstrate that the proposed DTP-Net consistently outperforms existing state-of-the-art methods on metrics including relative root mean square error (RRMSE) and signal-to-noise ratio improvement ($\Delta$SNR). Moreover, the proposed DTP-Net is applied to a BCI classification task, yielding an improvement of up to 5.55% in accuracy. This confirms the potential of DTP-Net for applications in the fields of EEG-based neuroscience and neuro-engineering. An in-depth analysis further illustrates the representation learning behavior of each module in DTP-Net, demonstrating its robustness and reliability.

## 228. EEG-based finger movement classification with intrinsic time-scale decomposition

**Authors:** Murside Degirmenci, Yilmaz Kemal Yuce, M. Perc, Yalçin Isler (2024)
**DOI/URL:** 10.3389/fnhum.2024.1362135

Introduction Brain-computer interfaces (BCIs) are systems that acquire the brain's electrical activity and provide control of external devices. Since electroencephalography (EEG) is the simplest non-invasive method to capture the brain's electrical activity, EEG-based BCIs are very popular designs. Aside from classifying the extremity movements, recent BCI studies have focused on the accurate coding of the finger movements on the same hand through their classification by employing machine learning techniques. State-of-the-art studies were interested in coding five finger movements by neglecting the brain's idle case (i.e., the state that brain is not performing any mental tasks). This may easily cause more false positives and degrade the classification performances dramatically, thus, the performance of BCIs. This study aims to propose a more realistic system to decode the movements of five fingers and the no mental task (NoMT) case from EEG signals. Methods In this study, a novel praxis for feature extraction is utilized. Using Proper Rotational Components (PRCs) computed through Intrinsic Time Scale Decomposition (ITD), which has been successfully applied in different biomedical signals recently, features for classification are extracted. Subsequently, these features were applied to the inputs of well-known classifiers and their different implementations to discriminate between these six classes. The highest classifier performances obtained in both subject-independent and subject-dependent cases were reported. In addition, the ANOVA-based feature selection was examined to determine whether statistically significant features have an impact on the classifier performances or not. Results As a result, the Ensemble Learning classifier achieved the highest accuracy of 55.0% among the tested classifiers, and ANOVA-based feature selection increases the performance of classifiers on five-finger movement determination in EEG-based BCI systems. Discussion When compared with similar studies, proposed praxis achieved a modest yet significant improvement in classification performance although the number of classes was incremented by one (i.e., NoMT).

## 229. Brain Neuroplasticity Leveraging Virtual Reality and Brain–Computer Interface Technologies

**Authors:** Athanasios Drigas, Angeliki Sideraki (2024)
**DOI/URL:** 10.3390/s24175725

This study explores neuroplasticity through the use of virtual reality (VR) and brain–computer interfaces (BCIs). Neuroplasticity is the brain’s ability to reorganize itself by forming new neural connections in response to learning, experience, and injury. VR offers a controlled environment to manipulate sensory inputs, while BCIs facilitate real-time monitoring and modulation of neural activity. By combining VR and BCI, researchers can stimulate specific brain regions, trigger neurochemical changes, and influence cognitive functions such as memory, perception, and motor skills. Key findings indicate that VR and BCI interventions are promising for rehabilitation therapies, treatment of phobias and anxiety disorders, and cognitive enhancement. Personalized VR experiences, adapted based on BCI feedback, enhance the efficacy of these interventions. This study underscores the potential for integrating VR and BCI technologies to understand and harness neuroplasticity for cognitive and therapeutic applications. The researchers utilized the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) method to conduct a comprehensive and systematic review of the existing literature on neuroplasticity, VR, and BCI. This involved identifying relevant studies through database searches, screening for eligibility, and assessing the quality of the included studies. Data extraction focused on the effects of VR and BCI on neuroplasticity and cognitive functions. The PRISMA method ensured a rigorous and transparent approach to synthesizing evidence, allowing the researchers to draw robust conclusions about the potential of VR and BCI technologies in promoting neuroplasticity and cognitive enhancement.

## 230. Subject-Independent Brain–Computer Interfaces Based on Deep Convolutional Neural Networks

**Authors:** O-Yeon Kwon, Min-Ho Lee, Cuntai Guan, Seong-Whan Lee (2019)
**DOI/URL:** 10.1109/TNNLS.2019.2946869

For a brain–computer interface (BCI) system, a calibration procedure is required for each individual user before he/she can use the BCI. This procedure requires approximately 20–30 min to collect enough data to build a reliable decoder. It is, therefore, an interesting topic to build a calibration-free, or subject-independent, BCI. In this article, we construct a large motor imagery (MI)-based electroencephalography (EEG) database and propose a subject-independent framework based on deep convolutional neural networks (CNNs). The database is composed of 54 subjects performing the left- and right-hand MI on two different days, resulting in 21 600 trials for the MI task. In our framework, we formulated the discriminative feature representation as a combination of the spectral–spatial input embedding the diversity of the EEG signals, as well as a feature representation learned from the CNN through a fusion technique that integrates a variety of discriminative brain signal patterns. To generate spectral–spatial inputs, we first consider the discriminative frequency bands in an information-theoretic observation model that measures the power of the features in two classes. From discriminative frequency bands, spectral–spatial inputs that include the unique characteristics of brain signal patterns are generated and then transformed into a covariance matrix as the input to the CNN. In the process of feature representations, spectral–spatial inputs are individually trained through the CNN and then combined by a concatenation fusion technique. In this article, we demonstrate that the classification accuracy of our subject-independent (or calibration-free) model outperforms that of subject-dependent models using various methods [common spatial pattern (CSP), common spatiospectral pattern (CSSP), filter bank CSP (FBCSP), and Bayesian spatio-spectral filter optimization (BSSFO)].

## 231. Electroencephalogram-Based Satisfaction Assessment Brain-Computer Interface in Emerging Video Service by Using Graph Representation Learning.

**Authors:** Yifan Niu, Ziyu Li, Gangyan Zeng, Yuan Zhang, Li Yao, Xia Wu (2025)
**DOI/URL:** 10.1177/21580014251359107

Background: Emerging video services (EVS) offer users various multimedia presentations, and satisfaction assessment is crucial for enhancing their user experience and competitiveness. However, existing research methods are unable to provide a quantitative satisfaction assessment. Electroencephalogram (EEG), as a popular signal source in brain-computer interface (BCI), with the advantage of being difficult to disguise and containing rich brain activity information, has gained increasing attention from researchers. This article aims to investigate the advantages of employing EEG for modeling satisfaction in EVS. Unlike the subjective metrics assessment in traditional video services, generating satisfaction in EVS involves a range of cognitive functions, including cognitive load, emotion, and audiovisual perception, which are difficult to characterize using a single feature. The representation of brain states for complex cognitive functions has been a major challenge for EEG modeling approaches. Methods: To address this challenge, we propose an EEG-based EVS satisfaction assessment BCI by raising a Point-to-Global graph representation learning strategy (P2G) that efficiently identifies satisfaction level through a parallel coding module and a graph-based brain region perception module. P2G captures satisfaction-sensitive graph representations in EEG samples based on coding and integrating point features and the global topography. Results: We validate the effectiveness of introducing a P2G learning strategy in EVS satisfaction modeling using a self-constructed dataset and a relevant public dataset, and our method outperforms existing methods. Additionally, we provide a detailed visual analysis to unveil neural markers associated with EVS satisfaction, thereby laying a scientific foundation for the optimization and development of video services.

## 232. Enhancing EEG Signals in Brain Computer Interface Using Intrinsic Time-Scale Decomposition

**Authors:** Eltaf Abdalsalam Mohamed, M. Zuki Yusoff, Ibrahim Khalil Adam, Elnazeer Ali Hamid, Fares Al-Shargie, M. Muzammel (2018)
**DOI/URL:** 10.1088/1742-6596/1123/1/012004

A brain–computer interface (BCI) provides a link between the human brain and a computer. The EEG signal is nonlinear and non-stationary. Feature extraction is one of the most important steps in any BCI system; as such, enhancement to the existing methods has been incorporated in this work. For this, we propose a four-class movement imaginations of the right hand, left hand, both hands, and both feet, and develop feature extraction methods utilizing an intelligent method based on intrinsic time-scale decomposition (ITD) and Artificial neural networks (ANN). Based on the processed electroencephalography (EEG) data recorded from nine subjects, ITD accurately classified and discriminated the four classes of motor imagery; the average accuracy achieved is 92.20%.

## 233. The Improved ELM Algorithms Optimized by Bionic WOA for EEG Classification of Brain Computer Interface

**Authors:** Zhaoyang Lian, Lijuan Duan, Yuanhua Qiao, Juncheng Chen, Jun Miao, Ming-ai Li (2021)
**DOI/URL:** 10.1109/ACCESS.2021.3076347

The breakthrough of electroencephalogram (EEG) signal classification of brain computer interface (BCI) will set off another technological revolution of human computer interaction technology. Because the collected EEG is a type of nonstationary signal with strong randomness, effective feature extraction and data mining techniques are urgently required for EEG classification of BCI. In this paper, the new bionic whale optimization algorithms (WOA) are proposed to promote the improved extreme learning machine (ELM) algorithms for EEG classification of BCI. Two improved WOA-ELM algorithms are designed to compensate for the deficiency of random weight initialization for basic ELM. Firstly, the top several best individuals are selected and voted to make decisions to avoid misjudgment on the best individual. Secondly, the initial connection weights and bias between the input layer nodes and hidden layer nodes are optimized by WOA through bubble-net attacking strategy (BNAS) and shrinking encircling mechanism (SEM), and different regularization mechanisms are introduced in different layers to generate appropriate sparse weight matrix to promote the generalization performance of the algorithm.As shown in the contrast results, the average accuracy of the proposed method can reach 93.67%, which is better than other methods on BCI dataset.

## 234. Weak Feature Extraction and Strong Noise Suppression for SSVEP-EEG Based on Chaotic Detection Technology

**Authors:** Kai Zhang, Guanghua Xu, Chenghang Du, Yongcheng Wu, Xiaowei Zheng, Sicong Zhang, Chengcheng Han, Renhao Liang, Ruiquan Chen (2021)
**DOI/URL:** 10.1109/TNSRE.2021.3073918

Brain computer interface (BCI) is a novel communication method that does not rely on the normal neural pathway between the brain and muscle of human. It can transform mental activities into relevant commands to control external equipment and establish direct communication pathway. Among different paradigms, steady-state visual evoked potential (SSVEP) is widely used due to its certain periodicity and stability of control. However, electroencephalogram (EEG) of SSVEP is extremely weak and companied with multi-scale and strong noise. Existing algorithms for classification are based on the principle of template matching and spatial filtering, which cannot obtain satisfied performance of feature extraction under the multi-scale noise. Especially for the subjects produce weak response for external stimuli in EEG representation, i.e., BCI-Illiteracy subject, traditional algorithms are difficult to recognize the internal patterns of brain. To address this issue, a novel method based on Chaos theory is proposed to extract feature of SSVEP. The rule of this method is applying the peculiarity of nonlinear dynamics system to detect feature of SSVEP by judging the state changes of chaotic systems after adding weak EEG. To evaluate the validity of proposed method, this research recruit 32 subjects to participate the experiment. All subjects are divided into two groups according to the preliminary classification accuracy (mean acc >70% or < 70%) by canonical correlation analysis and we define the accuracy above 70% as group A (normal subjects), below 70% as group B (BCI-Illiteracy). Then, the classification accuracy and information transmission rate of two groups are verified using Chaotic theory. Experimental results show that all classification methods using in our study achieve good performance for normal subjects while chaos obtain excellent performance and significant improvements than traditional methods for BCI-Illiteracy.

## 235. A Parallel Algorithm Framework for Feature Extraction of EEG Signals on MPI

**Authors:** Q. Xiong, Xinman Zhang, Wenfeng Wang, Yuhong Gu (2020)
**DOI/URL:** 10.1155/2020/9812019

In this paper, we present a parallel framework based on MPI for a large dataset to extract power spectrum features of EEG signals so as to improve the speed of brain signal processing. At present, the Welch method has been wildly used to estimate the power spectrum. However, the traditional Welch method takes a lot of time especially for the large dataset. In view of this, we added the MPI into the traditional Welch method and developed it into a reusable master-slave parallel framework. As long as the EEG data of any format are converted into the text file of a specified format, the power spectrum features can be extracted quickly by this parallel framework. In the proposed parallel framework, the EEG signals recorded by a channel are divided into N overlapping data segments. Then, the PSD of N segments are computed by some nodes in parallel. The results are collected and summarized by the master node. The final PSD results of each channel are saved in the text file, which can be read and analyzed by Microsoft Excel. This framework can be implemented not only on the clusters but also on the desktop computer. In the experiment, we deploy this framework on a desktop computer with a 4-core Intel CPU. It took only a few minutes to extract the power spectrum features from the 2.85 GB EEG dataset, seven times faster than using Python. This framework makes it easy for users, who do not have any parallel programming experience in constructing the parallel algorithms to extract the EEG power spectrum.

## 236. Exploration of Pattern Recognition Methods for Motor Imagery EEG Signal with Convolutional Neural Network Approach

**Authors:** H. N. Zahra, H. Zakaria, B. R. Hermanto (2022)
**DOI/URL:** 10.1088/1742-6596/2312/1/012064

As an application of EEG, Motor Imagery based Brain-Computer Interface (MI BCI) plays a significant role in assisting patients with disability to communicate with their environment. MI BCI could now be realized through various methods such as machine learning. Many attempts using different machine learning approaches as MI BCI applications have been done with every one of them yielding various results. While some attempts managed to achieve agreeable results, some still failed. This failure may be caused by the separation of the feature extraction and classification steps, as this may lead to the loss of information which in turn causes lower classification accuracy. This problem can be solved by integrating feature extraction and classification by harnessing a classification algorithm that processed the input data as a whole until it produces the prediction, hence the use of convolutional neural network (CNN) approach which is known for its versatility in processing and classifying data all in one go. In this study, the CNN exploration involved a task to classify 5 different classes of fingers’ imaginary movement (thumb, index, middle, ring, and pinky) based on the processed raw signal provided. The CNN performance was observed for both non-augmented and augmented data with the data augmentation techniques used include sliding window, noise addition, and the combination of those two methods. From these experiments, the results show that the CNN model managed to achieve an averaged accuracy of 47%, meanwhile with the help of augmentation techniques of sliding window, noise addition, and the combined methods, the model achieved even higher averaged accuracy of 57,1%, 47,2%, and 57,5% respectively.

## 237. Research on Decoding EEG Signals Based on Grey Wolf Optimization Algorithm for Multi-Feature Fusion

**Authors:** Yujing Guo, Pengfei Ma (2025)
**DOI/URL:** 10.1145/3727648.3727818

Due to the high-dimensional, unstable, and noise-sensitive features in EEG signals, traditional methods of single-feature extraction cannot fully represent and utilize the complete information of EEG signals. Therefore, this provides many challenges in signal processing and feature extraction. Thus, effective decoding of EEG signals and extracting representative features has always been a very critical and challenging issue in the field of EEG research. This paper proposes a new EEG decoding algorithm called DACG, which represents DWT+AR+CSP+GWO and involves multi-feature fusion with the Grey Wolf Optimization algorithm. With the integration of multiple features, the GWO algorithm performs feature selection, allowing more representative EEG features to be integrated into the classification model, thus solving the problems of single-feature representation and low classification accuracy found in traditional decoding algorithms. The BCIC IV 2a dataset is employed for feature selection in binary classification for left and right-hand movements. This selects the frequency domain wavelet coefficients, time domain Auto Regressive (AR) model coefficients, and spatial domain features from the Common Spatial Pattern (CSP). Compared with the traditional methods of Discrete Wavelet Transform (DWT), AR, and CSP, respectively, the accuracy of the DACG decoding algorithm was 96.2%, with an increase of 31.55%, 29.64%, and 8.99%, respectively, and the increase compared with the DAC(DWT+AR+CSP) is 7.83%. The great promotion offers a vital basis for developing Brain-Computer Interface (BCI) technology.

## 238. Fractal Based Feature Extraction Method for Epileptic Seizure Detection in Long-Term EEG Recording

**Authors:** A. Humairani, B. S. Atmojo, I. Wijayanto, S. Hadiyoso (2021)
**DOI/URL:** 10.1088/1742-6596/1844/1/012019

One of the most common brain disorders is epilepsy. A person who has epilepsy is not able to have normal days like the others. It’s characterized by more than two unprovoked seizures. However, the faster detection and treatment of epileptic seizures, the quicker reduction of the disease abnormal level. Neurologists are still diagnosing, detecting, and testing a seizure manually by observing the Electroencephalogram (EEG) signals. This takes a very long time because of the irregularity of EEG signals. Hence, a Computer-Aided Diagnosis (CAD) is developed by many scientists to help neurologists in detecting seizures automatically. In this research, a CAD system was developed at CHB-MIT dataset. The EEG signals were processed at several stages through this system, namely pre-processing, decomposition, feature extraction, and classification. In pre-processing, the EEG signals were uniformed by selecting the most appropriate channels and filtered using Butterworth Bandpass Filter (BPF) to remove noise. The process continued to the decomposition and feature extraction stage using Empirical Mode Decomposition (EMD) and fractal dimension-based methods, i.e. Higuchi, Katz, and Sevcik, respectively. Then, the features were classified by Support Vector Machine (SVM). The proposed method achieved the highest accuracy at 94.72% on the Chb07 record. Meanwhile, the average accuracy was 81.2% for all records. The proposed study is expected to be applied for the detection of seizure onset in a real-time system.

## 239. Motor Imagery EEG Classification Based on Multi-Domain Feature Rotation and Stacking Ensemble

**Authors:** Xianglong Zhu, Ming Meng, Zewen Yan, Zhizeng Luo (2025)
**DOI/URL:** 10.3390/brainsci15010050

Background: Decoding motor intentions from electroencephalogram (EEG) signals is a critical component of motor imagery-based brain–computer interface (MI–BCIs). In traditional EEG signal classification, effectively utilizing the valuable information contained within the electroencephalogram is crucial. Objectives: To further optimize the use of information from various domains, we propose a novel framework based on multi-domain feature rotation transformation and stacking ensemble for classifying MI tasks. Methods: Initially, we extract the features of Time Domain, Frequency domain, Time-Frequency domain, and Spatial Domain from the EEG signals, and perform feature selection for each domain to identify significant features that possess strong discriminative capacity. Subsequently, local rotation transformations are applied to the significant feature set to generate a rotated feature set, enhancing the representational capacity of the features. Next, the rotated features were fused with the original significant features from each domain to obtain composite features for each domain. Finally, we employ a stacking ensemble approach, where the prediction results of base classifiers corresponding to different domain features and the set of significant features undergo linear discriminant analysis for dimensionality reduction, yielding discriminative feature integration as input for the meta-classifier for classification. Results: The proposed method achieves average classification accuracies of 92.92%, 89.13%, and 86.26% on the BCI Competition III Dataset IVa, BCI Competition IV Dataset I, and BCI Competition IV Dataset 2a, respectively. Conclusions: Experimental results show that the method proposed in this paper outperforms several existing MI classification methods, such as the Common Time-Frequency-Spatial Patterns and the Selective Extract of the Multi-View Time-Frequency Decomposed Spatial, in terms of classification accuracy and robustness.

## 240. Evaluation of Different Signal Processing Methods in Time and Frequency Domain for Brain-Computer Interface Applications

**Authors:** J. Arnin, D. Kahani, H. Lakany, B. Conway (2018)
**DOI/URL:** 10.1109/EMBC.2018.8512193

Brain-computer interface (BCI) has been widely introduced in many medical applications. One of the main challenges in BCI is to run the signal processing algorithms in real-time which is challenging and usually comes with high processing unit costs. BCIs based on motor imagery task are introduced for severe neurological diseases especially locked-in patients. A common concept is to detect one’s movement intention and use it to control external devices such as wheelchair or rehabilitation devices. In real-time BCI, running the signal processing algorithms might not always be possible due to the complexity of the algorithms. Moreover, the speed of the affordable computational units is not usually enough for those applications. This study evaluated a range of feature extraction methods which are commonly used for such real-time BCI applications. Electroencephalogram (EEG) and Electrooculogram (EOG) data available through IEEE Brain Initiative repository was used to investigate the performance of different feature extraction methods including template matching, statistical moments, selective bandpower, and fast Fourier transform (FFT) power spectrum. The support vector machine (SVM) was used for classification. The result indicates that there is not a significant difference when utilizing different feature extraction methods in terms of movement prediction although there is a vast difference in the computational time needed to extract these features. The results suggest that computational time could be considered as the primary parameter when choosing the feature extraction methods as there is no significant difference between the results when different features extraction methods are used.

## 241. Investigating Feature Selection Techniques to Enhance the Performance of EEG-Based Motor Imagery Tasks Classification

**Authors:** Md. Humaun Kabir, Shabbir Mahmood, Abdullah Al Shiam, Abu Saleh Musa Miah, Jungpil Shin, M. I. Molla (2023)
**DOI/URL:** 10.3390/math11081921

Analyzing electroencephalography (EEG) signals with machine learning approaches has become an attractive research domain for linking the brain to the outside world to establish communication in the name of the Brain-Computer Interface (BCI). Many researchers have been working on developing successful motor imagery (MI)-based BCI systems. However, they still face challenges in producing better performance with them because of the irrelevant features and high computational complexity. Selecting discriminative and relevant features to overcome the existing issues is crucial. In our proposed work, different feature selection algorithms have been studied to reduce the dimension of multiband feature space to improve MI task classification performance. In the procedure, we first decomposed the MI-based EEG signal into four sets of the narrowband signal. Then a common spatial pattern (CSP) approach was employed for each narrowband to extract and combine effective features, producing a high-dimensional feature vector. Three feature selection approaches, named correlation-based feature selection (CFS), minimum redundancy and maximum relevance (mRMR), and multi-subspace randomization and collaboration-based unsupervised feature selection (SRCFS), were used in this study to select the relevant and effective features for improving classification accuracy. Among them, the SRCFS feature selection approach demonstrated outstanding performance for MI classification compared to other schemes. The SRCFS is based on the multiple k-nearest neighbour graphs method for learning feature weight based on the Laplacian score and then discarding the irrelevant features based on the weight value, reducing the feature dimension. Finally, the selected features are fed into the support vector machines (SVM), linear discriminative analysis (LDA), and multi-layer perceptron (MLP) for classification. The proposed model is evaluated with two benchmark datasets, namely BCI Competition III dataset IVA and dataset IIIB, which are publicly available and mainly used to recognize the MI tasks. The LDA classifier with the SRCFS feature selection algorithm exhibits better performance. It proves the superiority of our proposed study compared to the other state-of-the-art BCI-based MI task classification systems.

## 242. A Brief Review on EEG Signal Pre-processing Techniques for Real-Time Brain-Computer Interface Applications

**Authors:** B. Venkata Phanikrishna, Pawel Plawiak, Allam Jaya Prakash (2021)
**DOI/URL:** 10.36227/techrxiv.16691605.v1

Electro Encephalo Gram (EEG) is a monitoring method used in biomedical and computer science to understand brain activity. Therefore, the analysis and classification of these signals play a prominent role in estimating a person’s behavior to certain events. Manually analyzing these signals is very tedious and time-consuming, so an automated scientific tool is required to analyze the brain signals. In this work, the authors are explored various pre-processing segmentation techniques that are helpful in an automatic machine and deep learning-based classification methods available for EEG signal processing. Most of the machine and deep learning methods are followed pre-processing as a common step in classification. Extraction of the basic sub-band components from EEG signals such as delta (δ), theta (θ), alpha (α), beta (β), and gamma (γ) is very important in the pre-processing stage. These sub bands of EEG signal have extraordinary evidence related to multiple neurophysiological processes, which are useful for further prediction & diagnosis of diseases and other emotion-based applications. This review paper elaborates various elementary ideas of extracting EEG sub-bands and the role of EEG in Brain-Computer Interface (BCI) in the classification.  (Submitted To IEEE reviews in Biomedical Engineering)

## 243. Wavelet Transform Based Feature Extraction for EEG Signal Classification

**Authors:** S. Postalcıoğlu (2021)
**DOI/URL:** 10.37394/23205.2021.20.21

This study focused on the classification of EEG signal. The study aims to make a classification with fast response and high-performance rate. Thus, it could be possible for real-time control applications as Brain-Computer Interface (BCI) systems. The feature vector is created by Wavelet transform and statistical calculations. It is trained and tested with a neural network. The db4 wavelet is used in the study. Pwelch, skewness, kurtosis, band power, median, standard deviation, min, max, energy, entropy are used to make the wavelet coefficients meaningful. The performance is achieved as 99.414% with the running time of 0.0209 seconds

## 244. EEG Classification-based Comparison Study of Motor-Imagery Brain-Computer Interface

**Authors:** Kheira Djelloul, Abdelkader Nasreddine Belkacem (2021)
**DOI/URL:** 10.1109/ICRAMI52622.2021.9585902

For developing brain computer interface (BCI) applications, electroencephalography (EEG) is the most widely used measurement method due to its noninvasiveness, high temporal resolution, and portability. EEG signal contains sufficient neural information about each human task, which makes the extracting, and decoding of each task-related information is still challenging, especially to improve the existing BCI performances. In this paper, we present a comparison analysis to find the most relevant features and the most suitable classification method for decoding motor imagery for EEG-based BCI. Therefore, some signal processing and machine learning techniques have applied for features extraction and classification phases. For the decomposition of EEG signal, we used three type of features [EEG signal mean, root mean square (RMS) and Relative of band power (RBP)]. In addition, we investigated an analytical comparison between three methods of classification [Support Vector Machine (SVM), Linear Discriminant Analysis and K-Nearest Neighbors]. The methods were validated using a publicly available dataset (BCI Competition IV-III-a) to discriminate between two mental states (right and left hand movements) using 10-fold cross-validation. SVM method gave better classification accuracy of 76.4% using relative band powers as potential EEG features.

## 245. A Survey of EEG and Machine Learning-Based Methods for Neural Rehabilitation

**Authors:** Jaiteg Singh, F. Ali, Rupali Gill, Babar Shah, Daehan Kwak (2023)
**DOI/URL:** 10.1109/ACCESS.2023.3321067

One approach to therapy and training for the restoration of damaged muscles and motor systems is rehabilitation. EEG-assisted Brain-Computer Interface (BCI) may assist in restoring or enhancing ‘lost motor abilities in the brain. Assisted by brain activity, BCI offers simple-to-use technology aids and robotic prosthetics. This systematic literature review aims to explore the latest developments in BCI and motor control for rehabilitation. Additionally, we have explored typical EEG apparatuses that are available for BCI-driven rehabilitative purposes. Furthermore, a comparison of significant studies in rehabilitation assessment using machine learning techniques has been summarized. The results of this study may influence policymakers’ decisions regarding the use of EEG equipment, particularly wireless devices, to implement BCI technology. Moreover, the literature review results offer suggestions for further study and new research areas. We plan to identify the additional characteristics of each EEG equipment and determine which one is most suited for each industry by measuring the user experience based on various devices in future research.

## 246. Graph Neural Network with Multilevel Feature Fusion for EEG based Brain-Computer Interface

**Authors:** Youngchul Kwak, Woo‐Jin Song, Seong-Eun Kim (2020)
**DOI/URL:** 10.1109/ICCE-Asia49877.2020.9276983

The brain-computer interface (BCI) system provides information exchanges between neural signals containing the user’s intention and device control signals. In this paper, we propose a graph neural network (GNN) with a multilevel feature fusion structure for high-performance BCI systems. Since the proposed structure can exploit both local and global neural information, the decoding accuracy greatly increases. Experimental results show that the original GNN outperforms conventional algorithms. Furthermore, the proposed multilevel feature fusion method dramatically enhances the performance of conventional GNN algorithms.

## 247. Brain Topology Modeling With EEG-Graphs for Auditory Spatial Attention Detection

**Authors:** Siqi Cai, T. Schultz, Haizhou Li (2023)
**DOI/URL:** 10.1109/TBME.2023.3294242

Objective: Despite recent advances, the decoding of auditory attention from brain signals remains a challenge. A key solution is the extraction of discriminative features from high-dimensional data, such as multi-channel electroencephalography (EEG). However, to our knowledge, topological relationships between individual channels have not yet been considered in any study. In this work, we introduced a novel architecture that exploits the topology of the human brain to perform auditory spatial attention detection (ASAD) from EEG signals. Methods: We propose EEG-Graph Net, an EEG-graph convolutional network, which employs a neural attention mechanism. This mechanism models the topology of the human brain in terms of the spatial pattern of EEG signals as a graph. In the EEG-Graph, each EEG channel is represented by a node, while the relationship between two EEG channels is represented by an edge between the respective nodes. The convolutional network takes the multi-channel EEG signals as a time series of EEG-graphs and learns the node and edge weights from the contribution of the EEG signals to the ASAD task. The proposed architecture supports the interpretation of the experimental results by data visualization. Results: We conducted experiments on two publicly available databases. The experimental results showed that EEG-Graph Net significantly outperforms the state-of-the-art methods in terms of decoding performance. In addition, the analysis of the learned weight patterns provides insights into the processing of continuous speech in the brain and confirms findings from neuroscientific studies. Conclusion: We showed that modeling brain topology with EEG-graphs yields highly competitive results for auditory spatial attention detection. Significance: The proposed EEG-Graph Net is more lightweight and accurate than competing baselines and provides explanations for the results. Also, the architecture can be easily transferred to other brain-computer interface (BCI) tasks.

## 248. EEG Signals Feature Extraction Based on DWT and EMD Combined with Approximate Entropy

**Authors:** Na Ji, Liangdi Ma, Hui Dong, Xuejun Zhang (2019)
**DOI/URL:** 10.3390/brainsci9080201

The classification recognition rate of motor imagery is a key factor to improve the performance of brain–computer interface (BCI). Thus, we propose a feature extraction method based on discrete wavelet transform (DWT), empirical mode decomposition (EMD), and approximate entropy. Firstly, the electroencephalogram (EEG) signal is decomposed into a series of narrow band signals with DWT, then the sub-band signal is decomposed with EMD to get a set of stationary time series, which are called intrinsic mode functions (IMFs). Secondly, the appropriate IMFs for signal reconstruction are selected. Thus, the approximate entropy of the reconstructed signal can be obtained as the corresponding feature vector. Finally, support vector machine (SVM) is used to perform the classification. The proposed method solves the problem of wide frequency band coverage during EMD and further improves the classification accuracy of EEG signal motion imaging.

## 249. Determination of Effective Signal Processing Stages for Brain Computer Interface on BCI Competition IV Data Set 2b: A Review Study

**Authors:** Eda Dağdevir, M. Tokmakçi (2021)
**DOI/URL:** 10.1080/03772063.2021.1914204

Considering the entire BCI system, a big challenge is that information can be extracted from brain signals in a meaningful way. Therefore, most BCI studies are focused on brain signal processing, in which the stages are preprocessing, feature extraction, feature selection, and classification. Since each of the signal processing methods is subject-specific, it is necessary to select a specific subject group, that is, a data set, for an effective signal processing review. In this study, all stages of BCI signal processing studies that used the 2b data set recorded with the EEG method for the BCI Competition IV were compiled and compared comprehensively. To be an effective review, this paper organized into common components and showed how varying the four stages alter classification performance. Classification of performance obtained with the methods in the compiled studies was compared in terms of kappa values. The results demonstrate that combinations of different methods affect and improve the performance. This study presents comprehensive guidance by considering all stages for BCI Competition IV data set 2b. The purpose of the present study was to shed light on research with the aim to enhance BCI performance with signal processing using BCI Competition IV data set 2b.

## 250. EEG Based Mental Arithmetic Task Classification Using a Stacked Long Short Term Memory Network for Brain-Computer Interfacing

**Authors:** Biswarup Ganguly, Arpan Chatterjee, Waqar Mehdi, Soumyadip Sharma, S. Garai (2020)
**DOI/URL:** 10.1109/VLSIDCS47293.2020.9179949

This paper proposes an electroencephalogram (EEG) based mental arithmetic task classification using a stacked long short-term memory (LSTM) architecture for brain computer interfacing (BCI). EEG signals from 22 channels are taken from 36 subjects, as mentioned in the Physionet database. A deep learning framework based on LSTM is employed to identify and classify the mental arithmetic task by reducing the number of electrodes. Window segmentation is applied for data augmentation as well as feature extraction from all the recorded EEG signals. Eight features per electrode have been fed into the proposed LSTM architecture. The main aspect of this network along with the dropout layers is to enhance feature learning ability and to avoid over fitting.

# References

* A. Albahri, Z. Al-qaysi, Laith Alzubaidi, Alhamzah Alnoor, O. Albahri, A. Alamoodi, Anizah Abu Bakar (2023). *A Systematic Review of Using Deep Learning Technology in the Steady-State Visually Evoked Potential-Based Brain-Computer Interface Applications: Current Trends and Future Trust Methodology*. Retrieved from https://doi.org/10.1155/2023/7741735
* A. Humairani, B. S. Atmojo, I. Wijayanto, S. Hadiyoso (2021). *Fractal Based Feature Extraction Method for Epileptic Seizure Detection in Long-Term EEG Recording*. Retrieved from https://doi.org/10.1088/1742-6596/1844/1/012019
* A. Palumbo, V. Gramigna, B. Calabrese, N. Ielpo (2021). *Motor-Imagery EEG-Based BCIs in Wheelchair Movement and Control: A Systematic Literature Review*. Retrieved from https://doi.org/10.3390/s21186285
* A. Savić, Marija Novičić, Olivera Ðorđević, L. Konstantinović, Vera Miler-Jerković (2023). *Novel electrotactile brain-computer interface with somatosensory event-related potential based control*. Retrieved from https://doi.org/10.3389/fnhum.2023.1096814
* A. Subasi (2022). *Artificial Intelligence in Brain Computer Interface*. Retrieved from https://doi.org/10.1109/hora55278.2022.9800002
* A. Tayade, R. Khobragade (2022). *An Empirical Evaluation of Brain Computer Interface Models from a Pragmatic Perspective*. Retrieved from https://doi.org/10.1109/ICERECT56837.2022.10060641
* Abir Das, Saurabh Singh, Jaejeung Kim, T. Ahanger, A. Pise (2025). *Enhanced EEG signal classification in brain computer interfaces using hybrid deep learning models*. Retrieved from https://doi.org/10.1038/s41598-025-07427-2
* Ade Widyatama Dian Boernama, N. A. Setiawan, O. Wahyunggoro (2021). *Multiclass Classification of Brain-Computer Interface Motor Imagery System: A Systematic Literature Review*. Retrieved from https://doi.org/10.1109/AIMS52415.2021.9466056
* Adi Alhudhaif (2021). *An effective classification framework for brain-computer interface system design based on combining of fNIRS and EEG signals*. Retrieved from https://doi.org/10.7717/peerj-cs.537
* Aigerim Keutayeva, China Jesse Nwachukwu, Muslim Alaran, Zhenis Otarbay, B. Abibullaev (2025). *Neurotechnology in Gaming: A Systematic Review of Visual Evoked Potential-Based Brain-Computer Interfaces*. Retrieved from https://doi.org/10.1109/ACCESS.2025.3564328
* Alireza Pirasteh, Manouchehr Shamseini Ghiyasvand, Majid Pouladian (2024). *EEG-based brain-computer interface methods with the aim of rehabilitating advanced stage ALS patients*. Retrieved from https://doi.org/10.1080/17483107.2024.2316312
* Amin Besharat, N. Samadzadehaghdam, Reyhaneh Afghan (2024). *A Comparative Review of Detection Methods in SSVEP-Based Brain-Computer Interfaces*. Retrieved from https://doi.org/10.1109/ACCESS.2024.3509275
* Amr F. Mohamed, V. Jusas (2024). *Developing Innovative Feature Extraction Techniques from the Emotion Recognition Field on Motor Imagery Using Brain–Computer Interface EEG Signals*. Retrieved from https://doi.org/10.3390/app142311323
* Anand Mohan, R. S. Anand (2025). *Phase-Based EEG Analysis for Enhanced Imagined Speech Decoding in Brain-Computer Interfaces*. Retrieved from https://doi.org/10.1109/IC3ECSBHI63591.2025.10990955
* Anh Hoang Phuc Nguyen, Oluwabunmi Oyefisayo, Maximilian Achim Pfeffer, Sai-Ho Ling (2024). *EEG-TCNTransformer: A Temporal Convolutional Transformer for Motor Imagery Brain–Computer Interfaces*. Retrieved from https://doi.org/10.3390/signals5030034
* Anisha Roy (2022). *A CNN model with feature integration for MI EEG subject classification in BMI*. Retrieved from https://doi.org/10.1101/2022.01.05.475058
* Anup Singh, S. Krishnan (2023). *Trends in EEG signal feature extraction applications*. Retrieved from https://doi.org/10.3389/frai.2022.1072801
* Arpa Suwannarat, S. Pan-ngum, P. Israsena (2024). *Analysis of Minimal Channel Electroencephalography for Wearable Brain–Computer Interface*. Retrieved from https://doi.org/10.3390/electronics13030565
* Athanasios Drigas, Angeliki Sideraki (2024). *Brain Neuroplasticity Leveraging Virtual Reality and Brain–Computer Interface Technologies*. Retrieved from https://doi.org/10.3390/s24175725
* Ayman Altameem, Jaideep Singh Sachdev, Vijander Singh, Ramesh Chandra Poonia, Sandeep Kumar, Abdul Khader Jilani Saudagar (2022). *Performance Analysis of Machine Learning Algorithms for Classifying Hand Motion-Based EEG Brain Signals*. Retrieved from https://doi.org/10.32604/csse.2022.023256
* B. Abibullaev, A. Zollanvari (2021). *A Systematic Deep Learning Model Selection for P300-Based Brain–Computer Interfaces*. Retrieved from https://doi.org/10.1109/TSMC.2021.3051136
* B. Venkata Phanikrishna, Pawel Plawiak, Allam Jaya Prakash (2021). *A Brief Review on EEG Signal Pre-processing Techniques for Real-Time Brain-Computer Interface Applications*. Retrieved from https://doi.org/10.36227/techrxiv.16691605.v1
* Benjamin McCartney, Jesus Martinez-del-Rincon, Barry Devereux, B. Murphy (2019). *A zero-shot learning approach to the development of brain-computer interfaces for image retrieval*. Retrieved from https://doi.org/10.1371/journal.pone.0214342
* Biswarup Ganguly, Arpan Chatterjee, Waqar Mehdi, Soumyadip Sharma, S. Garai (2020). *EEG Based Mental Arithmetic Task Classification Using a Stacked Long Short Term Memory Network for Brain-Computer Interfacing*. Retrieved from https://doi.org/10.1109/VLSIDCS47293.2020.9179949
* Boxun Fu, Fu Li, Youshuo Ji, Yang Li, Xuemei Xie, Guangming Shi (2023). *SCDAN: Learning Common Feature Representation of Brain Activation for Intersubject Motor Imagery EEG Decoding*. Retrieved from https://doi.org/10.1109/TIM.2023.3284926
* Boyu Wang, C. Wong, Zhao Kang, Feng Liu, Changjian Shui, Feng Wan, C. L. P. Chen (2020). *Common Spatial Pattern Reformulated for Regularizations in Brain–Computer Interfaces*. Retrieved from https://doi.org/10.1109/tcyb.2020.2982901
* C. F. Blanco-Díaz, E. R. S. Serafini, T. Bastos-Filho, A. F. O. D. A. Dantas, C. D. E. Santo, D. Delisle-Rodríguez (2024). *A Gait Imagery-Based Brain–Computer Interface With Visual Feedback for Spinal Cord Injury Rehabilitation on Lokomat*. Retrieved from https://doi.org/10.1109/TBME.2024.3440036
* C. Yilmaz, Bahar Hatipoglu Yilmaz (2023). *Advancements in Image Feature-Based Classification of Motor Imagery EEG Data: A Comprehensive Review*. Retrieved from https://doi.org/10.18280/ts.400507
* César Alfredo Rocha-Herrera, Alan Díaz-Manríquez, J. H. Barrón-Zambrano, J. C. Elizondo-Leal, V. P. Saldivar-Alonso, J. Martínez-Angulo, M. Nuño-Maganda, Said Polanco-Martagón (2022). *EEG Feature Extraction Using Evolutionary Algorithms for Brain-Computer Interface Development*. Retrieved from https://doi.org/10.1155/2022/7571208
* Chandan Choubey, M. Dhanalakshmi, S. Karunakaran, Gaurav Vishnu Londhe, Vrince Vimal, M. Kirubakaran (2025). *Optimizing Bioimaging: Quantum Computing-Inspired Bald Eagle Search Optimization for Motor Imaging EEG Feature Selection*. Retrieved from https://doi.org/10.1177/15500594251325273
* Chang Liu, Jing Jin, Ren Xu, Shurui Li, Cili Zuo, Hao Sun, Xingyu Wang, A. Cichocki (2021). *Distinguishable spatial-spectral feature learning neural network framework for motor imagery-based brain–computer interface*. Retrieved from https://doi.org/10.1088/1741-2552/ac1d36
* Chao Tang, Dongyao Jiang, Lujuan Dang, Badong Chen (2024). *EEG Decoding Based on Normalized Mutual Information for Motor Imagery Brain–Computer Interfaces*. Retrieved from https://doi.org/10.1109/TCDS.2024.3401717
* Chao-Ran Jia, Jian-Wei Huang, Ying‐Qing Hu, Hai‐Yun Zhou, Hong‐Yu Liu, Xin Liu, Hai Zhang, Zu‐Cheng Shen, Wen‐Sheng Li, Shuang-Qi Gao, Ying Guo (2025). *The clinical applications of brain–computer interfaces*. Retrieved from https://doi.org/10.1002/brx2.70033
* Chengcheng Fan, Banghua Yang, Xiaoou Li, Shouwei Gao, Peng Zan (2024). *EEG-Based Feature Classification Combining 3D-Convolutional Neural Networks with Generative Adversarial Networks for Motor Imagery.*. Retrieved from https://doi.org/10.31083/j.jin2308153
* Chengzhen Wu, Bo Yao, Xin Zhang, Ting Li, Jinhai Wang, Jiangbo Pu (2025). *The Application of Entropy in Motor Imagery Paradigms of Brain–Computer Interfaces*. Retrieved from https://doi.org/10.3390/brainsci15020168
* Chukwuemeka Nwagu, Ala'a N. Alslaity, Rita Orji (2023). *EEG-Based Brain-Computer Interactions in Immersive Virtual and Augmented Reality: A Systematic Review*. Retrieved from https://doi.org/10.1145/3593226
* Chuong H. Nguyen, George K. Karavas, P. Artemiadis (2019). *Adaptive multi-degree of freedom Brain Computer Interface using online feedback: Towards novel methods and metrics of mutual adaptation between humans and machines for BCI*. Retrieved from https://doi.org/10.1371/journal.pone.0212620
* Cunbo Li, Peiyang Li, Yangsong Zhang, Ning Li, Yajing Si, Fali Li, Zehong Cao, Huafu Chen, Badong Chen, Dezhong Yao, Peng Xu (2023). *Effective Emotion Recognition by Learning Discriminative Graph Topologies in EEG Brain Networks*. Retrieved from https://doi.org/10.1109/TNNLS.2023.3238519
* D. Delisle-Rodríguez, Leticia Silva, T. Bastos-Filho (2023). *EEG changes during passive movements improve the motor imagery feature extraction in BCIs-based sensory feedback calibration*. Retrieved from https://doi.org/10.1088/1741-2552/acb73b
* Diego Lopez-Bernal, David C. Balderas, Pedro Ponce, Arturo Molina (2024). *Exploring inter-trial coherence for inner speech classification in EEG-based brain–computer interface*. Retrieved from https://doi.org/10.1088/1741-2552/ad3f50
* Dr Venkata Phanikrishna B (Balam) (2024). *Systematic Review of Single-Channel EEG-Based Drowsiness Detection Methods*. Retrieved from https://doi.org/10.1109/TITS.2024.3442249
* E. Gkintoni, Anthimos Aroutzidis, H. Antonopoulou, C. Halkiopoulos (2025). *From Neural Networks to Emotional Networks: A Systematic Review of EEG-Based Emotion Recognition in Cognitive Neuroscience and Real-World Applications*. Retrieved from https://doi.org/10.3390/brainsci15030220
* Eda Dağdevir, M. Tokmakçi (2021). *Determination of Effective Signal Processing Stages for Brain Computer Interface on BCI Competition IV Data Set 2b: A Review Study*. Retrieved from https://doi.org/10.1080/03772063.2021.1914204
* Eltaf Abdalsalam Mohamed, M. Zuki Yusoff, Ibrahim Khalil Adam, Elnazeer Ali Hamid, Fares Al-Shargie, M. Muzammel (2018). *Enhancing EEG Signals in Brain Computer Interface Using Intrinsic Time-Scale Decomposition*. Retrieved from https://doi.org/10.1088/1742-6596/1123/1/012004
* Emre Arı, E. Taçgın (2023). *Input Shape Effect on Classification Performance of Raw EEG Motor Imagery Signals with Convolutional Neural Networks for Use in Brain—Computer Interfaces*. Retrieved from https://doi.org/10.3390/brainsci13020240
* Essam H. Houssein, A. Hammad, Abdelmgeid A. Ali (2022). *Human emotion recognition from EEG-based brain–computer interface using machine learning: a comprehensive review*. Retrieved from https://doi.org/10.1007/s00521-022-07292-4
* Eunmok Yang, K. Shankar, Eswaran Perumal, Changho Seo (2024). *Optimal Fuzzy Logic Enabled EEG Motor Imagery Classification for Brain Computer Interface*. Retrieved from https://doi.org/10.1109/ACCESS.2023.3346674
* F. Ahmed, Hashim Iqbal, Ahmed Nouman, H. F. Maqbool, Saqib Zafar, M. Saleem (2023). *A non Invasive Brain-Computer-Interface for Service Robotics*. Retrieved from https://doi.org/10.1109/ICAI58407.2023.10136672
* F. Pichiorri, J. Toppi, V. de Seta, E. Colamarino, M. Masciullo, F. Tamburella, M. Lorusso, F. Cincotti, D. Mattia (2023). *Exploring high-density corticomuscular networks after stroke to enable a hybrid Brain-Computer Interface for hand motor rehabilitation*. Retrieved from https://doi.org/10.1186/s12984-023-01127-6
* Fengge Bao, Weiheng Liu (2023). *EEG feature extraction methods in motor imagery brain computer interface*. Retrieved from https://doi.org/10.1117/12.2667875
* Francesco Mattioli, C. Porcaro, Gianluca Baldassarre (2021). *A 1D CNN for high accuracy classification and transfer learning in motor imagery EEG-based brain-computer interface*. Retrieved from https://doi.org/10.1088/1741-2552/ac4430
* Funda Kutlu Onay, C. Köse (2019). *Assessment of CSP-based two-stage channel selection approach and local transformation-based feature extraction for classification of motor imagery/movement EEG data*. Retrieved from https://doi.org/10.1515/bmt-2018-0201
* Gaganjot Kaur, Meenu Gupta, Rakesh Kumar (2023). *Swarm Intelligence-Based Feature Selection Algorithm of EEG Classification for Brain Emotion Detection: A Review*. Retrieved from https://doi.org/10.1109/I2CT57861.2023.10126425
* Gan Huang, Zhiheng Zhao, Shaorong Zhang, Zhenxing Hu, Jiaming Fan, Meisong Fu, Jiale Chen, Yaqiong Xiao, Jun Wang, Guo Dan (2023). *Discrepancy between inter- and intra-subject variability in EEG-based motor imagery brain-computer interface: Evidence from multiple perspectives*. Retrieved from https://doi.org/10.3389/fnins.2023.1122661
* Guangyu Wang, Wenchao Liu, Yuhong He, Cong Xu, Lin Ma, Haifeng Li (2024). *EEGPT: Pretrained Transformer for Universal and Reliable Representation of EEG Signals*. Retrieved from https://doi.org/10.52202/079017-1239
* Guoyang Liu, Rui Zhang, Lan Tian, Weidong Zhou (2025). *Fine-Grained Spatial-Frequency-Time Framework for Motor Imagery Brain–Computer Interface*. Retrieved from https://doi.org/10.1109/JBHI.2025.3536212
* Gursimran Singh, Aviral Chharia, Rahul Upadhyay, Vinay Kumar, Luca Longo (2025). *PyNoetic: A modular python framework for no-code development of EEG brain-computer interfaces*. Retrieved from https://doi.org/10.1371/journal.pone.0327791
* H. N. Zahra, H. Zakaria, B. R. Hermanto (2022). *Exploration of Pattern Recognition Methods for Motor Imagery EEG Signal with Convolutional Neural Network Approach*. Retrieved from https://doi.org/10.1088/1742-6596/2312/1/012064
* H. Nisar, Kee Wee Boon, Yeap Kim Ho, Teoh Shen Khang (2022). *Brain-Computer Interface: Feature Extraction and Classification of Motor Imagery-Based Cognitive Tasks*. Retrieved from https://doi.org/10.1109/i2cacis54679.2022.9815460
* H. Sadreazami, G. Mitsis (2020). *Motor Task Learning in Brain Computer Interfaces using Time-Dependent Regularized Common Spatial Patterns and Residual Networks*. Retrieved from https://doi.org/10.1109/newcas49341.2020.9159807
* Haider Abdulkarim, M. Al-Faiz (2021). *Online multiclass EEG feature extraction and recognition using modified convolutional neural network method*. Retrieved from https://doi.org/10.11591/IJECE.V11I5.PP4016-4026
* Hao Sun, Jing Jin, Ren Xu, A. Cichocki (2021). *Feature Selection Combining Filter and Wrapper Methods for Motor-Imagery Based Brain-Computer Interfaces*. Retrieved from https://doi.org/10.1142/S0129065721500404
* He He, Dongrui Wu (2018). *Transfer Learning for Brain–Computer Interfaces: A Euclidean Space Data Alignment Approach*. Retrieved from https://doi.org/10.1109/TBME.2019.2913914
* Hojong Choi, Junghun Park, Yeon-Mo Yang (2022). *A Novel Quick-Response Eigenface Analysis Scheme for Brain–Computer Interfaces*. Retrieved from https://doi.org/10.3390/s22155860
* Hsiang-Chen Lee, Ching‐Hung Lee (2023). *Generalized Optimal EEG Channels Selection for Motor Imagery Brain–Computer Interface*. Retrieved from https://doi.org/10.1109/JSEN.2023.3313236
* Hua Fang, Jing Jin, I. Daly, Xingyu Wang (2022). *Feature Extraction Method Based on Filter Banks and Riemannian Tangent Space in Motor-Imagery BCI*. Retrieved from https://doi.org/10.1109/JBHI.2022.3146274
* Humaun Kabir, Nadim Ibne Akhtar, Nishat Tasnim, Abu Saleh Musa Miah, Hyoun-Sup Lee, Si-Woong Jang, Jungpil Shin (2024). *Exploring Feature Selection and Classification Techniques to Improve the Performance of an Electroencephalography-Based Motor Imagery Brain–Computer Interface System*. Retrieved from https://doi.org/10.3390/s24154989
* Hye-Young Nam, Jun-Mo Kim, Woohyeok Choi, Soyeon Bak, Tae-Eui Kam (2023). *The effects of layer-wise relevance propagation-based feature selection for EEG classification: a comparative study on multiple datasets*. Retrieved from https://doi.org/10.3389/fnhum.2023.1205881
* J. Arnin, D. Kahani, H. Lakany, B. Conway (2018). *Evaluation of Different Signal Processing Methods in Time and Frequency Domain for Brain-Computer Interface Applications*. Retrieved from https://doi.org/10.1109/EMBC.2018.8512193
* J. Fumanal-Idocin, Yu-kai Wang, Chin-Teng Lin, Javier Fern'andez, J. Sanz, H. Bustince (2021). *Motor-Imagery-Based Brain–Computer Interface Using Signal Derivation and Aggregation Functions*. Retrieved from https://doi.org/10.1109/TCYB.2021.3073210
* J. Gutiérrez-Martínez, J. A. Mercado-Gutiérrez, B. Carvajal-Gámez, J. L. Rosas-Trigueros, A. Contreras-Martínez (2021). *Artificial Intelligence Algorithms in Visual Evoked Potential-Based Brain-Computer Interfaces for Motor Rehabilitation Applications: Systematic Review and Future Directions*. Retrieved from https://doi.org/10.3389/fnhum.2021.772837
* J. Kirar, R. Agrawal (2018). *Relevant Frequency Band Selection using Sequential Forward Feature Selection for Motor Imagery Brain Computer Interfaces*. Retrieved from https://doi.org/10.1109/SSCI.2018.8628719
* Jai Kalra, Prashasti Mittal, Nirmiti Mittal, Abhishek Arora, Utkarsh Tewari, Aviral Chharia, Rahul Upadhyay, Vinay Kumar, Longo Luca (2023). *How Visual Stimuli Evoked P300 is Transforming the Brain–Computer Interface Landscape: A PRISMA Compliant Systematic Review*. Retrieved from https://doi.org/10.1109/TNSRE.2023.3246588
* Jaiteg Singh, F. Ali, Rupali Gill, Babar Shah, Daehan Kwak (2023). *A Survey of EEG and Machine Learning-Based Methods for Neural Rehabilitation*. Retrieved from https://doi.org/10.1109/ACCESS.2023.3321067
* Ji-Hack Lee, Young-Seok Choi (2019). *A data driven Information theoretic feature extraction in EEG-based Motor Imagery BCI*. Retrieved from https://doi.org/10.1109/ictc46691.2019.8939945
* Jia Wen Li, Di Lin, Yan Che, J. Lv, Rong Jun Chen, Lei Wang, Xiangyu Zeng, Jin-Chang Ren, Huiming Zhao, X. Lu (2023). *An innovative EEG-based emotion recognition using a single channel-specific feature from the brain rhythm code method*. Retrieved from https://doi.org/10.3389/fnins.2023.1221512
* Jiayuan Meng, Yingru Zhao, Kun Wang, Jinsong Sun, Weibo Yi, Fangzhou Xu, Minpeng Xu, Dong Ming (2023). *Rhythmic temporal prediction enhances neural representations of movement intention for brain–computer interface*. Retrieved from https://doi.org/10.1088/1741-2552/ad0650
* Jiebo Luo, Weigang Cui, Song Xu, Lina Wang, Xiao Li, Xiaofeng Liao, Yang Li (2024). *A Dual-Branch Spatio-Temporal-Spectral Transformer Feature Fusion Network for EEG-Based Visual Recognition*. Retrieved from https://doi.org/10.1109/TII.2023.3280560
* Jihen Souissi, Sourour Karmani, Kais Belwafi, R. Djemal (2024). *Enhancing Four-Class Motor Imagery Detection Through Advanced Feature Extraction Techniques*. Retrieved from https://doi.org/10.1109/AICCSA63423.2024.10912553
* Jing Chen, Zexian Zhao, Q. Shu, Guolong Cai (2022). *Feature extraction based on microstate sequences for EEG–based emotion recognition*. Retrieved from https://doi.org/10.3389/fpsyg.2022.1065196
* Jing Jin, Ruitian Xu, Ian Daly, Xueqing Zhao, Xingyu Wang, Andrzej Cichocki (2024). *MOCNN: A Multiscale Deep Convolutional Neural Network for ERP-Based Brain-Computer Interfaces*. Retrieved from https://doi.org/10.1109/TCYB.2024.3390805
* Jing Jin, Weijie Chen, Ren Xu, Wei Liang, Xiao Wu, Xinjie He, Xingyu Wang, Andrzej Cichocki (2024). *Multiscale Spatial-Temporal Feature Fusion Neural Network for Motor Imagery Brain-Computer Interfaces*. Retrieved from https://doi.org/10.1109/JBHI.2024.3472097
* Jing Shi, Qisong Wang, Dan Liu, C. Kim, Yan Zhang, Xin Liu (2023). *A WPSD-Based Feature Extraction Method of EEG Signal for Motor Imagination*. Retrieved from https://doi.org/10.1109/CEI60616.2023.10527898
* John Larocco, Qudsia Tahmina, Sam Lecian, Jason Moore, Cole Helbig, Surya Gupta (2023). *Evaluation of an English language phoneme-based imagined speech brain computer interface with low-cost electroencephalography*. Retrieved from https://doi.org/10.3389/fninf.2023.1306277
* Juliana Gonzalez-Astudillo, Fabrizio de Vico Fallani (2025). *Feature Interpretability in Motor Imagery Brain Computer Interfaces: A Meta-Analysis Across Connectivity, Spatial Filtering, and Riemannian Methods.*. Retrieved from https://doi.org/10.1177/21580014251392230
* Junjian Chen, Zhuliang Yu, Z. Gu, Yuanqing Li (2020). *Deep Temporal-Spatial Feature Learning for Motor Imagery-Based Brain–Computer Interfaces*. Retrieved from https://doi.org/10.1109/TNSRE.2020.3023417
* K. R. Swetha, R. G K, S. S V (2022). *SSVEP-Based Brain-Computer Interface System for Managing Disabilities*. Retrieved from https://doi.org/10.1109/ICERECT56837.2022.10060273
* K. Won, Moonyoung Kwon, M. Ahn, S. Jun (2022). *EEG Dataset for RSVP and P300 Speller Brain-Computer Interfaces*. Retrieved from https://doi.org/10.1038/s41597-022-01509-w
* Kai Zhang, Guanghua Xu, Chenghang Du, Yongcheng Wu, Xiaowei Zheng, Sicong Zhang, Chengcheng Han, Renhao Liang, Ruiquan Chen (2021). *Weak Feature Extraction and Strong Noise Suppression for SSVEP-EEG Based on Chaotic Detection Technology*. Retrieved from https://doi.org/10.1109/TNSRE.2021.3073918
* Kai Zhang, Guanghua Xu, Xiaowei Zheng, Huanzhong Li, Sicong Zhang, Yunhui Yu, Renghao Liang (2020). *Application of Transfer Learning in EEG Decoding Based on Brain-Computer Interfaces: A Review*. Retrieved from https://doi.org/10.3390/s20216321
* Kheira Djelloul, Abdelkader Nasreddine Belkacem (2021). *EEG Classification-based Comparison Study of Motor-Imagery Brain-Computer Interface*. Retrieved from https://doi.org/10.1109/ICRAMI52622.2021.9585902
* Kholoud Elnaggar, M. M. El-gayar, M. Elmogy (2025). *Depression Detection and Diagnosis Based on Electroencephalogram (EEG) Analysis: A Systematic Review*. Retrieved from https://doi.org/10.3390/diagnostics15020210
* Kritiprasanna Das, R. B. Pachori (2023). *Electroencephalogram-Based Motor Imagery Brain–Computer Interface Using Multivariate Iterative Filtering and Spatial Filtering*. Retrieved from https://doi.org/10.1109/TCDS.2022.3214081
* Kun Xia, Włodziaław Duch, Yu Sun, Kedi Xu, Weili Fang, Hanbin Luo, Yi Zhang, Dong Sang, Xiaodong Xu, Fei‐Yue Wang, Dongrui Wu (2023). *Privacy-Preserving Brain–Computer Interfaces: A Systematic Review*. Retrieved from https://doi.org/10.1109/TCSS.2022.3184818
* Kübra Erat, Elif Bilge Şahin, Furkan Doğan, Nur Merdanoğlu, Ahmet Akcakaya, P. O. Durdu (2024). *Emotion recognition with EEG-based brain-computer interfaces: a systematic literature review*. Retrieved from https://doi.org/10.1007/s11042-024-18259-z
* L. F. S. Uribe, C. A. S. Filho, Vinicius Alves de Oliveira, T. B. da Silva Costa, P. G. Rodrigues, D. Soriano, Levy Boccato, G. Castellano, R. Attux (2019). *A correntropy-based classifier for motor imagery brain-computer interfaces*. Retrieved from https://doi.org/10.1088/2057-1976/ab5145
* L. Garrote, Rute Bettencourt, João Perdiz, Gabriel Pires, Urbano J. Nunes (2025). *Generalization of Machine and Deep Learning Models for Brain-Computer Interfaces Across Sessions and Paradigms in a Completely Locked-In Patient*. Retrieved from https://doi.org/10.1109/RO-MAN63969.2025.11217899
* Li Hu, Wei Gao, Zilin Lu, Chun Shan, Haiwei Ma, Wenyu Zhang, Yuanqing Li (2024). *Subject-Independent Wearable P300 Brain–Computer Interface Based on Convolutional Neural Network and Metric Learning*. Retrieved from https://doi.org/10.1109/TNSRE.2024.3457502
* Li Zheng, Sen Sun, Hongze Zhao, Weihua Pei, Hongda Chen, Xiaorong Gao, Lijian Zhang, Yijun Wang (2020). *A Cross-Session Dataset for Collaborative Brain-Computer Interfaces Based on Rapid Serial Visual Presentation*. Retrieved from https://doi.org/10.3389/fnins.2020.579469
* Li Zhu, Youyang Liu, Riheng Liu, Yong Peng, Jianting Cao, Junhua Li, Wanzeng Kong (2023). *Decoding Multi-Brain Motor Imagery From EEG Using Coupling Feature Extraction and Few-Shot Learning*. Retrieved from https://doi.org/10.1109/TNSRE.2023.3336356
* Lihua Zhang, Xin Zhang, Xiu Zhang, Changyi Yu, Xuguang Liu (2025). *Objective Emotion Assessment Using a Triple Attention Network for an EEG-Based Brain–Computer Interface*. Retrieved from https://doi.org/10.3390/brainsci15111167
* Lina Qiu, Yongshi Zhong, Zhipeng He, Jiahui Pan (2022). *Improved classification performance of EEG-fNIRS multimodal brain-computer interface based on multi-domain features and multi-level progressive learning*. Retrieved from https://doi.org/10.3389/fnhum.2022.973959
* Linlin Gong, Wanzhong Chen, Dingguo Zhang (2024). *An Attention-Based Multi-Domain Bi-Hemisphere Discrepancy Feature Fusion Model for EEG Emotion Recognition*. Retrieved from https://doi.org/10.1109/JBHI.2024.3418010
* Lorenza Brusini, Francesca Stival, F. Setti, E. Menegatti, G. Menegaz, S. Storti (2021). *A Systematic Review on Motor-Imagery Brain-Connectivity-Based Computer Interfaces*. Retrieved from https://doi.org/10.1109/thms.2021.3115094
* M. Bittencourt-Villalpando, N. Maurits (2018). *Stimuli and Feature Extraction Algorithms for Brain-Computer Interfaces: A Systematic Comparison*. Retrieved from https://doi.org/10.1109/TNSRE.2018.2855801
* M. Rashid, N. Sulaiman, A. P. Majeed, R. Musa, A. Nasir, Bifta Sama Bari, S. Khatun (2020). *Current Status, Challenges, and Possible Solutions of EEG-Based Brain-Computer Interface: A Comprehensive Review*. Retrieved from https://doi.org/10.3389/fnbot.2020.00025
* M. Sadiq, Xiaojun Yu, Zhaohui Yuan, Fan Zeming, A. Rehman, Inam Ullah, Guoqi Li, Gaoxi Xiao (2019). *Motor Imagery EEG Signals Decoding by Multivariate Empirical Wavelet Transform-Based Framework for Robust Brain–Computer Interfaces*. Retrieved from https://doi.org/10.1109/ACCESS.2019.2956018
* M. U. Ali, Kwang-su Kim, K. D. Kallu, A. Zafar, Seung Won Lee (2023). *OptEF-BCI: An Optimization-Based Hybrid EEG and fNIRS–Brain Computer Interface*. Retrieved from https://doi.org/10.3390/bioengineering10050608
* M. Z. A. Faiz, Ammar A. Al-hamadani (2019). *Online Brain Computer Interface Based Five Classes EEG To Control Humanoid Robotic Hand*. Retrieved from https://doi.org/10.1109/TSP.2019.8769072
* Maedeh Azadi Moghadam, Ali Maleki (2023). *Fatigue factors and fatigue indices in SSVEP-based brain-computer interfaces: a systematic review and meta-analysis*. Retrieved from https://doi.org/10.3389/fnhum.2023.1248474
* Maham Saeidi, W. Karwowski, F. Farahani, K. Fiok, R. Taiar, P. Hancock, Awad M. Aljuaid (2021). *Neural Decoding of EEG Signals with Machine Learning: A Systematic Review*. Retrieved from https://doi.org/10.3390/brainsci11111525
* Mahsa Pourhosein Kalashami, M. Pedram, H. Sadr (2022). *EEG Feature Extraction and Data Augmentation in Emotion Recognition*. Retrieved from https://doi.org/10.1155/2022/7028517
* Mala Saraswat, A. Dubey (2023). *EBi-LSTM: an enhanced bi-directional LSTM for time-series data classification by heuristic development of optimal feature integration in brain computer interface*. Retrieved from https://doi.org/10.1080/10255842.2023.2187662
* Marcel F. Hinss, E. Jahanpour, B. Somon, Lou Pluchon, F. Dehais, R. Roy (2023). *Open multi-session and multi-task EEG cognitive Dataset for passive brain-computer Interface Applications*. Retrieved from https://doi.org/10.1038/s41597-022-01898-y
* Marija Novičić, O. Djordjević, Vera Miler-Jerković, L. Konstantinović, Andrej M Savić (2024). *Improving the Performance of Electrotactile Brain–Computer Interface Using Machine Learning Methods on Multi-Channel Features of Somatosensory Event-Related Potentials*. Retrieved from https://doi.org/10.3390/s24248048
* Mary Judith Antony, Baghavathi Priya Sankaralingam, Shakir Khan, Abrar Almjally, N. Almujally, Rakesh Kumar Mahendran (2023). *Brain–Computer Interface: The HOL–SSA Decomposition and Two-Phase Classification on the HGD EEG Data*. Retrieved from https://doi.org/10.3390/diagnostics13172852
* Marzieh Hajizamani, M. Helfroush, K. Kazemi (2020). *Optimum Feature Selection Using Hybrid Grey Wolf Differential Evolution for Motor Imagery Brain Computer Interface*. Retrieved from https://doi.org/10.1109/ICCKE50421.2020.9303629
* Mathias Schmoigl-Tonis, Christoph Schranz, Gernot R. Müller-Putz (2023). *Methods for motion artifact reduction in online brain-computer interface experiments: a systematic review*. Retrieved from https://doi.org/10.3389/fnhum.2023.1251690
* Mathis Fleury, Patrícia Figueiredo, A. Vourvopoulos, A. Lécuyer (2023). *Two is better? combining EEG and fMRI for BCI and neurofeedback: a systematic review*. Retrieved from https://doi.org/10.1088/1741-2552/ad06e1
* Md Samiul Haque Sunny, Nashrah Afroze, Eklas Hossain (2020). *EEG Band Separation Using Multilayer Perceptron for Efficient Feature Extraction and Perfect BCI Paradigm*. Retrieved from https://doi.org/10.1109/ETCCE51779.2020.9350883
* Md. Humaun Kabir, Shabbir Mahmood, Abdullah Al Shiam, Abu Saleh Musa Miah, Jungpil Shin, M. I. Molla (2023). *Investigating Feature Selection Techniques to Enhance the Performance of EEG-Based Motor Imagery Tasks Classification*. Retrieved from https://doi.org/10.3390/math11081921
* Mehmet Zubeyir Unlu (2025). *A Comparative Analysis of Mathematical EEG Feature Extraction Methods Across Temporal, Spectral, and Nonlinear Domains*. Retrieved from https://doi.org/10.59671/xtsjd
* Mehrnoosh Neghabi, H. Marateb, A. Mahnam (2018). *Comparing Steady-State Visually Evoked Potentials Frequency Estimation Methods in Brain-Computer Interface With the Minimum Number of EEG Channels*. Retrieved from https://doi.org/10.32598/bcn.9.10.200
* Miao Cai, Jie Hong (2024). *Joint multi-feature extraction and transfer learning in motor imagery brain computer interface.*. Retrieved from https://doi.org/10.1080/10255842.2024.2404541
* Moein Radman, Reza Arghand, Nader Nariman-Zadeh, Ali Chaibakhsh (2025). *Enhancing EEG-based BCI Performances by Reducing Covariate Shift via Adaptive Multi-Domain Feature Extraction*. Retrieved from https://doi.org/10.1109/ICCKE68588.2025.11273863
* Mohamed A A Mohamed, Salem Mansour, P. Soulatiantork, K. Ang, K. Phua, M. Arvaneh (2023). *Improving Common Spatial Patterns in Brain-Computer Interface Using Dynamic Time Warping and EEG Normalization*. Retrieved from https://doi.org/10.1109/MetroXRAINE58569.2023.10405776
* Mohammad Nur Alam, M. Ibrahimy, S. Motakabber (2021). *Feature Extraction of EEG Signal by Power Spectral Density for Motor Imagery Based BCI*. Retrieved from https://doi.org/10.1109/ICCCE50029.2021.9467141
* Muhammad Arif, Faizan ur Rehman, Lukás Sekanina, A. Malik (2024). *A comprehensive survey of evolutionary algorithms and metaheuristics in brain EEG-based applications*. Retrieved from https://doi.org/10.1088/1741-2552/ad7f8e
* Murside Degirmenci, Yilmaz Kemal Yuce, M. Perc, Yalçin Isler (2024). *EEG-based finger movement classification with intrinsic time-scale decomposition*. Retrieved from https://doi.org/10.3389/fnhum.2024.1362135
* Muskan Priyadarshani, Pushpendra Kumar, Kanojia Sindhuben Babulal, Dharmendra Singh Rajput, Harshita Patel (2024). *Human Brain Waves Study Using EEG and Deep Learning for Emotion Recognition*. Retrieved from https://doi.org/10.1109/ACCESS.2024.3427822
* Mustapha Moufassih, Oussama Tarahi, Soukaina Hamou, Said Agounad, Hafida Idrissi Azami (2022). *Spectral feature extraction from EEG based motor imagery using common spatial patterns*. Retrieved from https://doi.org/10.1109/IRASET52964.2022.9738394
* Na Ji, Liangdi Ma, Hui Dong, Xuejun Zhang (2019). *EEG Signals Feature Extraction Based on DWT and EMD Combined with Approximate Entropy*. Retrieved from https://doi.org/10.3390/brainsci9080201
* Nannaphat Siribunyaphat, Yunyong Punsawad (2023). *Brain–Computer Interface Based on Steady-State Visual Evoked Potential Using Quick-Response Code Pattern for Wheelchair Control*. Retrieved from https://doi.org/10.3390/s23042069
* Natasha M. J. Padfield, J. Zabalza, Huimin Zhao, Valentin Masero Vargas, J. Ren (2019). *EEG-Based Brain-Computer Interfaces Using Motor-Imagery: Techniques and Challenges*. Retrieved from https://doi.org/10.3390/s19061423
* Natjamee Tohkhwan, Charoenporn Bouyam, Theerat Saichoo, Nannaphat Siribunyaphat, Manorot Borirakarawin, Yunyong Punsawad (2024). *EEG-based Brain-Computer Interface System via Time-Locked Visual Attention for Assistive Device Control*. Retrieved from https://doi.org/10.1109/ECTI-CON60892.2024.10594880
* Navtej S. Ghumman, B. Jindal (2022). *An Optimized SWCSP Technique for Feature Extraction in EEG-based BCI System*. Retrieved from https://doi.org/10.14500/aro.10926
* Nedime Karakullukcu, Bülent Yilmaz (2021). *Detection of Movement Intention in EEG-Based Brain-Computer Interfaces Using Fourier-Based Synchrosqueezing Transform*. Retrieved from https://doi.org/10.1142/S0129065721500593
* Nupur Chugh, Swati Aggarwal (2022). *Hybrid Brain–Computer Interface Spellers: A Walkthrough Recent Advances in Signal Processing Methods and Challenges*. Retrieved from https://doi.org/10.1080/10447318.2022.2093445
* Nurhan Gürsel Özmen, Levent Gümüsel, Yuan Yang (2018). *A Biologically Inspired Approach to Frequency Domain Feature Extraction for EEG Classification*. Retrieved from https://doi.org/10.1155/2018/9890132
* O-Yeon Kwon, Min-Ho Lee, Cuntai Guan, Seong-Whan Lee (2019). *Subject-Independent Brain–Computer Interfaces Based on Deep Convolutional Neural Networks*. Retrieved from https://doi.org/10.1109/TNNLS.2019.2946869
* Ó. Gómez-Morales, D. Collazos-Huertas, A. Álvarez-Meza, C. Castellanos-Dominguez (2025). *EEG Signal Prediction for Motor Imagery Classification in Brain–Computer Interfaces*. Retrieved from https://doi.org/10.3390/s25072259
* Olena Shevchenko, Sofiia Yeremeieva, Brokoslaw Laschowski (2024). *Comparative Analysis of Neural Decoding Algorithms for Brain-Machine Interfaces*. Retrieved from https://doi.org/10.1101/2024.12.05.627080
* P. Arpaia, Antonio Esposito, Nicola Moccaldi, Angela Natalizio, M. Parvis (2023). *Online processing for motor imagery-based brain-computer interfaces relying on EEG*. Retrieved from https://doi.org/10.1109/I2MTC53148.2023.10176052
* P. Huynh, Gregory Warner, Hong Lin (2020). *Effects of EMD and Feature Extraction on EEG Analysis*. Retrieved from https://doi.org/10.12720/jait.11.1.26-34
* P. Lahane, Jay Jagtap, Aditya Inamdar, Nihal Karne, Ritwik Dev (2019). *A review of recent trends in EEG based Brain-Computer Interface*. Retrieved from https://doi.org/10.1109/ICCIDS.2019.8862054
* P. Nikolov, Olexiy Bychkov, Katia Rasheva-Yordanova, G. Dimitrov, Pavel S. Petrov, V. Martsenyuk (2025). *Exploring the Potential of Brain-Computer Interfaces and EEG Signal Analysis Algorithms: A Review and Analysis of Computational Techniques*. Retrieved from https://doi.org/10.1109/ACIT65614.2025.11185624
* P. Petrantonakis, I. Kompatsiaris (2018). *Single-Trial NIRS Data Classification for Brain–Computer Interfaces Using Graph Signal Processing*. Retrieved from https://doi.org/10.1109/TNSRE.2018.2860629
* P. S. Shabestari, Delphine Ribes, Lara Défayes, Danpeng Cai, Emily Groves, Harry H. Behjat, D. Van de Ville, Tobias Kleinjung, Adrian Naas, Nicolas Henchoz, A. Sonderegger, Patrick Neff (2025). *Advances on Real Time M/EEG Neural Feature Extraction*. Retrieved from https://doi.org/10.1109/CBMS65348.2025.00074
* Patcharin Cheng, Phairot Autthasan, Boriwat Pijarana, Ekapol Chuangsuwanich, Theerawit Wilaiprasitporn (2018). *Towards Asynchronous Motor Imagery-Based Brain-Computer Interfaces: a joint training scheme using deep learning*. Retrieved from https://doi.org/10.1109/TENCON.2018.8650546
* Pengpai Wang, Xuhao Cao, Yueying Zhou, Peiliang Gong, Muhammad Yousefnezhad, Wei Shao, Daoqiang Zhang (2023). *A comprehensive review on motion trajectory reconstruction for EEG-based brain-computer interface*. Retrieved from https://doi.org/10.3389/fnins.2023.1086472
* Ph.D M.Kanimozhi, Dr.R.Roselin (2020). *Statistical Feature Extraction and Classification using Machine Learning Techniques in Brain-Computer Interface*. Retrieved from https://doi.org/10.35940/ijitee.k2343.019320
* Ping-Chen Tsai, Asangaedem Akpan, K. Tang, Heba Lakany (2025). *Brain computer interfaces for cognitive enhancement in older people - challenges and applications: a systematic review*. Retrieved from https://doi.org/10.1186/s12877-025-05676-4
* Pragati Patel, R. R, Ramesh Naidu Annavarapu (2021). *EEG-based human emotion recognition using entropy as a feature extraction measure*. Retrieved from https://doi.org/10.1186/s40708-021-00141-5
* Pragati Patel, Sivarenjani Balasubramanian, Ramesh Naidu Annavarapu (2024). *Cross subject emotion identification from multichannel EEG sub-bands using Tsallis entropy feature and KNN classifier*. Retrieved from https://doi.org/10.1186/s40708-024-00220-3
* Prajwal Singh, Dwip Dalal, Gautam Vashishtha, KrishnaP Miyapuram, S. Raman (2023). *Learning Robust Deep Visual Representations from EEG Brain Recordings*. Retrieved from https://doi.org/10.1109/WACV57701.2024.00738
* Q. Xiong, Xinman Zhang, Wenfeng Wang, Yuhong Gu (2020). *A Parallel Algorithm Framework for Feature Extraction of EEG Signals on MPI*. Retrieved from https://doi.org/10.1155/2020/9812019
* Qingsong Ai, Anqi Chen, Kun Chen, QUAN LIU, Tichao Zhou, Sijin Xin, Ze Ji (2019). *Feature extraction of four-class motor imagery EEG signals based on functional brain network*. Retrieved from https://doi.org/10.1088/1741-2552/ab0328
* Qiwei Xue, Yu-jia Song, Huapeng Wu, Yong Cheng, Hongtao Pan (2024). *Graph neural network based on brain inspired forward-forward mechanism for motor imagery classification in brain-computer interfaces*. Retrieved from https://doi.org/10.3389/fnins.2024.1309594
* R. K. Kanna, Preety Shoran, Meenakshi Yadav, Mohammad Nadeem Ahmed, S. Burje, Garima Shukla, Anurag Sinha, Mohammad Rashid Hussain, Saifullah Khalid (2025). *Improving EEG based brain computer interface emotion detection with EKO ALSTM model*. Retrieved from https://doi.org/10.1038/s41598-025-07438-z
* R. Raman, Vikram Kumar, C. P. Sanjay, Apurv Verma, Shailesh Rastogi, Dharmendra Pandey (2024). *Advancing EEG Brain-Computer Interfaces with Efficient Machine Learning Classifications*. Retrieved from https://doi.org/10.1109/ACOIT62457.2024.10939133
* Radia Rayan Chowdhury, Yar Muhammad, Usman Adeel (2023). *Enhancing Cross-Subject Motor Imagery Classification in EEG-Based Brain–Computer Interfaces by Using Multi-Branch CNN*. Retrieved from https://doi.org/10.3390/s23187908
* Ramadhan Rashid Said, Md Belal Bin Heyat, Keer Song, Chao Tian, Zhe Wu (2022). *A Systematic Review of Virtual Reality and Robot Therapy as Recent Rehabilitation Technologies Using EEG-Brain–Computer Interface Based on Movement-Related Cortical Potentials*. Retrieved from https://doi.org/10.3390/bios12121134
* Rifai Chai, K. Hong, M. J. Khan, M. J. Hong (2018). *Feature Extraction and Classification Methods for Hybrid fNIRS-EEG Brain-Computer Interfaces*. Retrieved from https://doi.org/10.3389/fnhum.2018.00246
* Rito Clifford Maswanganyi, Chunling Tu, P. Owolawi, Shengzhi Du (2022). *Statistical Evaluation of Factors Influencing Inter-Session and Inter-Subject Variability in EEG-Based Brain Computer Interface*. Retrieved from https://doi.org/10.1109/ACCESS.2022.3205734
* Robert Finnis, Adeel Mehmood, Henning Holle, Jamshed Iqbal (2025). *Exploring Imagined Movement for Brain–Computer Interface Control: An fNIRS and EEG Review*. Retrieved from https://doi.org/10.3390/brainsci15091013
* Rosanne Zerafa, Tracey A. Camilleri, O. Falzon, Kenneth P. Camilleri (2018). *To train or not to train? A survey on training of feature extraction methods for SSVEP-based BCIs*. Retrieved from https://doi.org/10.1088/1741-2552/aaca6e
* Ruixin Luo, Minpeng Xu, Xiaoyu Zhou, Xiaolin Xiao, T. Jung, Dong Ming (2022). *Data Augmentation of SSVEPs Using Source Aliasing Matrix Estimation for Brain–Computer Interfaces*. Retrieved from https://doi.org/10.1109/TBME.2022.3227036
* Runze Wu, Jing Jin, I. Daly, Xingyu Wang, A. Cichocki (2023). *Classification of Motor Imagery Based on Multi-Scale Feature Extraction and the Channel-Temporal Attention Module*. Retrieved from https://doi.org/10.1109/TNSRE.2023.3294815
* S. Gokulnath, A. Ponraj, Bhargav Krishna, Shivaganesh, Sandeep (2024). *Motion Control Using Brain Computer Interface Utilizing GCNs-Net with BILstms*. Retrieved from https://doi.org/10.1109/ICDECS59733.2023.10503435
* S. Postalcıoğlu (2021). *Wavelet Transform Based Feature Extraction for EEG Signal Classification*. Retrieved from https://doi.org/10.37394/23205.2021.20.21
* S. Rajalakshmi, Ibrahim AlMohimeed, Mohamed Yacin Sikkandar, S. Sabarunisha Begum (2023). *Optimal Deep Learning-Based Recognition Model for EEG Enabled Brain-Computer Interfaces Using Motor-Imagery*. Retrieved from https://doi.org/10.2478/msr-2023-0031
* S. Saha, M. Baumert (2020). *Intra- and Inter-subject Variability in EEG-Based Sensorimotor Brain Computer Interface: A Review*. Retrieved from https://doi.org/10.3389/fncom.2019.00087
* S. Thakur, Samriti Thakur, Aryan Rana, Pankaj Kumar, Kranti Kumar, Chien‐Ming Chen (2025). *Exploring the Evolution of Feature Extraction Methods in Brain–Computer Interfaces (BCIs): A Systematic Review of Research Progress and Future Trends*. Retrieved from https://doi.org/10.1002/widm.70040
* Saher Soni, Shivam Chaudhary, K. Miyapuram (2024). *Enhancing Motor Imagery based Brain Computer Interfaces for Stroke Rehabilitation*. Retrieved from https://doi.org/10.1145/3632410.3632441
* Saim Rasheed (2021). *A Review of the Role of Machine Learning Techniques towards Brain-Computer Interface Applications*. Retrieved from https://doi.org/10.3390/make3040042
* Salwa Alzahrani, H. Banjar, Rsha Mirza (2024). *Systematic Review of EEG-Based Imagined Speech Classification Methods*. Retrieved from https://doi.org/10.3390/s24248168
* Sepideh Kilani, Seyedeh Nadia Aghili, M. Hulea (2023). *Enhancing P300-Based Brain-Computer Interfaces with Hybrid Transfer Learning: A Data Alignment and Fine-Tuning Approach*. Retrieved from https://doi.org/10.3390/app13106283
* Shang Feng, Haifeng Li, Lin Ma, Zhongliang Xu (2020). *An EEG Feature Extraction Method Based on Sparse Dictionary Self-Organizing Map for Event-Related Potential Recognition*. Retrieved from https://doi.org/10.3390/a13100259
* Shaotong Zhu, S. Hosni, Xiaofei Huang, Michael Wan, S. B. Borgheai, J. McLinden, Y. Shahriari, S. Ostadabbas (2022). *A dynamical graph-based feature extraction approach to enhance mental task classification in brain-computer interfaces*. Retrieved from https://doi.org/10.2139/ssrn.4170113
* Shaotong Zhu, S. Hosni, Xiaofei Huang, S. B. Borgheai, J. McLinden, Y. Shahriari, S. Ostadabbas (2021). *A Graph-Based Feature Extraction Algorithm Towards a Robust Data Fusion Framework for Brain-Computer Interfaces*. Retrieved from https://doi.org/10.1109/EMBC46164.2021.9630804
* Shiau-Ru Yang, T. Jung, Chin-Teng Lin, Kuan-Chih Huang, Chun-Shu Wei, H. Chiueh, Y. Hsin, Guan-Ting Liou, Li-Chun Wang (2022). *Recognizing Tonal and Nontonal Mandarin Sentences for EEG-Based Brain–Computer Interface*. Retrieved from https://doi.org/10.1109/TCDS.2021.3137251
* Shuang Liang, Changsheng Xuan, Wenlong Hang, Baiying Lei, Jun Wang, Jing Qin, K. Choi (2023). *Domain-Generalized EEG Classification With Category-Oriented Feature Decorrelation and Cross-View Consistency Learning*. Retrieved from https://doi.org/10.1109/TNSRE.2023.3300961
* Shuangling Ma, Zijie Situ, Xiaobo Peng, Zhangyang Li, Ying Huang (2025). *Multi-Class Classification Methods for EEG Signals of Lower-Limb Rehabilitation Movements*. Retrieved from https://doi.org/10.3390/biomimetics10070452
* Simona Cariello, D. Sanalitro, Alessandro Micali, A. Buscarino, M. Bucolo (2023). *Brain–Computer-Interface-Based Smart-Home Interface by Leveraging Motor Imagery Signals*. Retrieved from https://doi.org/10.3390/inventions8040091
* Siqi Cai, T. Schultz, Haizhou Li (2023). *Brain Topology Modeling With EEG-Graphs for Auditory Spatial Attention Detection*. Retrieved from https://doi.org/10.1109/TBME.2023.3294242
* Soroosh Shahtalebi, A. Asif, Arash Mohammadi (2020). *Siamese Neural Networks for EEG-based Brain-computer Interfaces*. Retrieved from https://doi.org/10.1109/EMBC44109.2020.9176001
* Sunreet Khanna, Anirban Chowdhury, Ashish Dutta, Venkatesh K. Subramanian (2024). *SCSP-3: A Spectrally Augmented Common Spatial Pattern Approach for Robust Motor Imagery-Based Brain–Computer Interface*. Retrieved from https://doi.org/10.1109/JSEN.2024.3351880
* Tao Wang, Linyan Wu, Yanping Li, Nuo Gao, Zhang Weiran (2019). *Learning Advanced Brain Computer Interface Technology: Comparing CSP Algorithm and WPA Algorithm for EEG Feature Extraction*. Retrieved from https://doi.org/10.4018/IJTHI.2019070102
* Tharun Kumar Reddy, L. Behera (2022). *Driver Drowsiness Detection: An Approach Based on Intelligent Brain–Computer Interfaces*. Retrieved from https://doi.org/10.1109/MSMC.2021.3069145
* Tharun Kumar Reddy, Vipul Arora, L. Behera, Yu-kai Wang, Chin-Teng Lin (2020). *Fuzzy Divergence Based Analysis for Eeg Drowsiness Detection Brain Computer Interfaces*. Retrieved from https://doi.org/10.1109/FUZZ48607.2020.9177833
* Tharun Kumar Reddy, Yu-kai Wang, Chin-Teng Lin, Javier Andreu-Perez (2021). *JOINT APPROXIMATE DIAGONALIZATION DIVERGENCE BASED SCHEME FOR EEG DROWSINESS DETECTION BRAIN COMPUTER INTERFACES*. Retrieved from https://doi.org/10.1109/FUZZ45933.2021.9494500
* Tian-jian Luo (2022). *Dual regularized feature extraction and adaptation for cross-subject motor imagery EEG classification*. Retrieved from https://doi.org/10.1109/BIBM55620.2022.9995282
* Tianliang Huang, Ziyue Luo, Yin Lyu (2023). *A2FWPO: Anti-aliasing filter based on whale parameter optimization method for feature extraction and recognition of dance motor imagery EEG*. Retrieved from https://doi.org/10.2298/csis221222033h
* Tianwei Shi, Ke Chen, Ling Ren, Wenhua Cui (2023). *Brain Computer Interface Based on Motor Imagery for Mechanical Arm Grasp Control*. Retrieved from https://doi.org/10.5755/j01.itc.52.2.32873
* Tianwei Shi, Ling Ren, Wenhua Cui (2020). *Feature Extraction of Brain–Computer Interface Electroencephalogram Based on Motor Imagery*. Retrieved from https://doi.org/10.1109/JSEN.2019.2939343
* Tingnan Qu, Jing Jin, Ren Xu, Xingyu Wang, A. Cichocki (2022). *Riemannian distance based channel selection and feature extraction combining discriminative time-frequency bands and Riemannian tangent space for MI-BCIs*. Retrieved from https://doi.org/10.1088/1741-2552/ac9338
* Upasana Talukdar, S. Hazarika, J. Q. Gan (2020). *Adaptive feature extraction in EEG-based motor imagery BCI: tracking mental fatigue*. Retrieved from https://doi.org/10.1088/1741-2552/ab53f1
* V. Galiotta, I. Quattrociocchi, M. D'ippolito, F. Schettini, P. Aricó, S. Sdoia, R. Formisano, F. Cincotti, D. Mattia, A. Riccio (2022). *EEG-based Brain-Computer Interfaces for people with Disorders of Consciousness: Features and applications. A systematic review*. Retrieved from https://doi.org/10.3389/fnhum.2022.1040816
* V. Jusas, Sam Gilvine Samuvel (2019). *Classification of Motor Imagery Using Combination of Feature Extraction and Reduction Methods for Brain-Computer Interface*. Retrieved from https://doi.org/10.5755/J01.ITC.48.2.23091
* Vairaprakash Selvaraj, Manjunathan Alagarsamy, Kavitha Datchanamoorthy, Geethalakshmi Manickam (2024). *Band power feature part-based convolutional neural network with African vulture optimization fostered channel selection for EEG classification*. Retrieved from https://doi.org/10.1080/10255842.2024.2356633
* Vartika Gupta, Tushar P. Kendre, Tharun Kumar Reddy, Vipul Arora (2022). *Comparative Performance Analysis of Scalp EEG and Ear EEG based P300 Ambulatory Brain-Computer Interfaces using Riemannian Geometry and Convolutional Neural Networks*. Retrieved from https://doi.org/10.1109/NCC55593.2022.9806815
* Víctor Asanza, Enrique Peláez, Francis R. Loayza, L. L. Lorente-Leyva, D. Peluffo-Ordóñez (2022). *Identification of Lower-Limb Motor Tasks via Brain–Computer Interfaces: A Topical Overview*. Retrieved from https://doi.org/10.3390/s22052028
* VK Benzy, A. P. Vinod (2019). *Classification of Motor Imagery Hand Movement Directions from EEG extracted Phase Locking Value features for Brain Computer Interfaces*. Retrieved from https://doi.org/10.1109/TENCON.2019.8929678
* Wallace Faveron de Almeida, Clodoaldo Aparecido de Moraes Lima, Sarajane Marques Peres (2021). *A systematic mapping of feature extraction and feature selection methods of electroencephalogram signals for neurological diseases diagnostic assistance*. Retrieved from https://doi.org/10.1109/TLA.2021.9448287
* Wei Tao, Z. Wang, C. Wong, Ziyu Jia, Senior Member Ieee Xun Chen, F. I. C. L. Philip Chen, Feng Wan, ChangLiiswith (2023). *ADFCNN: Attention-Based Dual-Scale Fusion Convolutional Neural Network for Motor Imagery Brain–Computer Interface*. Retrieved from https://doi.org/10.1109/TNSRE.2023.3342331
* Wei Zhao, Baocan Zhang, Haifeng Zhou, Dezhi Wei, Chenxi Huang, Quan Lan (2025). *Multi-scale convolutional transformer network for motor imagery brain-computer interface*. Retrieved from https://doi.org/10.1038/s41598-025-96611-5
* Weiyue Zhu, Lin Fang, Xinmiao Cao, Wenhao Li, Kai Wu, Jing Zhou (2024). *Design and Implementation of EEG-fNIRS Based Brain-Computer Interface Paradigm for Musical Imagery*. Retrieved from https://doi.org/10.1109/ICHCI63580.2024.10808007
* Weizheng Yuan (2022). *Features Domains and Classification Algorithms in Motor Imagery Brain Computer Interface*. Retrieved from https://doi.org/10.1109/EIECT58010.2022.00081
* Wenchang Zhang, Chuanqi Tan, F. Sun, Hang Wu, Bo Zhang (2018). *A Review of EEG-Based Brain-Computer Interface Systems Design*. Retrieved from https://doi.org/10.26599/BSA.2018.9050010
* Xianglong Zhu, Ming Meng, Zewen Yan, Zhizeng Luo (2025). *Motor Imagery EEG Classification Based on Multi-Domain Feature Rotation and Stacking Ensemble*. Retrieved from https://doi.org/10.3390/brainsci15010050
* Xiangmin Lun, Yifei Zhang, Mengyang Zhu, Yongheng Lian, Yimin Hou (2023). *A Combined Virtual Electrode-Based ESA and CNN Method for MI-EEG Signal Feature Extraction and Classification*. Retrieved from https://doi.org/10.3390/s23218893
* Xiangwen Deng, Ju-xia Zhu, Shangming Yang (2021). *SFE-Net: EEG-based Emotion Recognition with Symmetrical Spatial Feature Extraction*. Retrieved from https://doi.org/10.1145/3474085.3475403
* Xianlun Tang, Caiquan Yang, Xia Sun, Mi Zou, Huiming Wang (2023). *Motor Imagery EEG Decoding Based on Multi-Scale Hybrid Networks and Feature Enhancement*. Retrieved from https://doi.org/10.1109/TNSRE.2023.3242280
* Xianlun Tang, Xingchen Li, Wei Li, Bohui Hao, Yingke Xie, Xiaoyuan Dang (2021). *Transfer Learning: Rotation Alignment With Riemannian Mean for Brain–Computer Interfaces and Wheelchair Control*. Retrieved from https://doi.org/10.1109/TCDS.2021.3082648
* Xiaozhong Geng, Song Xue, Ping Yu, Dezhi Li, Mengzhe Yue, Xi Zhang, Linen Wang (2022). *A Fusion Algorithm for EEG Signal Processing Based on Motor Imagery Brain-Computer Interface*. Retrieved from https://doi.org/10.1155/2022/8935543
* Xicheng Lou, Xinwei Li, Hongying Meng, Jun Hu, Meili Xu, Yue Zhao, Jiazhang Yang, Zhangyong Li (2024). *EEG-DBNet: A Dual-Branch Network for Temporal-Spectral Decoding in Motor-Imagery Brain-Computer Interfaces*. Retrieved from https://doi.org/10.48550/arXiv.2405.16090
* Xinbin Liang, Yaru Liu, Yang Yu, Kaixuan Liu, Yadong Liu, Zongtan Zhou (2023). *Convolutional Neural Network with a Topographic Representation Module for EEG-Based Brain—Computer Interfaces*. Retrieved from https://doi.org/10.3390/brainsci13020268
* Xingbin Shi, Haiyan Wang, Baojiang Li, Yuxin Qin, Cheng Peng, Yifan Lu (2025). *Fusion Analysis of EEG-fNIRS Multimodal Brain Signals: A Multitask Classification Algorithm Incorporating Spatial-Temporal Convolution and Dual Attention Mechanisms*. Retrieved from https://doi.org/10.1109/TIM.2025.3538086
* Xiuyu Huang, Shuang Liang, Zengguang Li, C. Lai, K. Choi (2022). *EEG-based vibrotactile evoked brain-computer interfaces system: A systematic review*. Retrieved from https://doi.org/10.1371/journal.pone.0269001
* Xu Chen, Xingtong Bao, Kailun Jitian, Ruihan Li, Li Zhu, Wanzeng Kong (2025). *Hybrid EEG Feature Learning Method for Cross-Session Human Mental Attention State Classification*. Retrieved from https://doi.org/10.3390/brainsci15080805
* Yan Pei, Jiahui Xu, Qianhao Chen, Chenhao Wang, Feng Yu, Lisan Zhang, Wei Luo (2023). *DTP-Net: Learning to Reconstruct EEG Signals in Time-Frequency Domain by Multi-Scale Feature Reuse*. Retrieved from https://doi.org/10.1109/JBHI.2024.3358917
* Yaqi Chu, Xingang Zhao, Yijun Zou, He Zhang, Weiliang Xu, Yiwen Zhao (2018). *A Comparative Study of Different Feature Extraction Methods for Motor Imagery EEG Decoding within the Same Upper Extremity*. Retrieved from https://doi.org/10.1109/CAC.2018.8623624
* Yifan Niu, Ziyu Li, Gangyan Zeng, Yuan Zhang, Li Yao, Xia Wu (2025). *Electroencephalogram-Based Satisfaction Assessment Brain-Computer Interface in Emerging Video Service by Using Graph Representation Learning.*. Retrieved from https://doi.org/10.1177/21580014251359107
* Yifan Zhang, Yao-Kun Wang (2021). *Research on Feature Extraction Algorithm Commonly Used in Brain-computer Interface Technology*. Retrieved from https://doi.org/10.1088/1742-6596/1861/1/012027
* Yinan Wang, Chengxin Song, Tao Zhang, Zongwei Yao, Zhiyong Chang, Deping Wang (2023). *Feature Extraction of Motor Imagery EEG via Discrete Wavelet Transform and Generalized Maximum Fuzzy Membership Difference Entropy: A Comparative Study*. Retrieved from https://doi.org/10.3390/electronics12102207
* Ying Sun, Xiaolin Liu, Rui Na, Shuai Wang, Dezhi Zheng, Shangchun Fan (2023). *Cross-domain Feature Distillation Framework for Enhancing Classification in Ear-EEG Brain-Computer Interfaces*. Retrieved from https://doi.org/10.1145/3594739.3612911
* Yinghui Meng, YaRu Su, Duan Li, Jiaofen Nan, Yongquan Xia (2024). *A Stepwise Discriminant Analysis and FBCSP Feature Selection Strategy for EEG MI Recognition*. Retrieved from https://doi.org/10.14569/ijacsa.2024.0150597
* Yipeng Du, Jian Liu (2022). *IENet: a robust convolutional neural network for EEG based brain-computer interfaces*. Retrieved from https://doi.org/10.1088/1741-2552/ac7257
* Yongqiang Yu (2022). *Review of epileptic EEG feature extraction methods*. Retrieved from https://doi.org/10.54097/fcis.v1i3.1907
* Youngchul Kwak, Woo‐Jin Song, Seong-Eun Kim (2020). *Graph Neural Network with Multilevel Feature Fusion for EEG based Brain-Computer Interface*. Retrieved from https://doi.org/10.1109/ICCE-Asia49877.2020.9276983
* Yu Pei, Zhiguo Luo, Hongyu Zhao, Dengke Xu, Weiguo Li, Ye Yan, Huijiong Yan, Liang Xie, Minpeng Xu, E. Yin (2021). *A Tensor-Based Frequency Features Combination Method for Brain–Computer Interfaces*. Retrieved from https://doi.org/10.1109/TNSRE.2021.3125386
* Yu Xie, S. Oniga (2020). *A Review of Processing Methods and Classification Algorithm for EEG Signal*. Retrieved from https://doi.org/10.2478/cjece-2020-0004
* Yuan Tang, Zining Zhao, Shaorong Zhang, Zhi Li, Yun Mo, Yan Guo (2022). *Motor Imagery EEG Decoding Based on New Spatial-Frequency Feature and Hybrid Feature Selection Method*. Retrieved from https://doi.org/10.1155/2022/2856818
* Yue Ma, Xin Wu, Liangsheng Zheng, Pengchen Lian, Yang Xiao, Zhengkun Yi (2022). *Iterative Outlier Removal Clustering Based Time-Frequency-Spatial Feature Selection for Binary EEG Motor Imagery Decoding*. Retrieved from https://doi.org/10.1109/tim.2022.3193407
* Yujing Guo, Pengfei Ma (2025). *Research on Decoding EEG Signals Based on Grey Wolf Optimization Algorithm for Multi-Feature Fusion*. Retrieved from https://doi.org/10.1145/3727648.3727818
* Yunyuan Gao, Biao Jia, Michael Houston, Yingchun Zhang (2023). *Hybrid EEG-fNIRS Brain Computer Interface Based on Common Spatial Pattern by Using EEG-Informed General Linear Model*. Retrieved from https://doi.org/10.1109/TIM.2023.3276509
* Yunyuan Gao, Mengting Li, Yun Peng, Feng Fang, Yingchun Zhang (2023). *Double Stage Transfer Learning for Brain–Computer Interfaces*. Retrieved from https://doi.org/10.1109/TNSRE.2023.3241301
* Yunyuan Gao, Yici Liu, Qingshan She, Jianhai Zhang (2022). *Domain Adaptive Algorithm Based on Multi-Manifold Embedded Distributed Alignment for Brain-Computer Interfaces*. Retrieved from https://doi.org/10.1109/JBHI.2022.3218453
* Yuqing Wang, Zhiqiang Yang, Hongfei Ji, Jie Li, Lingyu Liu, Zhuang Jie (2022). *Cross-Modal Transfer Learning From EEG to Functional Near-Infrared Spectroscopy for Classification Task in Brain-Computer Interface System*. Retrieved from https://doi.org/10.3389/fpsyg.2022.833007
* Yuxin Chen, Yong Peng, Jiajia Tang, Tracey A. Camilleri, Kenneth P. Camilleri, Wangzeng Kong, Andrzej Cichocki (2025). *EEG-based affective brain–computer interfaces: recent advancements and future challenges*. Retrieved from https://doi.org/10.1088/1741-2552/ade290
* Yuyi Lu, Wenbo Wang, Baosheng Lian, Chencheng He (2024). *Feature Extraction and Classification of Motor Imagery EEG Signals in Motor Imagery for Sustainable Brain–Computer Interfaces*. Retrieved from https://doi.org/10.3390/su16156627
* Z. Iscan (2022). *Comparison of Deep Learning and Traditional Machine Learning Classification Performance in a Steady State Visual Evoked Potential Based Brain Computer Interface*. Retrieved from https://doi.org/10.17694/bajece.1088353
* Zhaoyang Lian, Lijuan Duan, Yuanhua Qiao, Juncheng Chen, Jun Miao, Ming-ai Li (2021). *The Improved ELM Algorithms Optimized by Bionic WOA for EEG Classification of Brain Computer Interface*. Retrieved from https://doi.org/10.1109/ACCESS.2021.3076347
* Zhen Chen, Ye Cao, Qiangqiang Fu, Liyang Hou (2025). *Hierarchical attention enhanced deep learning achieves high precision motor imagery classification in brain computer interfaces*. Retrieved from https://doi.org/10.1038/s41598-025-17922-1
* Zhengqing Miao, Xin Zhang, Mei-rong Zhao, Dong Ming (2023). *LMDA-Net: A lightweight multi-dimensional attention network for general EEG-based brain-computer interface paradigms and interpretability*. Retrieved from https://doi.org/10.48550/arXiv.2303.16407
* Zhihan Lv, Liang Qiao, Haibin Lv (2022). *Cognitive Computing for Brain–Computer Interface-Based Computational Social Digital Twins Systems*. Retrieved from https://doi.org/10.1109/TCSS.2022.3202872
* Zhizeng Luo, Xianju Lu, Xugang Xi (2020). *EEG Feature Extraction Based on a Bilevel Network: Minimum Spanning Tree and Regional Network*. Retrieved from https://doi.org/10.3390/electronics9020203
* Zhouzhou Zhou, Anmin Gong, Qian Qian, Lei Su, Lei Zhao, Yunfa Fu (2021). *A novel strategy for driving car brain–computer interfaces: Discrimination of EEG-based visual-motor imagery*. Retrieved from https://doi.org/10.1515/tnsci-2020-0199
* Zifan Xue, Yunfan Zhang, Hui Li, Hongbin Chen, Shengnan Shen, Hejun Du (2024). *Instrumentation, Measurement, and Signal Processing in Electroencephalography-Based Brain-Computer Interfaces: Situations and Prospects*. Retrieved from https://doi.org/10.1109/TIM.2024.3417598
* Ziwei Zhao, Yanfei Lin, Yijun Wang, Xiaorong Gao (2023). *Single-Trial EEG Classification Using Spatio-Temporal Weighting and Correlation Analysis for RSVP-Based Collaborative Brain Computer Interface*. Retrieved from https://doi.org/10.1109/TBME.2023.3309255
